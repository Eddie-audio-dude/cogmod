[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Cognitive Models",
    "section": "",
    "text": "Preface\nThis is a collection of notes and materials for an introductory course in computational cognitive modeling. It will be updated and, arguably, improved over the course of the semester.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Some functions of models\nUnderstanding the mind is ultimately about understanding a dynamic system comprised of a large set of elements that interact in complex ways. If we had designed the mind, things would be easier: Like a car, a computer, or some other piece of modern machinery, we would have built different parts for different functions and stuck them together in a way that would make it easy for us to repair and reconfigure the system. In reality, things are not so simple. Because the mind is not human-engineered (or really “engineered” at all!), for us mere humans to understand it requires us to reverse-engineer the mind. In other words, we have to see what the mind does in some particular situation, build a particular type of machine—a model—that we hypothesize operates like the mind does, and then put the machine in that same scenario and see whether it acts like a human mind. To the extent that our model acts like a human in that scenario, that gives us reason to believe that the model is operating in some sense “like” a human mind does in that scenario.\nIn the early days of scientific psychology, our tools for building models of complex dynamical systems were quite limited. We could build physical models, but these are constrained by the physical properties of the materials we use (nonetheless, it is worth noting that mechanical model of attention by Broadbent (1957) is designed in such a way that the physical properties of the model capture important psychological constraints). Purely mathematical models may not have been so strongly constrained by physicality, but when considering situations with many interacting elements or when stochastic noise is involved, mathematical models quickly become intractable (consider the insoluble “three body problem”—even with a complete model of such a system, we cannot derive its future behavior analytically). As a result, early psychology was dominated by behaviorism, which eschewed the development of theories of the mind and contented itself merely with observing and cataloging behavior.\nIt was not until the middle of the twentieth century, when modern computers began to become of use, that the possibility of “reverse-engineering the mind” became a reality. This was the time of the “cognitive revolution” (Neisser, 1967). The revolution came about for both technical and conceptual reasons.\nFrom a conceptual perspective, computers offered a productive metaphor for helping us understand how the mind works. A computer uses the same physical substrate to perform different functions, similar to how the same brain lets us both speak and play piano. A computer’s adaptivity comes from the fact that the computer can run different “programs” on its hardware. A program is a set of procedures that take a set of “inputs” and transform them into “outputs”. This is analogous to how a living organism decides to act in a certain way (its “outputs”) depending on its goals and on the environment it happens to be in (its “inputs”). Meanwhile, the procedures that transform a computer’s inputs into outputs often involve intermediate steps that do not themselves produce observable behavior but which are nonetheless represented by changes in the internal state of the computer. These internal states are analogous to thoughts or beliefs in that they may not be externally observable, but they are critical steps on the path toward taking an action. The computer metaphor thus enables us to understand cognition in terms of how internal states of mind represent aspects of an organism’s environment, goals, and thoughts in such a way that these representations can be processed to yield behavior that is appropriate to the situation the organism is in.\nFrom a technical perspective, computers offer a way to derive predictions from complex models that would not have been tractable otherwise. As we shall see, this is particularly valuable for two applications: First, we can use the computer to simulate what a model would do and thereby understand the distribution of possible actions it can take. This obviates the need to derive predictions through mathematical analysis or logic, which though powerful, can only be applied to simple models. Second, we can use the computer to fit a model to data. Almost all models have parameters which can be thought of as “knobs” or “settings” that adjust the kind of behavior the model produces. To “fit” a model means to find the parameters for that model that get it to generate behavior that is as close as possible to the behavior recorded in a dataset. Except for very simple models, it is impossible (or at least very impractical) to try to fit them to data without a computer. But as we shall see, fitting a model is useful because we can infer from the best-fitting parameters something about the person who produced the data to which the model was fit.\nIn summary, computers made it feasible for cognitive psychologists to “reverse-engineer” the mind because they (a) provided a valuable conceptual metaphor that allowed theories of cognition to be posed in the form of computational models comprised of internal representations and processes applied to those representations; (b) enabled predictions to be derived for models that were complex and/or had stochastic elements; and (c) enabled those same kinds of models to be “fit” to data so that model parameters can give insight into how a person performed the task for which data was recorded.\nThere is an important difference between “reverse-engineering” a natural system, like the mind, from reverse-engineering a human-designed system like a car. Because a natural system was not “engineered”, the models we devise are not guaranteed to work the same way as a natural system, even if the model accurately mimicks the behavior of the natural system in the cases we study. The purpose in “reverse-engineering” the mind is not to build a duplicate mind, it is instead to “translate” a complex system into a form that enables us to understand it better. The model is a deliberate simplification which we expect to deviate from reality in many ways. What we hope is that we arrive at a model that helps us understand the key features of a natural system well enough for us to understand why it acts the way it does in specific situations (for further discussion of the purposes of models in psychology, see Cox & Shiffrin, 2024; Singmann et al., 2022).\nAs Cox & Shiffrin (2024) describe, a computational cognitive model falls on the “causal” end of the spectrum in the graph shown at the top. They enumerate a couple of goals that such a model might serve:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#some-functions-of-models",
    "href": "intro.html#some-functions-of-models",
    "title": "1  Introduction",
    "section": "",
    "text": "All models are wrong, but causal models are useful when they capture and approximate the causal processes at work and when they generalize to other settings. When modeling complex human behavior, all the models are at best crude approximations to reality, but nonetheless they can prove useful by describing the processes that are most important for explaining behavior.\nModeling allows precise communication among scientists. When theories and hypotheses are proposed verbally and heuristically, their precise meaning is not generally known even to the proposers, and they are often misinterpreted and misunderstood by others. When theoretical constructs are clearly linked to elements of a model and the internal workings of the model are described with mathematical or computational precision (e.g., by including the code running the model simulation), other scientists can use, generalize, and test the model because its application in at least its original domain is well specified.\nModels make clear the links between assumptions and predictions. Different investigators cannot dispute the predictions of the model that are produced by a given set of parameters (the parameters generally index different quantitative variants of a given class of models).\nThe formal specification of the model clarifies the nature of proposed internal cognitive processes. A poor modeler may fail to demonstrate that linkage. A good modeler will explore the parameter space and show how the parameter values change the predictions and how narrow or broad a range of outcomes can be predicted by changes in the parameter values. A good modeler will also explore alterations in the model, perhaps by deleting some processes or by adding others, or by fixing some parameter values at certain values, thus providing diagnostic information about the qualitative features of the outcome space that are primarily due to a process controlled by particular parameters. A bad modeler might claim a fit to data provides support for an underlying causal theory when in fact the fit is primarily due to some parameter or theory not conceptually related to the claim.\nConstructing a model can act as an “intuition pump” (cf. Dennett, 1980). Many modelers try to infer underlying cognitive processes from complex data sets that involve multiple measures (e.g., accuracy and response time) and many conditions which may be difficult or impossible to summarize adequately. Modelers form hypotheses about the processes involved based on the data and their prior knowledge. It is often the case that intuiting predictions for different combinations of processes is not possible due to the limitations of human cognition. Thus, different combinations of processes are instantiated as formal models, enabling a modeler to observe and test the predictions of their hypotheses. In an iterative model building process, the failures in each iteration indicate the way forward to an appropriate account.\nModeling allows different hypothesis classes to be compared, both because the predictions of each are well specified and because model comparison techniques take into account model complexity. The issue of complexity is itself quite complex.\n\nOne issue is due to statistical noise produced by limited data. A flexible model with many parameters can produce what seems to be a good fit with parameter values that explain the noise in the data rather than the underlying processes. The best model comparison techniques penalize models appropriately for extra complexity. However, models are in most cases developed after observing the data, and they are used to explain the patterns observed. To do so, they often incorporate assumptions that are critical but not explicitly parameterized. It thus becomes a difficult and subtle matter to assess complexity adequately. A secondary problem with using fit to compare models is the fact that the most principled ways to control for complexity, such as Bayesian model selection and minimum description length, are difficult to implement computationally and are often replaced by approximations such as the Akaike or Bayes/Schwartz information criteria that often fail to account for key aspects of model complexity.\nSimpler models are also favored for other reasons. A chief one is limited human reasoning: As a model becomes more complex, it becomes more difficult for a human to understand how it works. Simpler models are also favored when analytic predictions can be derived (thereby greatly reducing computational costs) and for qualitative reasons such as “elegance”.\nSimpler models are particularly favored when their core processes generalize well across many tasks.\nThere exists a danger that the modeler will mistake small quantitative differences in “fit” for the important differences among models—differences that generally lie in qualitative patterns of predictions. Knowing one model provides a better fit to a limited set of observations from a narrow experimental setting is not often useful. For example, consider a model that correctly predicts the relative levels of recall accuracy observed across conditions in a given experiment but quantitatively overpredicts the accuracy in a single condition. Meanwhile, another model perfectly predicts the accuracy in that condition but fails to predict the right qualitative pattern of accuracy across conditions. We argue that the qualitatively correct prediction is a reason to favor the first model, even though it might yield a worse quantitative fit. Correct qualitative predictions across conditions are often a sign that a model captures an important and generalizable causal process.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-simulation",
    "href": "intro.html#the-importance-of-simulation",
    "title": "1  Introduction",
    "section": "1.2 The importance of simulation",
    "text": "1.2 The importance of simulation\nThe models that we will be covering are models that simulate behavioral (and maybe even neural) outcomes. Because we are building models of a complex system—namely, the mind—our models can also become complex. Therefore, understanding what kind of behavior a model produces may require us to simulate behavior from that model. This will also help us to understand the relationship between the model’s parameters and its behavior. By simulating how behavior changes as one or more parameters change, we can understand the role played by the theoretical construct represented by that parameter.\nFor example, we might have a parameter that represents the quality or precision with which an event is stored in memory. In a model where this memory representation is used to yield behavior, we can systematically adjust the value of the quality/precision parameter and observe the effect this has on the model’s simulated behavior. Again, because we are dealing with models that can grow quite complex, we may even be surprised by the behavior the model produces!\nTwo analogies may help give some intuition about the value of simulation: If we are cooking, often the only way to know how a particular combination of spices will taste is to actually combine them and taste. Model parameters are like the different amounts of each spice, with the final taste being analogous to the model’s simulated behavior. Alternatively, you can think of model parameters as being like characters in an improv sketch. The characters have different backgrounds and goals which dictate how they will interact and how the story will develop. The background and goals of the characters are like the parameters of a model, with the resulting performance analogous to the model’s predicted behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-fitting-data",
    "href": "intro.html#the-importance-of-fitting-data",
    "title": "1  Introduction",
    "section": "1.3 The importance of fitting data",
    "text": "1.3 The importance of fitting data\n“Fitting” a model to data means finding the combination of parameter values for which the model produces behavior that most closely resembles that produced by a participant in some task. The value of doing this is that it helps us understand why that participant acted the way they did.\nFor example, we might want to know whether someone was fast because they were able to quickly accumulate the evidence they needed, because they were uncautious, because they were biased, or because they could execute motor actions quickly. We can address that question by finding the values of the parameters associated with each construct that best fit their observed performance.\n\n\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and immediate memory. Psychological Review, 64(3), 205–215.\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event memory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of human memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and Brain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nNeisser, U. (1967). Cognitive psychology. Appleton-Century-Crofts.\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober, C. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D., Navarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service of science: Don’t let the tail wag the dog. Computational Brain & Behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "ebrw.html",
    "href": "ebrw.html",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "2.1 Summed similarity\nThe Exemplar-Based Random Walk (EBRW) (Nosofsky et al., 2011; Nosofsky & Palmeri, 1997) is a dynamic extension of the Generalized Context Model (GCM) (Nosofsky, 1986). According to these models, each time you experience an item in a particular context, it leaves a “trace” in memory. This trace is called an “exemplar” or an “instance” and it consists of a record of the values the item had for particular features. When you are presented with a probe item, it activates each of these exemplars in memory in proportion to how similar the features of the probe are to the features of the exemplars in memory.\nThe EBRW was originally developed to account for choice and RT in categorization tasks. In what follows, we apply EBRW to a recognition task. Recognition decisions are based on the summed activation across all exemplars in memory, which is termed the “familiarity” of the probe. The extent to which familiarity is higher than a criterion determines the extent to which the probe will be recognized as having been seen before. Specifically, familiarity determines the rate at which evidence accumulates toward either a “yes” or “no” decision regarding whether the probe item was seen before. If the accumulated evidence reaches an upper threshold, a “yes” decision is made; otherwise, if the accumulated evidence reaches a lower threshold, a “no” decision is made.\nThe text below first describes how familiarity is determined by the summed similarity between a probe and the exemplars in memory, using the concrete example of items consisting of patches of color. Then, the dynamics of evidence accumulation are described. These dynamics are first described as a random walk between the thresholds for “yes” and “no” decisions. Then, we illustrate how the same dynamics can be described in continuous time as a diffusion process instead of a random walk (Nosofsky et al., 2014). Finally, we see how the continuous diffusion process makes it easier to fit the parameters of the EBRW model to recognition data.\nFor concreteness, we imagine an experiment in which several color patches were studied. Colors can be described in terms of three features: hue, chroma (or “saturation”), and luminance (or “brightness”). Imagine that you saw many reddish-hued colors that varied in chroma and luminance. According to the EBRW, each of the colors you saw would leave a trace in memory. Each trace would consist of the values of the color you saw along those three dimensions. In this example, all the colors have the same value for “hue”, which is 0. The value of “0” for “hue” corresponds to a reddish color. The colors differ in their values for chroma and luminance, as illustrated in the graph below:\nCode\ncolDF &lt;- expand_grid(h = hue, c = seq(30, 70, length.out = 5), l = seq(30, 70, length.out = 5)) %&gt;%\n    mutate(col = hcl(h, c, l))\n\ncolDF %&gt;%\n    ggplot(aes(x = c, y = l, fill = col)) +\n    geom_tile(width = 2.5, height = 2.5) +\n    scale_fill_identity() +\n    coord_equal() +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", caption = bquote(plain(hue) == .(round(hue))))\nYour memory traces can also be written as a matrix, where each row corresponds to an item (color) and each column corresponds to a feature (h for “hue”, c for “chroma”, and l for “luminance”):\nCode\nknitr::kable(head(colDF %&gt;% select(h, c, l), 10), row.names = TRUE)\n\n\n\n\n\n\nh\nc\nl\n\n\n\n\n1\n0\n30\n30\n\n\n2\n0\n30\n40\n\n\n3\n0\n30\n50\n\n\n4\n0\n30\n60\n\n\n5\n0\n30\n70\n\n\n6\n0\n40\n30\n\n\n7\n0\n40\n40\n\n\n8\n0\n40\n50\n\n\n9\n0\n40\n60\n\n\n10\n0\n40\n70\nThese coordinates will often be derived using Multidimensional Scaling (MDS) (Nosofsky, 1992; Shepard, 1962a, 1962b). This type of analysis derives a spatial representation of a set of stimuli on the basis of similarity judgments provided by raters.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#summed-similarity",
    "href": "ebrw.html#summed-similarity",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "2.1.1 Perceived distance and similarity\nThe perceived distance between any two of these colors is the Euclidean distance between their feature values, weighted by the degree of attention given to each feature: \\[\nd_{ij} = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{ik} - x_{jk} \\right)^2}\n\\] where \\(w_k\\) is the weight given to feature \\(k\\), \\(x_{ik}\\) is the value of item \\(i\\) on feature \\(k\\), \\(x_{jk}\\) is the value of item \\(j\\) on feature \\(k\\), \\(d_{ij}\\) is the perceived distance between items \\(i\\) and \\(j\\), and \\(N_F\\) is the number of features which in this example is 3 (hue, chroma, and luminance). Note also that while Euclidean distance is appropriate for colors, other types of distance metrics may be more appropriate for other kinds of stimuli.\nPerceived similarity between two items, \\(s_{ij}\\), is an exponential function of the psychological distance between those items: \\[\ns_{ij} = \\exp(-c d_{ij})\n\\] where \\(c\\) is a sensitivity parameter that controls how quickly perceived similarity decreases with distance, as illustrated in the graph below:\n\n\nCode\nexpand_grid(d = seq(0, 10, length.out = 151), c = seq(0.25, 3, by = 0.25)) %&gt;%\n    mutate(s = exp(-c * d)) %&gt;%\n    ggplot(aes(x = d, y = s, color = c, group = c)) +\n    geom_line() +\n    scale_color_continuous_sequential() +\n    labs(x = expression(d[ij]), y = expression(s[ij])) +\n    theme(legend.position = c(1, 1), legend.justification = c(1, 1))\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Summed similarity\nImagine that you have just been shown two colors from among the set shown earlier. We then present you with a third color—a probe item—and ask whether it was one of the two you just saw. You answer this question on the basis of the summed similarity between the probe item and the two items in memory. The probe item has its own vector of feature values, \\(\\mathbf{x_q}\\). The perceived distance between the probe item and each of the memory items is, as above, the Euclidean distance between the probe’s feature values and those of the memory item: \\[\n\\begin{align}\nd_{qj} & = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{qk} - x_{jk} \\right)^2} \\\\\ns_{qj} & = \\exp \\left( -c d_{qj} \\right) \\\\\nS & = \\sum_{j = 1}^{N_M} s_{qj}\n\\end{align}\n\\] and, again, the perceived similarity \\(s_{qj}\\) between the probe \\(q\\) and memory item \\(j\\) is an exponential function of perceived distance \\(d_{qj}\\). Finally, summed similarity \\(S\\) is the sum of the perceived similarities across all \\(N_M\\) items in memory.\nThe graphs below illustrate how this works. The left graph shows contours of equal similarity from each of two study items. The right graph shows summed similarity as a function of the chroma and luminance of a probe item (assuming the same hue).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d))\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 1, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n2.1.2.1 Trace strength\nIt is reasonable to believe that some memory traces are stronger than others, likely due to things like primacy and recency. In GCM/EBRW, “strength” is operationalized as a scaling factor \\(m_j\\) applied to perceived similarity: \\[\ns_{qj} = m_j \\exp \\left( -c d_{qj} \\right)\n\\]\nStronger traces have their similarity multiplied by a large value (\\(m_j\\) is large if trace \\(j\\) is strong) while weaker traces have their similarity multiplied by a small value (\\(m_j\\) is small if trace \\(j\\) is weak). This is illustrated in the pair of graphs below. A probe item does not need to be as similar to a strong item in order to evoke the same level of perceived similarity.\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Trace specificity\nThe specificity parameter \\(c\\) represents the fact that items are assumed to be encoded with some degree of error/uncertainty. Just as items may be encoded with more or less strength, it is reasonable to assume that items can be encoded in memory with more or less specificity. Thus, we add a subscript to the \\(c\\) parameter corresponding to each study item: \\[\ns_{qj} = m_j \\exp \\left( -c_j d_{qj} \\right)\n\\]\nIf an item is encoded with high specificity, then it will only be perceived as similar to the probe if the probe is very close in psychological space. This is illustrated in the pair of graphs below, where item 2 is not only stronger (\\(m_2 = 2\\) vs. \\(m_1 = 1\\)) but also more precise (\\(c_2 = 0.1\\) vs. \\(c_1 = 0.05\\)).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nspecificity &lt;- c(0.05, 0.1)\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-specificity[item] * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "href": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.2 Making a recognition decision: From random walk to diffusion",
    "text": "2.2 Making a recognition decision: From random walk to diffusion\nAccording to the EBRW, each trace \\(j\\) in memory races to be retrieved at a rate proportional to its perceived similarity to the probe item, \\(s_{qj}\\). Traces race not just against one another, but against a criterion. If a memory trace wins the race, this is taken as evidence that the probe item matches something in memory, thus favoring a “yes” recognition response. If the criterion wins the race instead, this is taken as evidence that the probe item does not match anything in memory, thus favoring a “no” recognition response.\nThe idea is that, if the probe item matches something in memory, then the corresponding memory trace (or one sufficiently similar to probably match) should be able to win against the criterion. If nothing wins against the criterion, then this suggests there are no traces in memory that are a good match to the probe.\n\n2.2.1 Accumulating memory evidence\nThe outcome of each race is added to a running tally which starts at zero. The value of the tally at any given time \\(t\\), which we can denote \\(x(t)\\), constitutes the current state of evidence from memory for making a recognition decision. Assume that each race takes \\(\\Delta t\\) seconds to complete. Each time a memory trace wins the race, the tally gets incremented by one; each time the criterion wins the race, the tally gets decremented by one. Put formally, we can write this process as \\[\nx\\left( t + \\Delta t \\right) =\n\\begin{cases}\nx\\left( t \\right) + 1 & \\text{if trace wins} \\\\\nx\\left( t \\right) - 1 & \\text{if criterion wins}\n\\end{cases}\n\\] where \\(x(0) = 0\\).\n\n\n2.2.2 Step probabilities\nAlthough we have specified that whether memory evidence goes up or down depends on whether a trace or the criterion wins the race, we have not yet specified how the outcome of that race is determined. The winner of each race is random but depends on the similarity \\(s_{qj}\\) between each trace \\(j\\) and the probe \\(q\\). Specifically, trace \\(j\\) wins the race with probability: \\[\n\\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa}\n\\] where \\(\\kappa\\) is a nonnegative number that represents how stringent the criterion is. In other words, the equation above says that the probability that trace \\(j\\) wins the race is the similarity between trace \\(j\\) and the probe \\(q\\) divided by the summed similarity across all traces plus the criterion \\(\\kappa\\). In a sense, we can think of the criterion is like a “virtual memory trace” that races alongside the \\(N\\) actual memory traces.\nRemember that we increment memory strength whenever any trace wins the race, regardless of which one it is. Because only one trace can win each race, the probability that any trace wins is just the sum of the probabilities of winning across all \\(N\\) traces, i.e.: \\[\np = \\sum_{j = 1}^N \\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa} = \\frac{1}{\\sum_{k = 1}^N s_{qk} + \\kappa} \\left( \\sum_{j = 1}^Ns_{qj} \\right) = \\frac{S}{S + \\kappa}\n\\] where \\(S = \\sum_{j = 1}^N s_{qj}\\) is the summed similarity across all \\(N\\) traces. The quantity \\(p\\) is the probability that the random walk takes a step up.\nThe EBRW models the speed of decision making in terms of how many races must be run until the accumulated win advantage in favor of either a “yes” or “no” response reaches a decision boundary. To convert this to “real time”, we must say how long each race takes and allow for a residual time. Above, we used \\(\\Delta t\\) to stand for the amount of time (in seconds) each race takes to run. It will be convenient later to think instead of \\(\\nu = \\frac{1}{\\Delta t}\\), where \\(\\nu\\) is the number of races per second.\nThe figure below shows an example of how memory evidence evolves during a single trial in which \\(p = 0.55\\), \\(\\nu = 40\\), \\(B_{Upper} = 7\\), \\(B_{Lower} = -8\\), and \\(t_0 = 0.2\\). In addition, the graphs above and below the evidence trajectory illustrate the relative frequency with which, across many identical trials, each type of response would be made at each unit of time. Note that these distributions are discrete because the random walk operates in discrete time intervals, each of duration \\(\\Delta t\\) (which in this example is \\(\\Delta t = \\frac{1}{\\nu} = 0.025\\) seconds).\n\n\nCode\nset.seed(1)\n\nnu &lt;- 40\np &lt;- 0.55\n\nB &lt;- c(-8, 7)\nresid &lt;- 0.2\n\n### RT distributions\n\nY_rw &lt;- seq(B[1], B[2])\nP_rw &lt;- matrix(0, nrow = length(Y_rw), ncol = length(Y_rw))\nP_rw[cbind(2:(nrow(P_rw) - 1), 1:(ncol(P_rw) - 2))] &lt;- 1 - p\nP_rw[cbind(2:(nrow(P_rw) - 1), 3:ncol(P_rw))] &lt;- p\nP_rw[1, 1] &lt;- P_rw[nrow(P_rw), ncol(P_rw)] &lt;- 1\n\n### Simulation\n\nwhile (TRUE) {\n    winner &lt;- 0\n    x_rw &lt;- 0\n\n    while (TRUE) {\n        s &lt;- 2 * (runif(n = 1) &lt; p) - 1\n        x_rw &lt;- c(x_rw, x_rw[length(x_rw)] + s)\n        if (x_rw[length(x_rw)] &lt;= B[1]) {\n            winner &lt;- 1\n            break\n        } else if (x_rw[length(x_rw)] &gt;= B[2]) {\n            winner &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == 2 & (length(x_rw) / nu) &gt; 1.5) {\n        break\n    }\n}\n\nRT_rw &lt;- matrix(0, nrow = 2, ncol = length(x_rw))\nZ_rw &lt;- 1 * c(Y_rw == 0)\n\nfor (i in 1:length(x_rw)) {\n    Z_rw &lt;- Z_rw %*% P_rw\n    RT_rw[1, i] &lt;- Z_rw[1]\n    RT_rw[2, i] &lt;- Z_rw[length(Z_rw)]\n}\n\ndRT_rw &lt;- apply(RT_rw, MARGIN = 1, FUN = diff) * nu / 2\n\nrtPlot1 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#eeb211\", color = NA, width = 1 / nu) +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_rw)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#46166b\", color = NA, width = 1 / nu) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_rw)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + 1:length(x_rw) / nu, x = x_rw) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step(linewidth = 1.5) +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 From discrete random walk to continuous diffusion\nA random walk takes discrete-valued steps either up or down in discrete units of time. A Wiener diffusion process takes continuous-valued steps sampled from a normal distribution in infinitely small units of time, thus effectively operating in continuous time. We are going to approximate the discrete EBRW with a continuous diffusion process (so technically we should call this model the EBD for Exemplar-Based Diffusion, but we will keep calling it the EBRW for posterity).\nIn going from a random walk to a diffusion model, we are making an important psychological claim: We are saying that, instead of memory evidence arriving in discrete units at regular intervals, memory evidence is a continuous value that continually evolves as new information arrives. We can think of this as saying that, instead of only knowing the outcome of each race, you can see who is ahead and who is behind at any given time; this is the move from discrete time to continuous time. Moreover, instead of only scoring each race as a win or loss for the memory traces, the races are assigned a continuous value depending on how clear the winner is; this is the move from discrete evidence to continuous evidence.\n\n2.2.3.1 Mean and standard deviation of diffusion\nWe can write the update equation for the random walk like we did above: \\[\n\\begin{align}\nx \\left( t + \\Delta t \\right) & = \\begin{cases} x(t) + 1 & \\text{with probability } p \\\\ x(t) - 1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & = \\begin{cases} 1 & \\text{with probability } p \\\\ -1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & \\sim 2 \\times \\text{Bernoulli} \\left( p \\right) - 1\n\\end{align}\n\\] where we have rearranged terms and used the shorthand in the final line to emphasize the idea that each step of the random walk can be thought of as a sample from a Bernoulli distribution with parameter \\(p\\) that is then transformed from \\(\\lbrace 0, 1 \\rbrace\\) to \\(\\lbrace -1, 1 \\rbrace\\).\nTo turn this into a continuous diffusion process, we need to swap out the transformed Bernoulli distribution with a normal distribution that has the same mean and variance. The mean is \\(2 p - 1\\) and the variance is \\(4 p \\left(1 - p \\right)\\). One more thing: remember that we run \\(\\nu\\) races per second, so we need to multiply the mean and variance by \\(\\nu\\). Therefore, the mean drift rate is \\(v = \\nu \\left(2 p - 1 \\right)\\) and the variance is \\(\\sigma^2 = 4 \\nu p (1 - p)\\).\nNote that this is different from the typical diffusion model where the variance of the evidence samples is arbitrarily fixed to 1. Notice an important property of this variance: It is largest when \\(p = 0.5\\) and approaches zero as \\(p\\) approaches either 0 or 1. In other words, the more uncertain the outcome of each race, the more noise there is in the diffusion. This is illustrated below:\n\n\nCode\nexpand_grid(p = seq(0, 1, length.out = 101), nu = seq(10, 40, by = 10)) %&gt;%\n    mutate(sigma2 = 4 * nu * p * (1 - p)) %&gt;%\n    ggplot(aes(x = p, y = sigma2, color = nu, group = nu)) +\n    geom_line() +\n    labs(x = p, y = expression(sigma^2), color = expression(nu)) +\n    theme(legend.position = c(1, 1), legend.justification = c(1, 1))\n\n\n\n\n\n\n\n\n\nTo summarize, the difference between the random walk and the diffusion is that we have swapped out a discrete binomial distribution of evidence increments per unit time with a continuous normal distribution of evidence increments per unit time. Everything else is the same: You still respond “yes” if and when the accumulated evidence \\(x(t)\\) reaches either the upper boundary or the lower boundary.\n\n\n2.2.3.2 Closeness of predictions\nTo illustrate how well the diffusion process approximates the random walk, the graphs below show the diffusion approximation to the same random walk example used above. The smooth lines in the upper and lower graphs are the probability of responding per unit time (i.e., the probability density function) according to the Wiener diffusion model. The open bars are the same probabilities from the random walk. The diffusion model’s predictions hew very closely to those of the random walk!\n\n\nCode\nmu &lt;- nu * (2 * p - 1)\nsigma2 &lt;- 4 * nu * p * (1 - p)\nboundsep &lt;- B[2] - B[1]\nbias &lt;- (0 - B[1]) / (B[2] - B[1])\ndelta_t &lt;- 0.001\n\nwhile (TRUE) {\n    winner_diff &lt;- NA\n    x_diff &lt;- 0\n    \n    while (TRUE) {\n        x_diff &lt;- c(x_diff, x_diff[length(x_diff)] + rnorm(n = 1, mean = mu * delta_t, sd = sqrt(sigma2 * delta_t)))\n        if (x_diff[length(x_diff)] &lt;= B[1]) {\n            winner_diff &lt;- 1\n            break\n        } else if (x_diff[length(x_diff)] &gt;= B[2]) {\n            winner_diff &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == winner_diff & abs((length(x_diff) * delta_t) - (length(x_rw) / nu)) &lt; (1 / nu)) {\n        break\n    }\n}\n\nx_diff &lt;- pmax(pmin(x_diff, B[2]), B[1])\n\nt &lt;- seq(1, length(x_diff)) * delta_t\n\ndRT_diff &lt;- cbind(\n    WienerPDF(t = t, response = \"lower\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value,\n    WienerPDF(t = t, response = \"upper\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value\n)\n\nrtPlot1 &lt;- tibble(t = resid + t, p = dRT_diff[,2]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])), color = \"#eeb211aa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#eeb21177\", color = \"#eeb211\") +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_diff)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + t, p = dRT_diff[,1]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])), color = \"#46166baa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#46166b77\", color = \"#46166b\") +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_diff)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + t, x = x_diff) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_line() +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu), v == .(signif(mu, 3)), sigma == .(signif(sqrt(sigma2), 3)))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#implementation-in-r",
    "href": "ebrw.html#implementation-in-r",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.3 Implementation in R",
    "text": "2.3 Implementation in R\nTo find the EBRW parameters that best fit the recognition data from a participant, let’s implement the diffusion version of the EBRW in R using the WienR package. We must define a function to compute the negative log-likelihood (NLL) for a set of observed responses/RT’s, given a set of parameters. The function itself, in outline form, looks like the one below. I have written comments for the things that the function needs to accomplish to get from what is given to the function (in the parentheses following function) to what the function needs to return at the end.\nFor example purposes, this implementation doesn’t include all of the bells and whistles that the full model includes. It will not allow for varying trace strength nor will it include attention weights on each dimension. This is meant to illustrate the basic idea that we can define a diffusion model in which the drift rates are derived from a theory, rather than just estimated.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\nLet’s now fill in each of those sections in turn.\n\n2.3.1 Parameters\nThe vector par that is the first argument to the ebrw_nll function should be a named vector that has the following entries:\n\n\nCode\npar &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\n\n\n2.3.2 Computing the mean and SD of the drift for each trial\nRecall that the drift rates depend on the distances between each of the stimulus items. Since the function is provided with stim_coords, we can make our job a little easier by using the dist function to compute the matrix of distances between all pairs of items. This saves us from “recomputing” the distances between pairs of items that occur on multiple trials:\n\n\nCode\nstim_dists &lt;- as.matrix(dist(stim_coords))\n\n\nThen, to compute the summed similarity for each trial i, we can use a for loop:\n\n\nCode\nevidence_mean &lt;- rep(0, length(probe_item))\nevidence_sd &lt;- rep(0, length(probe_item))\n\nfor (i in 1:length(probe_item)) {\n    summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n    p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n    \n    evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n    evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n}\n\n\nWe have now completed the second step of writing the ebrw_nll function, as summarized below.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\n\n\n2.3.3 Calculating the log-likelihood\nThis step is almost too easy. We are using the WienR package, which means we can use the WienerPDF function like we’ve seen already. There is only one thing we need to do: The WienerPDF function assumes that the standard deviation of the diffusion is always equal to one. As such, we need to standardize the drift rate and boundary separation before we send them to the WienerPDF function by dividing each by evidence_sd:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    )\n    \n    # 3. Return final result\n    return(-sum(result$logvalue))\n}\n\n\n\n\n2.3.4 Error-checking\nIt is important for us to do some error checking. Sometimes, a particular combination of parameters will make it impossible for the WienerPDF function to calculate the log-likelihood. When that happens, it gives an error. In essence, such a result tells us that the model cannot work with that combination of parameters. Thus, rather than an “error”, that is really telling us that we should assign zero likelihood to that set of parameters, which is equivalent to a log-likelihood of \\(-\\infty\\).\nWe can do that kind of check in R by putting the WienerPDF function call within try(). If the WienerPDF function gives an error, then the result that gets stored in trial_wiener is also an error. Otherwise, it just gives us the log-likelihoods that we want.\nLet’s set up an “if…else” structure to do this check:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- try(WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    ))\n    \n    # 3. Return final result\n    if (class(result) == \"try-error\") {\n        return(Inf)\n    } else {\n        return(-sum(result$logvalue))\n    }\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#a-worked-example",
    "href": "ebrw.html#a-worked-example",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.4 A worked example",
    "text": "2.4 A worked example\nThis example uses a single participant’s data from Experiment 2 of Gillespie & Cox (2024). In this experiment, each participant made similarity ratings between all pairs of eight items. Each item was an “auditory texture” constructed via Fourier synthesis. We applied Multidimensional Scaling to the similarity ratings from each participant to assign, for each participant, a set of coordinates to each item. The coordinates are such that items that are farther from one another were associated with lower similarity ratings and those that were closer to one another were assigned higher similarity ratings. Be sure to check out the paper itself for additional detail on how this was done, and how we decided that the multidimensional space in which the stimuli are represented had 3 dimensions. These coordinates will be used for the stim_coords argument of the ebrw_nll function.\nIn addition to providing similarity ratings, each participant engaged in a recognition memory task. On each trial of this task, the participant heard two auditory textures, presented sequentially. They then heard a “probe” sound and had to decide whether or not it was one of the two sounds that had just been presented. It is these recognition data that we will model with the EBRW.\nYou can grab the data yourself by running the following chunk of code to download it and load it into your R workspace:\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/ebrw_example_data.rdata\", \"blast_data.rdata\")\nload(\"ebrw_example_data.rdata\")\n\n\n\n2.4.1 Check out the data\nThe stimulus coordinates are saved in a matrix called stim_coords:\n\n\nCode\nprint(stim_coords)\n\n\n           [,1]         [,2]        [,3]\n[1,] -0.4679162 -0.463219039 -0.08056499\n[2,] -0.5549266  0.499390636  0.07099460\n[3,] -0.4742833 -0.132020672  0.43312165\n[4,] -0.5062581  0.005578674 -0.40175331\n[5,]  0.5110397 -0.222844222 -0.30381582\n[6,]  0.4578305  0.336495895 -0.27302187\n[7,]  0.5669455 -0.288366241  0.24624698\n[8,]  0.4675684  0.264984969  0.30879277\n\n\nWe can visualize them using plot_ly:\n\n\nCode\nto_plot &lt;- as.data.frame(stim_coords)\ncolnames(to_plot) &lt;- paste(\"Dimension\", 1:ncol(stim_coords))\nrownames(to_plot) &lt;- paste(\"Item\", 1:nrow(stim_coords))\n\nplot_ly(data = to_plot, x = ~ `Dimension 1`, y = ~ `Dimension 2`, z = ~ `Dimension 3`, type = \"scatter3d\", text = rownames(to_plot))\n\n\nNo scatter3d mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nIn addition for each trial of the recognition task, the study_items matrix tells us which of the two items had been presented as part of the set to be remembered and the probe_item vector tells us what the probe item was. These numbers refer to row in the stim_coords matrix.\n\n\nCode\nprint(study_items)\n\n\n      [,1] [,2]\n [1,]    3    5\n [2,]    3    6\n [3,]    8    1\n [4,]    1    7\n [5,]    2    4\n [6,]    7    2\n [7,]    6    7\n [8,]    8    3\n [9,]    3    4\n[10,]    5    6\n[11,]    6    8\n[12,]    1    4\n[13,]    4    8\n[14,]    7    4\n[15,]    6    1\n[16,]    1    3\n[17,]    1    2\n[18,]    3    2\n[19,]    6    4\n[20,]    8    2\n[21,]    3    7\n[22,]    4    5\n[23,]    5    2\n[24,]    1    5\n[25,]    7    8\n[26,]    2    6\n[27,]    7    5\n[28,]    5    8\n\n\nCode\nprint(probe_item)\n\n\n [1] 4 2 1 7 2 7 7 2 6 6 6 1 3 4 4 3 8 3 8 4 7 8 4 2 6 2 3 5\n\n\nFinally, the rt and response vectors record the response time (in seconds) and the response (where 2 is “yes” and 1 is “no”) produced by this participant on each trial.\n\n\n2.4.2 Finding optimal parameters\nThe version of the EBRW that we applied in our paper is a bit more complex than the one we will use here, which only has six free parameters. We will use R’s built-in nlminb function to find the best-fitting values of these parameters. To do this, we need to specify initial values for each parameter in a named vector, as shown below. These initial values don’t necessarily need to be anything in particular as long as they don’t cause the ebrw_nll function to return an error or a value of Inf.\n\n\nCode\ninit_par &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\nWe also need to specify the upper and lower values that each of these parameters could possibly take, as shown below:\n\n\nCode\nlower &lt;- c(\n    \"retrieval_rate\" = 0,     # This is the \"nu\" parameter\n    \"a\" = 0,                  # Response caution\n    \"w\" = 0,                  # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 0,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 0           # Criterion (the \"kappa\" parameter)\n)\n\nupper &lt;- c(\n    \"retrieval_rate\" = Inf,     # This is the \"nu\" parameter\n    \"a\" = Inf,                  # Response caution\n    \"w\" = 1,                    # Response bias\n    \"t0\" = min(rt),             # Residual time\n    \"specificity\" = Inf,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = Inf           # Criterion (the \"kappa\" parameter)\n)\n\n\nNote that these upper and lower values can be Infinite if necessary!\nFinally, let’s use the nlminb function, which we need to provide with each of the ingredients we prepared above. We will save the result as fit:\n\n\nCode\nfit &lt;- nlminb(\n    start = init_par,          # Need to provide initial guess of parameter values\n    objective = ebrw_nll,      # Tell R the name of the function to optimize\n    lower = lower,             # The lower bounds on each parameter\n    upper = upper,             # The upper bounds on each parameter\n    stim_coords = stim_coords, # The coordinates of each stimulus\n    rt = rt,                   # The vector of RT's on each trial\n    response = response,       # The vector of responses on each trial\n    study_items = study_items, # The study items on each trial\n    probe_item = probe_item    # The probe item on each trial\n)\n\n\nWarning in nlminb(start = init_par, objective = ebrw_nll, lower = lower, :\nNA/NaN function evaluation\n\n\nAnd the final result!\n\n\nCode\nfit\n\n\n$par\nretrieval_rate              a              w             t0    specificity \n     1.2474191      2.1459586      0.4488126      0.6884095      5.6470633 \n     criterion \n     0.1035233 \n\n$objective\n[1] 21.59716\n\n$convergence\n[1] 0\n\n$iterations\n[1] 35\n\n$evaluations\nfunction gradient \n      56      243 \n\n$message\n[1] \"relative convergence (4)\"\n\n\nThe beauty of this result is that we have explained why this participant did what they did in terms of\n\nTheir internal representations of the stimuli, modeled as coordinates in a latent psychological space.\nA decision process that involves continuously sampling exemplars from memory until a criterion is reached.\n\n\n\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for novel auditory stimuli: Similarity, serial position, and list homogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models. Annual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An exemplar-familiarity model predicts short-term and long-term probe recognition across diverse forms of memory search. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011). Short-term memory scanning viewed as exemplar-based categorization. Psychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random walk model of speeded classification. Psychological Review, 104(2), 266–300.\n\n\nShepard, R. N. (1962a). The analysis of proximities: Multidimensional scaling with an unknown distance function. I. Psychometrika, 27(2), 125–140. https://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities: Multidimensional scaling with an unknown distance function. II. Psychometrika, 27(3), 219–246. https://doi.org/https://doi.org/10.1007/BF02289621",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "r_coding.html",
    "href": "r_coding.html",
    "title": "3  Programming with R",
    "section": "",
    "text": "3.1 Tips and strategies",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#tips-and-strategies",
    "href": "r_coding.html#tips-and-strategies",
    "title": "3  Programming with R",
    "section": "",
    "text": "When trying to write code to accomplish a particular task—or when trying to understand code written by someone else—try to break the task into individual steps that are accomplished in sequence in order to yield the final result.\nIf you are unsure what a particular bit of code will do—for example, if you want to figure out how to code one of the steps you’ve identified above—try to construct a minimal working example. This example should be simple enough that you can figure out what the result should be without doing any code. Then you can try out the code and verify whether the result matches what you expected.\nR supports vectorization of many operations. While vectorization allows for code to run more efficiently, the resulting code can sometimes be harder to understand and debug. As a result, you may want to write a less efficient but easier to read version of your code first, so that you can verify that it works the way you expect. You can then see where you might want to try to make your code more efficient, using your original easy-to-read code to verify that any changes you make don’t alter the expected result.\nUsing named vectors/matrices/arrays can often be quite handy when you want to index values by using a string that describes their meaning or interpretation, rather than a numerical index. Not only can this make your code more interpretable, it avoids issues when you may not know ahead of time which numerical index contains a particular desired value.\nR has a tendency to recycle things in ways you may not expect! For example, when doing any operation involving multiple vectors, if one vector is shorter than the other, R will sometimes “recycle” the elements of the shorter vector to create a new vector that is the same length as the longer one. The rules that govern how R “recycles” are not consistently applied and can be hard to predict, therefore it is important to ensure that your code will not produce this kind of ambiguous situation. You may want to include error checks to ensure that vectors are the same length. Alternatively, if you want to recycle, you can do so explicitly so there is no ambiguity (e.g., x_recycled &lt;- rep(x, length(y))[1:length(y)]).\nAlways remember the drop option when subsetting an array, matrix, or data frame! If the subsetting procedure selects only a single element, unless you use drop = FALSE, the result will be a length-one vector that “throws out” the other dimensions of your data structure. This can result in bugs if your code assumes that the result of the subset will have a consistent number of dimensions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#exercise-fibonnacci",
    "href": "r_coding.html#exercise-fibonnacci",
    "title": "3  Programming with R",
    "section": "3.2 Exercise: Fibonnacci",
    "text": "3.2 Exercise: Fibonnacci\nThe following set of R coding exercises are meant to prepare you for the kind of coding that will be involved in writing our first cognitive model simulations. It is not exhaustive of all the things that you can do with R, but it addresses many of the essentials.\nThese exercises are based on everyone’s favorite sequence, the Fibonnacci sequence. The sequence is defined by a simple rule: the next value in the sequence is the sum of the previous two values. Written in Math, that’s: \\[\nf[i] = f[i - 2] + f[i - 1]\n\\] where \\(f[\\cdot]\\) is a value in the Fibonnacci sequence and \\(i\\) is the index of the next value. To get this sequence going, we need to know the first two values, \\(f[1]\\) and \\(f[2]\\). Typically, these are both set to 1. As a result, the beginning of the Fibonnacci sequence goes like this: \\[\n1, 1, 2, 3, 5, 8, 13, \\ldots\n\\]\nAnyway, let’s begin!\n\n3.2.1 Exercise 1\nWrite two versions of a chunk of code that will create a vector called fib that contains the first 20 values in the Fibonnacci sequence. Assume that the first two values in the sequence are 1 and 1. Write one version of the code that creates the vector by appending each new value to the end of fib. Write another version that assigns values to the corresponding entries in fib directly using the appropriate index (for this second version, you may want to use the rep function to create the fib vector).\n\n\n3.2.2 Exericse 2\nBased on the code you wrote for the previous exercise, write a function that returns a vector containing the first N terms of the Fibonnacci sequence. Your function should take two arguments, the value N and a vector called init that contains the first two values in the sequence. Give those arguments sensible default values. The chunk below gives a sense of the overall structure your function should have:\n\n\nCode\nfib_func &lt;- function(N = ___, init = ___) {\n    ...\n    return(fib)\n}\n\n\n\n\n3.2.3 Exercise 3\nWrite code that calls the function you wrote in the previous exercise several times, each time using a different value for the second value in the init argument (but the same value for N and for init[1]). Collect the results from each function call in a single data frame or tibble. The data frame or tibble should have a column that stores the second initial value, a column for the vector returned from the function, and a third column that is the value’s index within the sequence. An example of the kind of result you’re looking for is given below:\n\n\n# A tibble: 8 × 3\n  init2   fib     i\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     1     1     1\n2     1     1     2\n3     1     2     3\n4     1     3     4\n5     4     1     1\n6     4     4     2\n7     4     5     3\n8     4     9     4\n\n\n\n\n3.2.4 Exercise 4\nWrite code that uses the ggplot2 library to plot the values of the Fibonnacci sequence on the y-axis against their position in the sequence on the x-axis. Distinguish between different init2 values by using different colored lines. The result should look something like the plot below.\n\n\n\n\n\n\n\n\n\n\n\n3.2.5 Extension exercise\nWrite a new function that takes a third argument, n_back, which specifies how many of the previous values to add up to create the next value in the sequence. For the Fibonnacci sequence, n_back = 2, but in principle we could define other kinds of sequences too. Adapt the code you wrote for your previous exercises to explore what happens with different values of n_back. You may also want to include some code at the beginning of your function that checks to ensure that the number of initial values provided in the init argument is sufficient!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Broadbent, D. E. (1957). A mechanical model for human attention and\nimmediate memory. Psychological Review, 64(3),\n205–215.\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event\nmemory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of\nhuman memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and\nBrain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for\nnovel auditory stimuli: Similarity, serial position, and list\nhomogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nNeisser, U. (1967). Cognitive psychology.\nAppleton-Century-Crofts.\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the\nidentification-categorization relationship. Journal of Experimental\nPsychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models.\nAnnual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An\nexemplar-familiarity model predicts short-term and long-term probe\nrecognition across diverse forms of memory search. Journal of\nExperimental Psychology: Learning, Memory, and Cognition,\n40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011).\nShort-term memory scanning viewed as exemplar-based categorization.\nPsychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random\nwalk model of speeded classification. Psychological Review,\n104(2), 266–300.\n\n\nShepard, R. N. (1962a). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nI. Psychometrika, 27(2), 125–140.\nhttps://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nII. Psychometrika, 27(3), 219–246.\nhttps://doi.org/https://doi.org/10.1007/BF02289621\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober,\nC. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D.,\nNavarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service\nof science: Don’t let the tail wag the dog. Computational Brain\n& Behavior.",
    "crumbs": [
      "References"
    ]
  }
]
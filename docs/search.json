[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Cognitive Models",
    "section": "",
    "text": "Preface\nThis is a collection of notes and materials for an introductory course in computational cognitive modeling. It will be updated and, arguably, improved over the course of the semester.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Some functions of models\nAs Cox & Shiffrin (2024) describe, a computational cognitive model falls on the “causal” end of the spectrum in the graph shown at the top. They enumerate a couple of goals that such a model might serve:",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#some-functions-of-models",
    "href": "intro.html#some-functions-of-models",
    "title": "1  Introduction",
    "section": "",
    "text": "All models are wrong, but causal models are useful when they capture and approximate the causal processes at work and when they generalize to other settings. When modeling complex human behavior, all the models are at best crude approximations to reality, but nonetheless they can prove useful by describing the processes that are most important for explaining behavior.\nModeling allows precise communication among scientists. When theories and hypotheses are proposed verbally and heuristically, their precise meaning is not generally known even to the proposers, and they are often misinterpreted and misunderstood by others. When theoretical constructs are clearly linked to elements of a model and the internal workings of the model are described with mathematical or computational precision (e.g., by including the code running the model simulation), other scientists can use, generalize, and test the model because its application in at least its original domain is well specified.\nModels make clear the links between assumptions and predictions. Different investigators cannot dispute the predictions of the model that are produced by a given set of parameters (the parameters generally index different quantitative variants of a given class of models).\nThe formal specification of the model clarifies the nature of proposed internal cognitive processes. A poor modeler may fail to demonstrate that linkage. A good modeler will explore the parameter space and show how the parameter values change the predictions and how narrow or broad a range of outcomes can be predicted by changes in the parameter values. A good modeler will also explore alterations in the model, perhaps by deleting some processes or by adding others, or by fixing some parameter values at certain values, thus providing diagnostic information about the qualitative features of the outcome space that are primarily due to a process controlled by particular parameters. A bad modeler might claim a fit to data provides support for an underlying causal theory when in fact the fit is primarily due to some parameter or theory not conceptually related to the claim.\nConstructing a model can act as an “intuition pump” (cf. Dennett, 1980). Many modelers try to infer underlying cognitive processes from complex data sets that involve multiple measures (e.g., accuracy and response time) and many conditions which may be difficult or impossible to summarize adequately. Modelers form hypotheses about the processes involved based on the data and their prior knowledge. It is often the case that intuiting predictions for different combinations of processes is not possible due to the limitations of human cognition. Thus, different combinations of processes are instantiated as formal models, enabling a modeler to observe and test the predictions of their hypotheses. In an iterative model building process, the failures in each iteration indicate the way forward to an appropriate account.\nModeling allows different hypothesis classes to be compared, both because the predictions of each are well specified and because model comparison techniques take into account model complexity. The issue of complexity is itself quite complex.\n\nOne issue is due to statistical noise produced by limited data. A flexible model with many parameters can produce what seems to be a good fit with parameter values that explain the noise in the data rather than the underlying processes. The best model comparison techniques penalize models appropriately for extra complexity. However, models are in most cases developed after observing the data, and they are used to explain the patterns observed. To do so, they often incorporate assumptions that are critical but not explicitly parameterized. It thus becomes a difficult and subtle matter to assess complexity adequately. A secondary problem with using fit to compare models is the fact that the most principled ways to control for complexity, such as Bayesian model selection and minimum description length, are difficult to implement computationally and are often replaced by approximations such as the Akaike or Bayes/Schwartz information criteria that often fail to account for key aspects of model complexity.\nSimpler models are also favored for other reasons. A chief one is limited human reasoning: As a model becomes more complex, it becomes more difficult for a human to understand how it works. Simpler models are also favored when analytic predictions can be derived (thereby greatly reducing computational costs) and for qualitative reasons such as “elegance”.\nSimpler models are particularly favored when their core processes generalize well across many tasks.\nThere exists a danger that the modeler will mistake small quantitative differences in “fit” for the important differences among models—differences that generally lie in qualitative patterns of predictions. Knowing one model provides a better fit to a limited set of observations from a narrow experimental setting is not often useful. For example, consider a model that correctly predicts the relative levels of recall accuracy observed across conditions in a given experiment but quantitatively overpredicts the accuracy in a single condition. Meanwhile, another model perfectly predicts the accuracy in that condition but fails to predict the right qualitative pattern of accuracy across conditions. We argue that the qualitatively correct prediction is a reason to favor the first model, even though it might yield a worse quantitative fit. Correct qualitative predictions across conditions are often a sign that a model captures an important and generalizable causal process.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-simulation",
    "href": "intro.html#the-importance-of-simulation",
    "title": "1  Introduction",
    "section": "1.2 The importance of simulation",
    "text": "1.2 The importance of simulation\nThe models that we will be covering are models that simulate behavioral (and maybe even neural) outcomes. Because we are building models of a complex system—namely, the mind—our models can also become complex. Therefore, understanding what kind of behavior a model produces may require us to simulate behavior from that model. This will also help us to understand the relationship between the model’s parameters and its behavior. By simulating how behavior changes as one or more parameters change, we can understand the role played by the theoretical construct represented by that parameter.\nFor example, we might have a parameter that represents the quality or precision with which an event is stored in memory. In a model where this memory representation is used to yield behavior, we can systematically adjust the value of the quality/precision parameter and observe the effect this has on the model’s simulated behavior. Again, because we are dealing with models that can grow quite complex, we may even be surprised by the behavior the model produces!\nTwo analogies may help give some intuition about the value of simulation: If we are cooking, often the only way to know how a particular combination of spices will taste is to actually combine them and taste. Model parameters are like the different amounts of each spice, with the final taste being analogous to the model’s simulated behavior. Alternatively, you can think of model parameters as being like characters in an improv sketch. The characters have different backgrounds and goals which dictate how they will interact and how the story will develop. The background and goals of the characters are like the parameters of a model, with the resulting performance analogous to the model’s predicted behavior.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-fitting-data",
    "href": "intro.html#the-importance-of-fitting-data",
    "title": "1  Introduction",
    "section": "1.3 The importance of fitting data",
    "text": "1.3 The importance of fitting data\n“Fitting” a model to data means finding the combination of parameter values for which the model produces behavior that most closely resembles that produced by a participant in some task. The value of doing this is that it helps us understand why that participant acted the way they did.\nFor example, we might want to know whether someone was fast because they were able to quickly accumulate the evidence they needed, because they were uncautious, because they were biased, or because they could execute motor actions quickly. We can address that question by finding the values of the parameters associated with each construct that best fit their observed performance.\n\n\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and immediate memory. Psychological Review, 64(3), 205–215.\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event memory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of human memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and Brain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nNeisser, U. (1967). Cognitive psychology. Appleton-Century-Crofts.\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober, C. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D., Navarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service of science: Don’t let the tail wag the dog. Computational Brain & Behavior.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "r_coding.html",
    "href": "r_coding.html",
    "title": "2  Programming with R",
    "section": "",
    "text": "2.1 Tips and strategies",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#tips-and-strategies",
    "href": "r_coding.html#tips-and-strategies",
    "title": "2  Programming with R",
    "section": "",
    "text": "When trying to write code to accomplish a particular task—or when trying to understand code written by someone else—try to break the task into individual steps that are accomplished in sequence in order to yield the final result.\nIf you are unsure what a particular bit of code will do—for example, if you want to figure out how to code one of the steps you’ve identified above—try to construct a minimal working example. This example should be simple enough that you can figure out what the result should be without doing any code. Then you can try out the code and verify whether the result matches what you expected.\nThe same principles that underlie producing good code also underlie debugging code. This is covered well in the corresponding chapter of Wickham’s Advanced R book, but essentially debugging involves (a) isolating where the problem arises; (b) understanding the conditions that resulted in the problem; (c) revising the code in an attempt to correct the problem or to prevent problematic circumstances from arising; and (d) testing to ensure the solution in fact addresses the problem. Working on small bits of code at a time makes all of the essential steps of debugging easier.\nR supports vectorization of many operations. While vectorization allows for code to run more efficiently, the resulting code can sometimes be harder to understand and debug. As a result, you may want to write a less efficient but easier to read version of your code first, so that you can verify that it works the way you expect. You can then see where you might want to try to make your code more efficient, using your original easy-to-read code to verify that any changes you make don’t alter the expected result.\nUsing named vectors/matrices/arrays can often be quite handy when you want to index values by using a string that describes their meaning or interpretation, rather than a numerical index. Not only can this make your code more interpretable, it avoids issues when you may not know ahead of time which numerical index contains a particular desired value.\nR has a tendency to recycle things in ways you may not expect! For example, when doing any operation involving multiple vectors, if one vector is shorter than the other, R will sometimes “recycle” the elements of the shorter vector to create a new vector that is the same length as the longer one. The rules that govern how R “recycles” are not consistently applied and can be hard to predict, therefore it is important to ensure that your code will not produce this kind of ambiguous situation. You may want to include error checks to ensure that vectors are the same length. Alternatively, if you want to recycle, you can do so explicitly so there is no ambiguity (e.g., x_recycled &lt;- rep(x, length(y))[1:length(y)]).\nAlways remember the drop option when subsetting an array, matrix, or data frame! If the subsetting procedure selects only a single element, unless you use drop = FALSE, the result will be a length-one vector that “throws out” the other dimensions of your data structure. This can result in bugs if your code assumes that the result of the subset will have a consistent number of dimensions.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#exercise-fibonnacci",
    "href": "r_coding.html#exercise-fibonnacci",
    "title": "2  Programming with R",
    "section": "2.2 Exercise: Fibonnacci",
    "text": "2.2 Exercise: Fibonnacci\nThe following set of R coding exercises are meant to prepare you for the kind of coding that will be involved in writing our first cognitive model simulations. It is not exhaustive of all the things that you can do with R, but it addresses many of the essentials. It also exemplifies the workflow involved in building a model:\n\nImplement the basic processes involved in a simple case where you know what the correct result should be, so you can ensure you have implemented these basics appropriately.\nBuild a function that generalizes the code you wrote in step 1 so that you can apply it to different parameter settings.\nUse your function to simulate different results using different parameter settings.\nExplore the range of results your function produces across parameter settings.\nOptionally, consider ways that you can generalize your model even further by incorporating additional parameters.\n\nThese exercises are based on everyone’s favorite sequence, the Fibonnacci sequence. The sequence is defined by a simple rule: the next value in the sequence is the sum of the previous two values. Written in Math, that’s: \\[\nf[i] = f[i - 2] + f[i - 1]\n\\] where \\(f[\\cdot]\\) is a value in the Fibonnacci sequence and \\(i\\) is the index of the next value. To get this sequence going, we need to know the first two values, \\(f[1]\\) and \\(f[2]\\). Typically, these are both set to 1. As a result, the beginning of the Fibonnacci sequence goes like this: \\[\n1, 1, 2, 3, 5, 8, 13, \\ldots\n\\]\nAnyway, let’s begin!\n\n2.2.1 Exercise 1\nWrite two versions of a chunk of code that will create a vector called fib that contains the first 20 values in the Fibonnacci sequence. Assume that the first two values in the sequence are 1 and 1. Write one version of the code that creates the vector by appending each new value to the end of fib. Write another version that assigns values to the corresponding entries in fib directly using the appropriate index (for this second version, you may want to use the rep function to create the fib vector).\n\n\n2.2.2 Exericse 2\nBased on the code you wrote for the previous exercise, write a function that returns a vector containing the first N terms of the Fibonnacci sequence. Your function should take two arguments, the value N and a vector called init that contains the first two values in the sequence. Give those arguments sensible default values. The chunk below gives a sense of the overall structure your function should have:\n\n\nCode\nfib_func &lt;- function(N = ___, init = ___) {\n    ...\n    return(fib)\n}\n\n\n\n\n2.2.3 Exercise 3\nWrite code that calls the function you wrote in the previous exercise several times, each time using a different value for the second value in the init argument (but the same value for N and for init[1]). Collect the results from each function call in a single data frame or tibble. The data frame or tibble should have a column that stores the second initial value, a column for the vector returned from the function, and a third column that is the value’s index within the sequence. An example of the kind of result you’re looking for is given below:\n\n\n# A tibble: 8 × 3\n  init2   fib     i\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     1     1     1\n2     1     1     2\n3     1     2     3\n4     1     3     4\n5     4     1     1\n6     4     4     2\n7     4     5     3\n8     4     9     4\n\n\n\n\n2.2.4 Exercise 4\nWrite code that uses the ggplot2 library to plot the values of the Fibonnacci sequence on the y-axis against their position in the sequence on the x-axis. Distinguish between different init2 values by using different colored lines. The result should look something like the plot below.\n\n\n\n\n\n\n\n\n\n\n\n2.2.5 Extension exercise\nWrite a new function that takes a third argument, n_back, which specifies how many of the previous values to add up to create the next value in the sequence. For the Fibonnacci sequence, n_back = 2, but in principle we could define other kinds of sequences too. Adapt the code you wrote for your previous exercises to explore what happens with different values of n_back. You may also want to include some code at the beginning of your function that checks to ensure that the number of initial values provided in the init argument is sufficient!",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "random_walk.html",
    "href": "random_walk.html",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "3.1 Out for a random walk\nThe random walk model is designed to account for two aspects of behavior: choice and response time (RT). These and similar models are applied in situations where a person (or other organism!) has to decide between a small number of possible alternatives, often just two. Such situations abound in experimental psychology, including lexical decision, recognition memory, detection tasks, search tasks, categorization tasks, etc. The models are designed to help us understand two things:",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#out-for-a-random-walk",
    "href": "random_walk.html#out-for-a-random-walk",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "Why did a participant make the choices they made?\nWhy did it take the participant a certain amount of time to make the choices they made?\n\n\n3.1.1 Key theoretical constructs\nThe vast majority of models of choice and RT, including random walk and diffusion models, address the two questions above by invoking four basic theoretical constructs:\nEvidence accumulation: Choosing from among a set of options is assumed to require accumulating “evidence” that weighs either in favor of or against each option. This evidence may come from perception (e.g., deciding which of two stimuli is brighter), from memory (e.g., deciding whether an item was or was not on a previously-studied list), or from deliberation (e.g., deciding which of two products to buy). As such, the idea that decisions are made by accumulating evidence helps explain not only which choice was made (it was the option that was most favored by the accumulated evidence) and how long it took to made the choice (the time needed to accumulate sufficient evidence to commit to a decision).\nResponse caution: If decisions are made by accumulating evidence, there must be a policy that terminates the accumulation process, otherwise someone would keep accumulating evidence forever—and this is exactly what Buridan’s ass needs to avoid! The construct of “response caution” refers to the idea that, depending on the situation, a decision maker may adopt a policy of deciding quickly on the basis of very little evidence (low response caution) or deciding slowly by waiting for more evidence to accumulate (high response caution). Thus, this construct is directly related to the idea of speed-accuracy trade-off.\nResponse bias: It may be that a decision maker is willing to commit to some options more readily than others; in that case, we say they are “biased” in favor of those responses. Typically, this bias is modeled by assuming lower response caution for some options than others. In other words, a participant may be willing to commit to some decisions on the basis of less accumulated evidence than others.\nResidual time: The time needed to accumulate sufficient evidence to make a decision is not the only thing that contributes to observed response times. After all, it takes time to realize that a trial of a task has actually begun. It may also take time to retrieve relevant information from memory, to focus attention on relevant features in the environment, or to evaluate a potential outcome. Finally, it takes some time to execute the motor actions associated with the chosen option (e.g., to press a button, move a lever, etc.). The time for all of these additional processes is often called non-decision time (NDT) or encoding and response execution time (\\(T_{ER}\\)). However, I prefer to call it simply “residual time” because that is what it is—it is the time “left over” besides the time needed for evidence accumulation.\n\n\n3.1.2 Representing the current state of evidence\nThe random walk model assumes that, at any given time, a decision maker represents the current balance of evidence between two options as a number. We will creatively refer to this representation as \\(x(t)\\), where \\(x\\) stands for evidence and \\((t)\\) stands for the fact that it is the evidence at a specific time \\(t\\). The sign and magnitude of \\(x(t)\\) represents the extent to which the current value of evidence favors one option over the other.\nIf \\(x(t)\\) equals zero, then the evidence at time \\(t\\) does not favor either option. This is akin to the situation when Buridan’s ass first encounters the two piles of hay. If \\(x(t) &gt; 0\\), then the evidence favors one of the two options. For Buridan’s ass, perhaps positive values of evidence represent evidence in favor of going toward the pile of hay on the right. If \\(x(t) &lt; 0\\), then the evidence favors the other option. For Buridan’s ass, maybe negative values of evidence represent evidence in favor of going toward the pile of hay on the left. Notice that we could just as easily do it the other way around: positive evidence favors going left while negative evidence favors going right. The important thing is just that the two options are associated with opposite signs of evidence.\nIn a cognitive task, the two choices might be “word” and “non-word” in a lexical decision task, “old” and “new” in a recognition memory task, “present” and “absent” in a visual search task, “same” and “different” in a change detection task, “category A” and “category B” in a categorization task, etc. Again, the point is that, at any given time, the degree to which the decision maker’s accumulated evidence at time \\(t\\) favors one option or the other is represented by the value of a number \\(x(t)\\), with each option associated with opposite signs.\n\n\n3.1.3 Accumulating evidence\nThe value of \\(x(t)\\) represents the evidence that has been accumulated by time \\(t\\). But what does it mean to “accumulate” evidence? And what is the “evidence” that is accumulated?\nIn a random walk model, we assume that at regular time intervals (each interval has duration \\(\\Delta t\\)), the decision maker receives a “sample” of evidence, which we will label \\(\\Delta x(t)\\). This sample can take one of two values, \\(+1\\) or \\(-1\\). If it is \\(+1\\), the sample favors the option associated with positive evidence values (e.g., the pile of hay on the right) and if it is \\(-1\\), the sample favors the option associated with negative evidence values (e.g., the pile of hay on the left). To accumulate evidence means to add the new sample \\(\\Delta x(t)\\) to the current value of the accumulated evidence, i.e.: \\[\n\\overbrace{x(t + \\Delta t)}^{\\text{Updated evidence}} = \\overbrace{x(t)}^{\\text{Current accumulated evidence}} + \\overbrace{\\Delta x(t)}^{\\text{Current sample of evidence}}\n\\] Thus, the accumulated evidence \\(x(t)\\) is the sum of all the samples of evidence that were obtained by time \\(t\\).\n\n\n3.1.4 What is evidence?\nAt this point, it would be reasonable to ask where these samples of evidence come from. There is no single answer to this question because the random walk model, like most of the models of choice and RT we will consider, treats evidence in a very abstract sense. Later in the course, we will encounter models that instantiate specific theories of the “evidence” a decision maker may use in a specific context.\nTo return to Buridan’s ass, the evidence might be perceptual in nature: For an interval of time, the donkey looks at both piles of hay. Even though both piles are, by assumption, equally big, that may not always be visually apparent. During any finite interval of time, one pile might happen to look ever so slightly larger than the other, perhaps due to a quirk of the light, a sheaf fluttering in the breeze, the donkey’s visual acuity, etc. If the pile on the right happened to look a bit bigger than the one on the left during one of those intervals, then the sample of evidence for that interval would be \\(+1\\). Otherwise, it would be \\(-1\\). Because these minute differences are due to essentially chance factors, and they are equally likely to favor either pile, we can say that the probability of getting a sample that is either \\(+1\\) or \\(-1\\) is \\(0.5\\). While the evidence might not favor one pile over the other in the long run, it will favor one option over a finite interval of time, which is all any real decision maker has at their disposal. As we shall see shortly, this is the key to saving Buridan’s ass.\nTreating evidence as due, at least in part, to chance factors is why this model is called a “random” walk. It also highlights the fact that the evidence samples need not occur with equal frequency. Perhaps samples come up \\(+1\\) with probability \\(p\\) and otherwise come up \\(-1\\), like the proverbial biased coin flip. If the evidence consistently favors one option, that means that \\(p\\) is close to either 1 or 0. To the extent that chance factors influence the evidence, \\(p\\) will be closer to \\(0.5\\). We have now been introduced to the first parameter of the random walk model: \\(p\\), the probability of getting a sample of evidence that favors the option associated with positive evidence.\nThe figure below illustrates different ways that evidence might accumulate over time. Each step up or down is driven by the sample of evidence that was obtained at that time, which is assumed to be random with probability \\(p\\). The figure also illustrates why this model is called a random “walk”, because each trajectory kind of looks like a path that someone might have walked.\n\n\nCode\nexpand_grid(p = c(0.2, 0.5, 0.8), sim_index = 1:5, t = 1:20) %&gt;%\n    mutate(x_sample = 2 * rbinom(n = n(), size = 1, prob = p) - 1) %&gt;%\n    group_by(p, sim_index) %&gt;%\n    mutate(x_accum = cumsum(x_sample)) %&gt;%\n    ggplot(aes(x = t, y = x_accum, color = factor(p), group = interaction(p, sim_index))) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_step(alpha = 0.5) +\n    labs(x = \"Time interval\", y = \"Accumulated evidence\", color = \"p\")\n\n\n\n\n\n\n\n\n\nWhat about evidence in cognitive tasks? Buridan’s ass relies on the same kind of sensory evidence as one needs to do, for example, psychophysical tasks like picking which stimulus is brighter, more leftward-oriented, etc. Evidence derived from memory can also be noisy—perhaps when retrieving an event, you sometimes recall the color of an object as blue and sometimes as green. When deciding between different gambles or products, we may also shift attention to different features of those options, leading us to judge them as better or worse depending on which features we attend to (Busemeyer & Townsend, 1993; Diederich, 1997).\n\n\n3.1.5 Doing some code\nHaving now familiarized ourselves with how the random walk model represents a decision maker’s evidence and how it processes that evidence via accumulation, let’s see how we would write that model in code. Specifically, we will be writing code that simulates different possible random walks. The way we will do this is more of an intellectual exercise, since we will not be striving for efficiency (later on, we will use special-purposes R packages for that). Rather, the point here is to see how the conceptual aspects of a model can be implemented in code. We will add on to this code as we go.\nFor now, we know that we will have a line that looks something like the accumulation equation above:\n\n\nCode\nx &lt;- x + x_sample\n\n\nHere, x stands for the value of the accumulated evidence and x_sample stands for the current sample of evidence (which is either 1 or -1). The &lt;- evaluates the expression on the right and assigns it to the thing on the left, so the code above says “take the current value of x, add the new sample x_sample, and put it back as the new value of x”.\nWith the code above as the core of the model, we now need to do three things: first, specify how to get x_sample; second, obtain many such samples; third, keep a record of how the accumulated evidence changes over time.\n\n3.1.5.1 Sampling evidence\nTo get a value for x_sample, we will use R’s rbinom function, which generates a random sample from a binomial distribution. Specifically, the line rbinom(n = 1, size = 1, prob = 0.5) will generate a sample that equals 1 with probability 0.5, otherwise it equals zero. It is perhaps easiest to think of it in terms of a coin flip: The n parameter of the rbinom function says how many sets of coins to flip, size says how many coins we flip in each set, and prob is the probability that any single flip comes up heads. The number that rbinom gives is the number of heads in a particular set of flips.\nFor Buridan’s ass, the sample of evidence favors each pile equally often, so prob = 0.5 makes sense. Note that because rbinom returns either a 0 or a 1, we need to do some math to turn the result into \\(+1\\) or \\(-1\\). This is shown below.\n\n\nCode\nx_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\nx &lt;- x + x_sample\n\n\n\n\n3.1.5.2 Obtaining many samples\nThere are a few ways we can write code that will obtain many samples. To anticipate what we will be doing later, we will use the while control structure. We can use it to specify a condition such that, so long as the condition is met, a block of code will continue to be executed in a loop.\nOur condition will depend on the current time. Remember that, in the random walk, each sample of evidence arrives at fixed intervals of time. We will therefore need to keep track of the current time as well as the accumulated evidence. Similar to how we updated the evidence, we will need to keep track of t, the current time. We will also need to specify dt, the duration of each interval (otherwise known as \\(\\Delta t\\)), and t_max, the amount of time to keep accumulating evidence.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\nNotice that we specified values for t_max and dt outside the while loop. We can specify initial values for x and t the same way:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\n\n\n3.1.5.3 Keeping a record\nThe chunk of code above will work just fine! But unfortunately it does not leave a record of accumulated evidence over time that we can then examine, like we did with the graph above. In the chunk below, we use a fun trick to keep a record of each value of x and t: We create two vectors x_record and t_record and use the c function to concatenate the current values of x and t to these vectors:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\n\n\n\n3.1.5.4 Visualizing the record\nNow that we are keeping a record of evidence over time, let’s visualize it! The code below uses base R for that purpose, although the graph above uses ggplot2 which we will use again later. The type = \"s\" setting in the plot function at the end give the “step-like” plot.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\nplot(t_record, x_record, type = \"s\", xlab = \"Time\", ylab = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nTry copy-pasting the code above and running it yourself a few times to see what it looks like!\n\n\n3.1.5.5 Making a function\nIf we have a chunk of code that we want to re-run many times, we would do better to write a function that we can call instead of having to re-run the whole chunk. Writing a function also makes it easier to deal with parameters that can have different settings, like dt and t_max. We will also make the probability \\(p\\) a parameter too. Finally, the values for these three parameters in the function line are defaults.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, dt = 0.05, t_max = 5) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nNow we can call the function rw_sim with different settings to simulate different random walks. Note that, because the function returns t_record and x_record as different columns of a tibble, we can easily use ggplot2 to plot the results, as in the examples below.\n\n\nCode\nsim_result1 &lt;- rw_sim(p = 0.5, dt = 0.05, t_max = 5)\n\nsim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result2 &lt;- rw_sim(p = 0.2, dt = 0.05, t_max = 5)\n\nsim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.2\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result3 &lt;- rw_sim(p = 0.8, dt = 0.05, t_max = 5)\n\nsim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.8\")\n\n\n\n\n\n\n\n\n\nGo ahead, try it out yourself with different values of p, dt, and/or t_max. It’s fun! And if you don’t think the step graphs are too interesting, just imagine that each of those steps is Simon the donkey trying to decide between his two piles of hay.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#making-a-decision",
    "href": "random_walk.html#making-a-decision",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.2 Making a decision",
    "text": "3.2 Making a decision\nSo far, we have built a simple model of evidence accumulation. In this model, samples of “evidence” arrive at regular intervals, with the sample supporting either one option (\\(+1\\)) or the other (\\(-1\\)) with probability \\(p\\), and the decision maker accumulates these samples by summation. The resulting accumulated evidence thus starts at zero and takes a “random walk” that can drift upward (if \\(p &gt; 0.5\\)), downward (if \\(p &lt; 0.5\\)), or in no particular direction (if \\(p = 0.5\\)).\n\n3.2.1 Response boundaries\nWhat we have not done is say how the decision maker uses this accumulated evidence to decide between their two options. According to the random walk model, the decision maker sets two values prior to accumulating evidence. These values are called thresholds, criteria, or boundaries (these terms are often used interchangeably). There is one positive boundary and one negative boundary. If and when the accumulated evidence crosses one of these boundaries, the decision maker selects the corresponding option.\nFor example, say that Buridan’s ass will pick the pile on the right if his accumulated evidence ever gets greater than \\(+5\\) and he will pick the pile on the left if his accumulated evidence ever gets less than \\(-5\\). We can visualize this situation by overlaying lines at those two boundaries on the “random walk” of accumulating evidence:\n\n\nCode\nburidan_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nHere’s another one:\n\n\nCode\nburidan_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nGo ahead and try it out yourself!\nThe point is that we can read from these graphs which option the donkey ends up picking by seeing which boundary gets crossed first. We can also see when the donkey makes his decision based on how long it took for that first boundary-crossing to occur. This is how the random walk model ultimately produces both a choice (which boundary was crossed first) and an RT (how long it took). It is also why the random walk saves Buridan’s ass: Even if the evidence in the long run does not favor either option, by chance the accumulated evidence will at some point cross one of the boundaries, enabling the donkey to make a decision.\n\n\n3.2.2 Response bias\nIn the examples above, Buridan’s ass set his response boundaries to be of equal distance from the initial evidence value of zero. Burdian’s ass might be more willing to go to the leftward pile than the rightward one—maybe it is more aesthetically appealing or the donkey has a limp that makes it easier for him to walk left than right. This would amount to a bias in favor of one option (going left) over the other (going right).\nWe can instantiate this bias in the random walk model via the donkey’s response boundaries. For example, the donkey may go to the left if the accumulated evidence ever gets less than \\(-4\\) but would only be willing to go to the right if the accumulated evidence ever gets greater than \\(+6\\). The following two graphs illustrate these biased response boundaries.\n\n\nCode\nburidan_bias_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 1\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nburidan_bias_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 2\")\n\n\n\n\n\n\n\n\n\nIntuitively, it seems reasonable to expect that, if one boundary is closer to the start than the other, that two things will happen: First, the option associated with the closer boundary will be picked more often (at least if the evidence against that option is not too strong). Second, the decision maker will tend to be faster to pick the option associated with the closer boundary. We will verify these intuitions later, but for now you can rest assured that these intuitions are correct.\n\n\n3.2.3 Revising our function\nNow that we have gotten acquainted with the notion of response boundaries and how they can be biased, let’s incorporate them into our random walk simulation function from earlier. This will involve two things: First, we will need to add two parameters to the function, one for each boundary. Second, we will need to change the condition in the while loop so that the random walk stops when it reaches a boundary. As a corrollary to this second step, we will keep the t_max condition but adjust the default value of t_max.\nThe revised function is shown below, with some additional explanation following:\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nThe key changes we made to the rw_sim function are:\n\nAdding parameters b_upper and b_lower for the upper and lower response boundaries, respectively.\nChanging the default value of t_max to Inf for “infinity”. This means that, by default, reaching a boundary is the only way the random walk will stop. However, by leaving t_max as a parameter, it means that we can set it to some real number like 5 or 10 to force the random walk to stop eventually.\nChanging the condition in the while loop. Now the walk will continue so long as the evidence x is below the upper boundary (x &lt; b_upper) and above the lower boundary (x &gt; b_lower) and so long as the maximum time hasn’t been reached (t &lt; t_max). Note that the & is a “logical and” operator.\n\nHere are a few simulation runs—try it out yourself!\n\n\nCode\nboundary_sim_result1 &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5)\n\nboundary_sim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 5, b_lower = -5\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result2 &lt;- rw_sim(p = 0.5, b_upper = 6, b_lower = -4)\n\nboundary_sim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 6, b_lower = -4\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result3 &lt;- rw_sim(p = 0.7, b_upper = 6, b_lower = -4)\n\nboundary_sim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.7, b_upper = 6, b_lower = -4\")",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#residual-time",
    "href": "random_walk.html#residual-time",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.3 Residual time",
    "text": "3.3 Residual time\nWe are nearly done with our simulation model! We can model accumulating evidence and making a decision. The final ingredient arises from the fact that, while a decision maker might select one option at a particular time, we can only observe the behavioral consequences of that decision. Those behavioral consequences might be hitting a key, clicking a button, pressing a lever, or walking toward a pile of hay. Executing that behavior takes time in addition to the time needed to accumulate evidence and reach a response boundary. That additional time goes by many names, often “non-decision time” (NDT) or “encoding and responding” time (\\(T_{ER}\\)), but I prefer to simply call it residual time.\nFor now, we will adopt a simple assumption that this residual time is constant. Therefore, the observed response time will be the sum of the time needed for the random walk to reach a boundary plus the residual time associated with all the other processes that are involved in taking an action but which our model doesn’t explicitly enumerate.\nTo make this concrete, let’s introduce a parameter called t0 that will stand for residual time. While I cannot speak to what a plausible value of t0 would be for Buridan’s ass, in many cognitive tasks, it tends to be around 0.2 or 0.3 seconds, to account for the time needed to execute a simple motor action like hitting a button.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nNote that the main change to our rw_sim function is that the initial value for the time t is no longer 0 but t0, i.e., the value of the residual time parameter.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#simulating-many-trials",
    "href": "random_walk.html#simulating-many-trials",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.4 Simulating many trials",
    "text": "3.4 Simulating many trials\nOur rw_sim function can now simulate single realizations of a random walk decision process. As we have seen, though, each realization of this process is different because the samples of evidence are random. If we want to get a sense of the kind of behavior the model tends to produce, we need to simulate many realizations of the decision and examine the distribution of choices and RT’s produced by the model. This is the same reason why, in a typical cognitive task, we collect multiple trials from each participant in each condition. With a real participant, we are limited by the time and energy that a participant is willing to commit. With a model, we are still limited by time and energy, but they are our time and the computer’s energy. Nonetheless, it is worth keeping in mind that all the techniques below for visualizing choices and RT’s apply to observed data as well as they apply to simulated data.\n\n3.4.1 Running and saving many simulation results\nWe will need to write some code that repeatedly calls our rw_sim function a large number of times and saves the results so we can examine them later. What follows is not necessarily the most efficient way of accomplishing those goals, but it is conceptually transparent and introduces the for loop. The comments (following the # marks) explain what is going on with the line below.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Get a quick sense of what the results look like\nglimpse(sim_results)\n\n\nRows: 25,884\nColumns: 3\n$ t         &lt;dbl&gt; 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, …\n$ x         &lt;dbl&gt; 0, -1, -2, -3, -2, -3, -4, -3, -2, -3, -4, -3, -4, -3, -2, -…\n$ sim_index &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, …\n\n\n\n\n3.4.2 Visualizing the random walks\nWhat we are about to do may be a bit silly but helps build some intuitions about what is going on in the model. We are going to make a plot that overlays all 1000 simulated random walks on top of each other. The point is to get a sense of how much variability there is from one realization to the next.\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x, group = sim_index)) +\n    geom_step(alpha = 0.1) +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nOkay, maybe it is a bit silly after all. But it is possible to see that things “thin out” at longer times as more and more random walks end by hitting a boundary. If you check out the code that generates the plot, note how group = sim_index was used to make sure each individual simulation, indexed by sim_index, got its own step-line on the graph. Also note the use of alpha = 0.1 to make each line semi-transparent so they could be overlayed on one another.\nLet’s try a different approach to visualize the same thing, using a heatmap that indicates the relative frequency with which the accumulated evidence takes different values at different times:\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\")\n\n\n\n\n\n\n\n\n\nAgain, what is important to see above is that all the random walks start at the same time and evidence value (the yellow region) and then “fan out” over time.\n\n\n3.4.3 Joint distributions of choice and RT\nWhat we visualized in the previous section are the internal states of the model, that is, how the model represents the decision maker’s current balance of evidence between their two options. Remember, though, that the model is ultimately judged on its externally-observable behavior, since that is all we have to compare it against. We are finally going to visualize the choices and response times produced by the model. As we shall see, however, there are a few ways to do this!\n\n3.4.3.1 Extracting choices and RT’s\nFor each simulation, the RT is the final value of t, since that is the time (plus residual time) at which the first boundary was crossed. Meanwhile, the choice is whether the evidence x is positive or negative. The chunk of code below takes our simulation results and extracts the final choices and RT from each simulation.\n\n\nCode\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\nglimpse(choice_rt)\n\n\nRows: 1,000\nColumns: 3\n$ sim_index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ choice    &lt;fct&gt; lower, lower, lower, upper, upper, lower, upper, lower, uppe…\n$ rt        &lt;dbl&gt; 1.05, 2.35, 0.95, 0.75, 0.55, 2.45, 1.15, 0.45, 1.35, 3.25, …\n\n\n\n\n3.4.3.2 Joint frequency plot\nThe code below plots the frequency with which each choice (upper or lower) is made at different times. This kind of plot is not terribly common, but is a quick way to get a sense of both how often each choice is made as well as the shape of the distributions of RT’s.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_freqpoly(binwidth = 0.2) +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3.3 Conditional RT density\nThe code below plots the conditional density of the RT’s for each choice. This kind of plot is much more common, but doesn’t convey any information about the relative frequency with which different choices are made. Nonetheless, it illustrates how the random walk produces distributions of RT’s with a pronounced right skew, similar to RT distributions that are actually observed in choice tasks. Note that the conditional RT distributions for each choice are pretty similar to one another too.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3.4 Quantile-probability plots\nIn the choice-RT modeling world, it is common to make “quantile-probability plots”, sometimes abbreviated to QP plots. These plots can be a bit confusing at first, but are useful because they convey information about choice proportions and RT distributions in a single graph.\nThe horizontal axis of a QP plot corresponds to the probability of having made a particular choice. In this case, that is the proportion of simulations that resulted in each choice. We can get that information in numerical form from our choice_rt tibble:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\n\n# A tibble: 2 × 3\n  choice     n p_resp\n  &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 upper    507  0.507\n2 lower    493  0.493\n\n\nThe vertical axis of a QP plot corresponds to different quantiles of the conditional RT distributions for each choice. Typically, those quantiles are the RT’s at the 10th, 30th, 50th, 70th, and 90th percentiles of the distribution. The reason for all of these quantiles is that they convey information about different aspects of the distribution: The 50th percentile, otherwise known as the median, conveys the central tendency. The 30th and 70th percentiles indicate where the “bulk” of the RT’s tend to fall. Finally, the 10th and 90th percentiles convey information about the lower and upper tails of the distribution, respectively. We can obtain those quantiles numerically like so:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\n\n# A tibble: 10 × 2\n   choice  rt_q\n   &lt;fct&gt;  &lt;dbl&gt;\n 1 upper   0.55\n 2 upper   0.75\n 3 upper   1.05\n 4 upper   1.55\n 5 upper   2.65\n 6 lower   0.55\n 7 lower   0.85\n 8 lower   1.25\n 9 lower   1.75\n10 lower   2.75\n\n\nTo make a QP plot, we need to “join” together the response proportions and RT quantiles into the same tibble:\n\n\nCode\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q)\n\n\nJoining with `by = join_by(choice)`\n\n\n# A tibble: 10 × 4\n   choice     n p_resp  rt_q\n   &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 upper    507  0.507  0.55\n 2 upper    507  0.507  0.75\n 3 upper    507  0.507  1.05\n 4 upper    507  0.507  1.55\n 5 upper    507  0.507  2.65\n 6 lower    493  0.493  0.55\n 7 lower    493  0.493  0.85\n 8 lower    493  0.493  1.25\n 9 lower    493  0.493  1.75\n10 lower    493  0.493  2.75\n\n\nThat joined tibble can then be used as the basis for our QP plot:\n\n\nCode\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#putting-it-all-together",
    "href": "random_walk.html#putting-it-all-together",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.5 Putting it all together",
    "text": "3.5 Putting it all together\nWe have used R to build a random walk model of decision making, implemented via a function called rw_sim, that accumulates samples of evidence until the accumulated evidence reaches either an upper or lower boundary. This model depends on several parameters, of which the most theoretically important are:\n\np: The probability that any given sample of evidence favors the option associated with the upper response boundary.\nb_upper: The upper response boundary.\nb_lower: The lower response boundary.\nt0: Residual time.\n\nWe also saw different ways that we can visualize both the internal states and external behavior of the model. It may be useful at this point to put together everything we have done so far into a single chunk of code. This will make your own explorations of this model easier.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#exercises",
    "href": "random_walk.html#exercises",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\n\nSet the p parameter to something other than 0.5, so that the evidence tends to favor one option over the other. Do one set of simulations in which the response boundaries are equidistant from the starting value of 0 (you may need to play around to find values that you like). Do another set of simulations in which you keep the boundaries equidistant but make them closer to the starting point. What is the effect on the model’s choices and RT’s of having boundaries that are closer to the starting point?\nRun one set of simulations with the p parameter to 0.6 and the response boundaries equidistant from the starting point. Run another set of simulations keeping the response boundaries the same but increasing the p parameter to 0.8. What is the effect of increasing the p parameter on the RT distributions for making the “upper” choice? What is the effect of increasing the p parameter on the RT distributions for making the “lower” choice?\nImagine that, instead of each sample of evidence equalling either \\(+1\\) or \\(-1\\), the evidence could also equal \\(0\\). Write code to simulate this model and use your simulations to see how this model might differ from the random walk model we developed in this chapter.\n\nYou will need to introduce a new parameter to the model that represents the probability of getting a sample that equals zero. What ways can you think of to implement this aspect of the model? Which method did you pick and why?\nHow does the shape of the predicted RT distributions differ, if at all, from that predicted by the original random walk model? (Hint: you may want to explore settings in which there is zero probability of taking a step either up or down. It may also help to visualize the random walks themselves too.)\nWhat cognitive tasks might be better modeled by allowing for evidence to have a value of zero?\n\nTry implementing a model in which the residual time can vary randomly according to some distribution. Since residual time must be non-negative, you might consider distributions like the Gamma distribution or a uniform distribution between two positive values.\n\nHow did you implement random residual times?\nHow does random residual time affect the shape of the predicted RT distributions?\nWhat psychological factors might contribute to variability in residual time?\n\n\n\n\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A dynamic–cognitive approach to decision making in an uncertain environment. Psychological Review, 100(3), 432–459.\n\n\nDiederich, A. (1997). Dynamic stochastic models for decision making under time constraints. Journal of Mathematical Psychology, 41(3), 260–274. https://doi.org/10.1006/jmps.1997.1167",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html",
    "href": "diffusion_sim.html",
    "title": "4  From random walk to diffusion",
    "section": "",
    "text": "4.1 Discrete to continuous evidence\nLike most models of choice and RT, both random walk and diffusion models are premised on the idea that making a decision requires accumulating samples of “evidence” until the accumulated evidence reaches a response boundary. The “evidence” in these models is deliberately abstract because these models are meant to be applied in a variety of situations. The important thing is that “evidence” can be represented in these models as a number, where a sample of evidence supporting one option takes a positive value while a sample supporting the other option takes a negative value. A diffusion model differs from a random walk model in two aspects regarding the nature of the evidence that is accumulated:\nIn other words, the random walk model treats evidence as taking discrete values that are sampled at discrete intervals, whereas a diffusion model treats evidence as taking continuous values that are sampled continuously in time.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#discrete-to-continuous-evidence",
    "href": "diffusion_sim.html#discrete-to-continuous-evidence",
    "title": "4  From random walk to diffusion",
    "section": "",
    "text": "Samples of evidence take continuous values, rather than discrete values.\nSamples of evidence arrive continually, rather than at regular intervals.\n\n\n\n4.1.1 Evidence sampled from a normal distribution\nIn the random walk model, the magnitude of each sample of evidence was always equal to one. Each sample was either \\(+1\\) or \\(-1\\). In a diffusion model, evidence can take any real value, such that its magnitude is now important. Conceptually, this has some intuitive appeal. Some samples of evidence strongly favor one option, some samples only weakly support one option, and some are equivocal.\nIn a diffusion model, samples of evidence are specifically assumed to come from a normal distribution. The standard deviation of this distribution is typically fixed to some value like 0.1 or 1. Here, we will fix it to the value of 1. The reason for fixing this value is that “evidence” is abstract and therefore has no natural scale. We could multiply or divide all the evidence samples by a constant amount without changing their underlying meaning.\nThe mean of the evidence distribution represents how strongly the evidence tends to favor one option over the other, similar in meaning to the \\(p\\) parameter in the random walk model. The mean of the evidence distribution in a diffusion model is termed the drift rate, as it reflects the tendency for accumulated evidence to “drift” either upward or downward over time. As illustrated in the graph below, the mean of the evidence distribution governs the degree to which samples support one option versus the other.\n\n\nCode\nexpand_grid(v = c(-2, -1, 0, 1, 2), x = seq(-4, 4, length.out = 201)) %&gt;%\n    mutate(d = dnorm(x, mean = v, sd = 1)) %&gt;%\n    ggplot(aes(x = x, y = d, color = v, group = v)) +\n    geom_vline(xintercept = 0, linetype = \"dashed\") +\n    geom_line() +\n    scale_color_gradient2(mid = \"#444444\", midpoint = 0) +\n    labs(x = \"Value of evidence sample\", y = \"Relative frequency\", color = \"Mean of evidence\\ndistribution\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Evidence sampled continuously in time\nHere we come to a bit of a subtle issue: In the random walk, evidence arrived in discrete units at regular intervals, but the duration of the interval was not related to the magnitude of the evidence. In a diffusion model, we assume that evidence arrives continuously in time. One way to think about this—indeed, the way that we will simulate this—is that evidence is sampled in many very short intervals of time, each of which has duration \\(\\Delta t\\). When \\(\\Delta t\\) is small enough, those many little intervals will look like one continuous span of time. This principle is illustrated in the graph below.\n\n\nCode\ndiffusion_sim &lt;- expand_grid(dt = c(0.1, 0.01, 0.001)) %&gt;%\n    group_by(dt) %&gt;%\n    reframe(t = seq(0, 3, by = dt)) %&gt;%\n    ungroup() %&gt;%\n    mutate(x_sample = rnorm(n = n(), mean = 0, sd = 1 * sqrt(dt))) %&gt;%\n    group_by(dt) %&gt;%\n    mutate(x = cumsum(x_sample))\n\nscaled_plot &lt;- diffusion_sim %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    facet_wrap(\"dt\", labeller = label_bquote(Delta * t == .(dt))) +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = expression(\"Evidence scaled by \" * Delta * t))\n\nunscaled_plot &lt;- diffusion_sim %&gt;%\n    ggplot(aes(x = t, y = x / sqrt(dt))) +\n    geom_step() +\n    facet_wrap(\"dt\", labeller = label_bquote(Delta * t == .(dt))) +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Evidence not scaled\")\n\nscaled_plot / unscaled_plot\n\n\n\n\n\n\n\n\n\nThe top set of graphs above show how, when \\(\\Delta t\\) is sufficiently small, the trajectory of accumulated evidence looks essentially continuous—you can no longer see the “jumps” from one interval to the next.\nThe bottom set of graphs illustrate the subtlety I mentioned earlier. If we divide time into many small intervals but leave the mean and standard deviation of the evidence distribution the same, then we are essentially getting many more samples of evidence. As a result, accumulated evidence has a much larger scale than it would have if we had picked a smaller \\(\\Delta t\\). From a theoretical standpoint, this doesn’t make sense—the rate at which evidence accumulates for a decision should not be affected by the modeler’s arbitrary choice of \\(\\Delta t\\).\nSo what we do is scale the evidence samples by \\(\\Delta t\\). That’s what was done in the top set of graphs, but not the bottom set. The idea is that if you have very small time intervals, you shouldn’t be able to get as large of a sample of evidence. Again, this makes theoretical sense, if evidence is something that takes time to accumulate.\nSpecifically, a diffusion model assumes that each sample of evidence is drawn from a normal distribution with a mean of \\(v \\times \\Delta t\\), where \\(v\\) is the drift rate parameter, and a standard deviation of \\(\\sqrt{\\Delta t}\\). Why \\(\\sqrt{\\Delta t}\\) instead of just \\(\\Delta t\\)? Because it is the mean and variance that need to be scaled by \\(\\Delta t\\).\n\n\n4.1.3 A new simulation function\nLet’s take our rw_sim function from the previous chapter and turn it into a diffusion model. To do this, we make two modifications: First, we swap out the p parameter representing the probability of getting a positive sample for a parameter called v which is the drift rate. Second, instead of getting each evidence sample x_sample from a binomial distribution, we will get it from a normal distribution using R’s rnorm function. These changes are illustrated below.\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, b_upper = 1, b_lower = -1, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = v * dt, sd = sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nIn the code above, I also took the liberty of adjusting the default values of b_upper, b_lower, and dt so that the simulated choices and RT’s would look a bit more like those observed in cognitive tasks, but of course you may feel free to adjust those yourself as you like.\n\n\n4.1.4 Putting it all together—again\nAt the end of the last chapter, I included a chunk of code that simulated a random walk and produced some visualizations to help us understand both its internal states and its overt behavior (choices and RT). By swapping out rw_sim with the appropriately adjusted diffusion_sim line, we can apply the same chunk of code to the diffusion model! In the chunk below, I picked some arbitrary but reasonable values for the parameters.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, b_upper = 1, b_lower = -1)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\nYou may or may not be surprised to see that the RT distributions produced by the diffusion model closely resemble those produced by the random walk! The diffusion model also demonstrates an interesting feature of a random walk, namely, that the conditional RT distribution depends on the boundaries but not on the drift rate. In the example above, I set \\(v = 0.5\\), such that evidence would tend to favor the positive option. Even though the model ends up choosing that option more often, it does not do so any faster or slower than it chooses the negative option. This is something we will return to at the end of this chapter.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#response-caution-and-response-bias",
    "href": "diffusion_sim.html#response-caution-and-response-bias",
    "title": "4  From random walk to diffusion",
    "section": "4.2 Response caution and response bias",
    "text": "4.2 Response caution and response bias\nBefore confronting the issue of invariant RT distributions, it behooves us to consider a different way of specifying the response boundaries in our model. So far, we have specified those boundaries directly. We can speak of response caution in terms of how far those boundaries are from the starting point and response bias in terms of whether the boundaries are equidistant from the starting point.\nSpecifically, we could define a term \\(A\\) that is the total distance between the starting point (zero) and the two boundaries. If \\(B_{\\text{Upper}}\\) and \\(B_{\\text{Lower}}\\) are the upper and lower boundaries, respectively, then \\[\nA = B_{\\text{Upper}} - B_{\\text{Lower}}\n\\] In other words, \\(A\\) is how far apart the two boundaries are, called boundary separation. The term \\(A\\) can be seen to operationalize the construct of response caution in that a decision maker who wants to wait to accumulate evidence would put their response boundaries far apart.\nWe can also operationalize the construct of response bias by defining a term \\(w\\). This term will be a number between 0 and 1 that represents the degree to which response boundaries favor one choice over the other. Specifically, let \\[\nw = \\frac{-B_{\\text{Lower}}}{B_{\\text{Upper}} - B_{\\text{Lower}}}\n\\] As shown in the graph below, \\(w = 0.5\\) when the boundaries are equidistant from zero, \\(w &lt; 0.5\\) when the boundaries are biased in favor of the negative option, and \\(w &gt; 0.5\\) when the boundaries are biased in favor of the positive option.\n\n\nCode\nexpand_grid(b_upper = seq(1, 5), b_lower = seq(-1, -5)) %&gt;%\n    mutate(A = b_upper - b_lower) %&gt;%\n    mutate(w = -b_lower / A) %&gt;%\n    pivot_longer(c(A, w), names_to = \"par\", values_to = \"val\") %&gt;%\n    mutate(par = factor(par, levels = c(\"A\", \"w\"), labels = c(\"Response caution (A)\", \"Response bias (w)\"))) %&gt;%\n    ggplot(aes(x = b_upper, y = val, color = b_lower, group = b_lower)) +\n    geom_line() +\n    geom_point() +\n    facet_wrap(\"par\", scales = \"free_y\", strip.position = \"left\") +\n    labs(x = expression(B[\"Upper\"]), y = NULL, color = expression(B[\"Lower\"])) +\n    theme(strip.placement = \"outside\", strip.background = element_blank())\n\n\n\n\n\n\n\n\n\nHaving defined \\(A\\) and \\(w\\) as ways of operationalizing response caution and response bias, respectively, why not treat these values as parameters instead of the boundaries themselves? The value in doing so is that we can then specify these constructs directly, rather than having to work backwards from the boundaries. Specifically, if we pick values of \\(A\\) and \\(w\\) we can immediately compute what the upper and lower boundaries should be: \\[\\begin{align}\nB_{\\text{Upper}} & = w A \\\\\nB_{\\text{Lower}} & = -\\left(1 - w \\right) A \\\\\n\\end{align}\\]\nAnd we can adjust our diffusion_sim code accordingly to have a and w as parameters instead of b_upper and b_lower, which now get calculated in the function itself:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    b_upper &lt;- (1 - w) * a\n    b_lower &lt;- -w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#trial-by-trial-variability",
    "href": "diffusion_sim.html#trial-by-trial-variability",
    "title": "4  From random walk to diffusion",
    "section": "4.3 Trial-by-trial variability",
    "text": "4.3 Trial-by-trial variability\nRecall that both the random walk and the diffusion model have the following property: The response times they produce depend on the distance between the starting point and the response boundary, not on the drift rate \\(v\\) or the step probability \\(p\\). To see why this might be problematic from a psychological perspective, imagine that the upper boundary corresponds to making a correct response while the lower boundary corresponds to making an error. Assume that \\(v &gt; 0\\), such that the evidence tends to favor making a correct response. The fact that response times do not depend on drift rates means that the model predicts that correct and error responses will be made in the same amount of time. To be more precise, the distribution of RT’s conditional on accuracy are the same.\nOften, errors are either faster or slower than correct responses. For example, it may be that errors occur more often when the decision maker happens to get poor evidence. In that case, we might expect errors to be slow because they result from the decision maker deliberating longer in the face of this poor evidence. On the other hand, maybe a decision maker tends to be correct when they take their time, but will sometimes “jump the gun” and pick the wrong option, in which case we would expect errors to be faster than correct responses.\nThe critical factor that Ratcliff (1978) introduced to the diffusion model that has made it into such a useful tool is that the drift rate is not the same on every trial, but varies randomly from trial to trial. On some trials, you happen to get a drift rate in the high positive tail of the distribution of drift rates, in which case you would probably make a fast correct response. On other trials, you happen to get a drift rate that is close to zero or even falls below zero by chance, in which case you would be more likely to make an error and would tend to do so more slowly. Thus, trial-by-trial variability in drift rates accounts for slow errors.\nWhat about fast errors? Ratcliff & Rouder (1998) showed that these can result if your response boundaries are not always fixed, but can also vary randomly from trial to trial. Sometimes, they happen to be very close to the starting point such that it takes very little evidence to commit to a response. Such rapid responses would be more likely to be errors, since they don’t give much time to accumulate evidence. Thus, trial-by-trial variability in boundaries (or, equivalently, in starting point) accounts for fast errors.\nThere is a final thing that can vary from trial to trial, and that is residual time. After all, if the time needed to accumulate evidence can vary between trials, so can the time needed to accomplish all the other processes involved in any given decision task. Trial-by-trial variability in residual time does not, of course, affect the probability of choosing either option, but it does affect the form of the RT distributions.\n\n4.3.1 Adding variability to our simulation code\nTo model each of these kinds of trial-by-trial variability, we need to decide how each of the values above (drift rate, boundaries, and residual time) can vary. This will also inform us as to what new parameters we will need to add to our model to specify that variability. In what follows, we will adopt common assumptions in the literature that are also implemented in the model-fitting functions we will use in later chapters. Check out the exercises (or explore on your own) to consider other forms of trial-by-trial variability!\n\n4.3.1.1 Trial-by-trial variability in drift rates\nOur model already has a parameter called \\(v\\) that stands for the “drift rate”. Let us instead treat \\(v\\) as the mean of a normal distribution of drift rates, which has standard deviation \\(s_v\\). If \\(s_v = 0\\), then we have our original diffusion model with the same drift rate on every trial. On the other hand, if \\(s_v &gt; 0\\), then the drift rate on any given trial will sometimes be greater or less than \\(v\\), even if the average drift rate across all trials is \\(v\\).\nTo implement this in our simulation code, we need to\n\nAdd a new parameter sv.\nAdd a line that randomly samples the drift rate (called trial_v) from a normal distribution with mean v and standard deviation sv.\nReplace v when drawing samples of evidence with trial_v.\n\nThese changes are reflected in the following adjusted code:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    \n    b_upper &lt;- (1 - w) * a\n    b_lower &lt;- -w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe chunk of code below has the same settings as that shown above, only now sv = 1. As you can see, responses on the lower boundary have a different RT distribution, which tends to be slower, than responses on the upper boundary. (Note, too, that I am using our revised code that uses a and w to define the response boundaries.)\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0.5)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n4.3.1.2 Trial-by-trial variability in boundaries/starting point\nThere are a number of ways that we could introduce variability in the starting point and/or boundaries. To be consistent with the model-fitting we will do later, we will assume that the bias parameter \\(w\\) is not fixed, but is sampled from a uniform distribution that goes from \\(w - \\frac{s_w}{2}\\) to \\(w + \\frac{s_w}{2}\\). Thus, the average bias is still \\(w\\) but has a range defined by parameter \\(s_w\\). As above, we need to add this new parameter and randomly sample a trial_w value at the top of our code. Note that the line that samples trial_w does some checking using the min and max functions to make sure that \\(w\\) never falls below 0 or greater than 1.\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0, sw = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    trial_w &lt;- runif(n = 1, min = max(0, w - 0.5 * sw), max = min(1, w + 0.5 * sw))\n    \n    b_upper &lt;- (1 - trial_w) * a\n    b_lower &lt;- -trial_w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe simulations below set \\(s_v = 0\\) and \\(s_w = 0.9\\), while \\(v = 0.5\\). In the simulations below, when the model picks the “incorrect” option associated with the lower boundary, it is predicted to do so faster than when it responds by choosing the “correct” option associated with the upper boundary.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0, sw = 0.9)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n4.3.1.3 Trial-by-trial variability in residual time\nOur final amendment to our diffusion simulation code involves adding variability to the residual time. Again, there are many ways we could do this, but we will adopt the same conventional approach used in our model-fitting later: We will assume that the residual time on any given trial is sampled from a uniform distribution that ranges from \\(t_0\\) to \\(t_0 + s_{t_0}\\). The code below adds the new st0 parameter and samples a residual time trial_t0 from a uniform distribution at the beginning of the simulation:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0, sw = 0, st0 = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    trial_w &lt;- runif(n = 1, min = max(0, w - 0.5 * sw), max = min(1, w + 0.5 * sw))\n    trial_t0 &lt;- runif(n = 1, min = t0, max = t0 + st0)\n    \n    b_upper &lt;- (1 - trial_w) * a\n    b_lower &lt;- -trial_w * a\n    \n    x &lt;- 0\n    t &lt;- trial_t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe simulations below again assume that \\(v = 0.5\\) and set \\(s_v = s_w = 0\\) while \\(s_t = 0.5\\). Note that the resulting RT distributions end up having a longer early tail, reflecting greater variability in the fastest RT’s due to variability in residual time.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0, sw = 0, st0 = 0.6)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Putting it all together (finally!)\nFinally, for completeness, let’s collect our code to run a set of simulations that allows for all three kinds of variability. This code is not executed here, but is included so it can serve as the basis for your own simulations and explorations.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0.5, sw = 0.2, st0 = 0.4)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#shiny-app",
    "href": "diffusion_sim.html#shiny-app",
    "title": "4  From random walk to diffusion",
    "section": "4.4 Shiny App",
    "text": "4.4 Shiny App\nTo have a good deal of fun exploring how the different parameters of a diffusion model influence its predicted choice and RT distributions, download this Shiny app and run it from RStudio. You will also need to download this R script into the same directory as the Shiny app. The Shiny app has some additional functionality that we will see more of in the next chapter.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#exercises",
    "href": "diffusion_sim.html#exercises",
    "title": "4  From random walk to diffusion",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\nUnder what circumstances do you think it is more likely for errors to be faster than correct responses? What about circumstances in which errors are more likely to be slower than correct responses? What do you think about the psychological implications of how the diffusion model produces either fast or slow errors?\nWrite a new diffusion simulation that uses a different distribution of drift rates from trial to trial—you might try distributions that are skewed (like an ExGaussian) or have heavy tails (like the T distribution with few degrees of freedom).\n\nDescribe the distribution you picked and whether it corresponds to a theory or hypothesis about how evidence may vary from trial-to-trial in a particular cognitive task.\nDescribe any differences you find between the model you wrote and the model in the chapter that assumes a normal distribution of drift rates across trials.\n\n\n\n\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108.\n\n\nRatcliff, R., & Rouder, J. N. (1998). Modeling response times for two-choice decisions. Psychological Science, 9(5), 347–356.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html",
    "href": "diffusion_fit.html",
    "title": "5  Fitting a diffusion model to data",
    "section": "",
    "text": "5.1 Fitting a model\nFitting a model to data means finding the values of that model’s parameters that assign the highest likelihood to the observed data. Given a set of parameter values, we can use the model to compute how likely it would be to have seen each observation in our dataset.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-a-model",
    "href": "diffusion_fit.html#fitting-a-model",
    "title": "5  Fitting a diffusion model to data",
    "section": "",
    "text": "5.1.1 Parameters, likelihoods, and log-likelihoods\nUsing \\(\\theta\\) to stand for a set of parameter values and \\(x_i\\) to stand for a particular observation, we can use \\(f \\left( x \\mid \\theta \\right)\\) to stand for the likelihood of the datum \\(x_i\\) given the parameter values \\(\\theta\\) and a model with a likelihood function \\(f\\).\nConsider the familiar normal distribution. This distribution has two parameters, a mean \\(\\mu\\) and a standard deviation \\(\\sigma\\). So for the normal distribution, \\(\\theta\\) is actually a vector with two elements: \\(\\theta = \\left[ \\mu, \\sigma \\right]\\). The normal distribution is a simple model in that it says that observed values fall in a particular shape around the mean \\(\\mu\\) with a spread described by \\(\\sigma\\). The likelihood function for the normal distribution, written below, indicates how likely it would be to observe datum \\(x_i\\) given specific values of \\(\\mu\\) and \\(\\sigma\\): \\[\nf_{\\text{Normal}} \\left( x_i \\mid \\mu, \\sigma \\right) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} \\exp \\left[ - \\frac{\\left(x_i - \\mu \\right)^2}{2 \\sigma^2} \\right]\n\\]\nThe graph below assumes that we have just a single observation, \\(x_i = 0\\). The plots show how the likelihood assigned to that datum depends on both parameters of the normal distribution, \\(\\mu\\) and \\(\\sigma\\).\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = 0) %&gt;%\n    mutate(d = dnorm(x, mean = mu, sd = sigma))\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = d)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = d)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = d)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Joint likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\n\n\n\nData: (0)\n\n\n\n\nWhen we have more than one observation, the likelihood of all observations is the product of the likelihoods of each individual observation: \\[\nf \\left( \\mathbf{x} \\mid \\theta \\right) = \\prod_{i = 1}^N f \\left( x_i \\mid \\theta \\right)\n\\] This situation is illustrated in the graphs below. These graphs again assume a normal distribution as the model, but now we have observed the values \\(\\mathbf{x} = \\left[ 0, 1 \\right]\\).\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = c(0, 1)) %&gt;%\n    mutate(d = dnorm(x, mean = mu, sd = sigma)) %&gt;%\n    group_by(mu, sigma) %&gt;%\n    summarize(d = prod(d), .groups = \"keep\")\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = d)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = d)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = d)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Joint likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nData: (0, 1)\n\n\n\n\n\n\n5.1.2 Log-likelihood\nYou may have noticed that the scale on the bottom graph in the second set of plots (where the data were \\(0, 1\\)) has a smaller maximum than it did in the bottom graph in the first set of plots (where the data were just \\(0\\)). This is because the likelihood of the whole dataset is a product of many small numbers, so the result also tends to be small. Unfortunately, this can lead to technical issues when we have many observations because the resulting likelihood may be too small for the computer to accurately calculate.\nAs a result, we often work with the natural logarithm of the likelihood function. Because multiplication turns into addition on the log-scale, this saves the computer from needing to work with very tiny numbers. We often write \\(LL\\) to stand for this “log-likelihood”: \\[\nLL \\left( \\mathbf{x} \\mid \\theta \\right) = \\log \\left[ \\prod_{i = 1}^N f \\left( x_i \\mid \\theta \\right) \\right] = \\sum_{i = 1}^N \\log f \\left( x_i \\mid \\theta \\right)\n\\]\nFortunately, since the logarithm is a monotonic transformation, the parameters that maximize the likelihood are the very same parameters that maximize the log-likelihood. To get a sense of this, the graphs below replicate the graph above with observed values \\(\\mathbf{x} = \\left[ 0, 1 \\right]\\), but showing the log-likelihood instead of the likelihood.\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = c(0, 1)) %&gt;%\n    mutate(ll = dnorm(x, mean = mu, sd = sigma, log = TRUE)) %&gt;%\n    group_by(mu, sigma) %&gt;%\n    summarize(ll = sum(ll), .groups = \"keep\")\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = ll)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = ll)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = ll)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Total log-likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nData: (0, 1)\n\n\n\n\n\n\n5.1.3 Maximizing log-likelihood\nThe combination of parameter values that assigns the highest total log-likelihood to all the data is where the bright spot is in the bottom graph of each set of plots above. For a normal model, the values of \\(\\mu\\) and \\(\\sigma\\) that assign the highest total log-likelihood to the data can be computed directly: they are the sample mean and the population standard deviation computed on the same (i.e., where you divide by \\(N\\) instead of \\(N - 1\\)).\nFor a more complex model, like our diffusion model, we will not be able to calculate these “optimal” parameter values directly. Instead, we will need to use the computer to search for these values. The topic of parameter optimization is a large one that we cannot fully address here. However, the functions supplied with this tutorial make use of two search methods: the Nelder-Mead simplex algorithm and the ucminf function from the ucminf R package.\nThe essence of these parameter optimization algorithms is this: They begin with an initial “guess” of the parameter values and compute the log-likelihood of the data given that initial guess. They then “explore” by calculating the log-likelihood of the data using slightly adjusted parameter values. If this exploration finds a set of adjusted parameter values that assign a higher log-likelihood to the data than the original guess, then these adjusted values are considered a “better guess”. The search process then begins again starting from that better guess. As a result, the “guess” gets gradually better on each step of the algorithm until it can no longer find any way to adjust the parameters to find a higher log-likelihood.\nOne can think of this parameter search as like trying to find a mountain peak in a snowstorm: The snowstorm obscures your visibility so you can only search areas in your immediate vicinity (similar to how the parameter optimizer tries to adjust values of the parameters starting from an initial guess). However, you can still figure out which direction is “uphill” from your current position (similar to how the algorithm finds adjusted parameters that yield a higher log-likelihood than the current best guess). Eventually, you will reach a point where you can’t go uphill any more.\nThe metaphor in the previous paragraph serves to highlight the fact that parameter optimizers are not necessarily guaranteed to find the “global optimum”—the best possible set of parameter values. It is possible that they instead find a “local optimum”—a set of values for which no small adjustment yields an improvement, but which is not the best you could possibly do. To return to the metaphor, the tallest peak may be a mile away from the one you found, but you’ll never know that because you can’t see it.\nThe utility functions we will use in this tutorial are generally pretty good at finding global optima, but it is not guaranteed! This is why it is important to develop some intuitions about how model parameters manifest in behavior, so you can detect when you might have reached a local optimum instead of a global one.\n\n\n5.1.4 Minimizing negative log-likelihood\nDue to the vagaries of history, algorithms that search for optimal parameter values are often written not to maximize something, but to minimize it instead. As a result, what a parameter optimization algorithm actually does is minimize the negative log-likelihood. Basically, it flips the “maximization” problem over, although it does not change anything conceptually. However, it does mean that a more appropriate metaphor is finding the lowest point in a valley rather than the highest peak of a mountain range.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-a-diffusion-model",
    "href": "diffusion_fit.html#fitting-a-diffusion-model",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.2 Fitting a diffusion model",
    "text": "5.2 Fitting a diffusion model\nTo find the set of parameters for a diffusion model that assign the highest likelihood to the data, we need to be able to compute the likelihood of making a specific choice at a specific time, given a set of diffusion model parameters. This computation is not something we can do by hand—we have to rely on the computer. Fortunately, many folks have contributed to the development of efficient means of doing this computation (e.g., Blurton et al., 2012; Gondan et al., 2014; Hartmann & Klauer, 2021; Navarro & Fuss, 2009; Tuerlincx, 2004).\nWe will make use specifically of an R package that implements these methods called WienR (Hartmann & Klauer, 2023). The name comes from the fact that Norbert Wiener was associated with the development of the “bare-bones” diffusion model without any of the trial-by-trial variability introduced by Ratcliff (1978). That said, the WienR package allows for all of those additional forms of variability as described in the previous chapter.\nBe sure you have the WienR package installed and loaded!\n\n\nCode\nlibrary(WienR)\n\n\n\n5.2.1 Diffusion model likelihood\nThe WienR package provides a function called WienerPDF which returns both the likelihood and the log-likelihood of a set of responses, given a set of diffusion model parameters.\nUnlike with the normal distribution model, where an observation was characterized by a single number, an observation for a diffusion model is characterized by a choice and a response time. Thus, if we want to compute the likelihood of responding at the upper boundary in 1 second given a drift rate of \\(v = 0.5\\), response caution of \\(a = 2\\), response bias of \\(w = 0.5\\), and residual time \\(t_0 = 0.2\\), we use\n\n\nCode\nWienerPDF(t = 1, response = \"upper\", a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n\n\nFirst-passage time PDF\n\n[1] 0.4362052\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.8296426\n\n---------------------------\n\n\nThe “First-passage time PDF” is the likelihood of having made that response at that time.\nLet’s imagine that we observed a few more trials, one in which a decision-maker responded at the upper boundary in 1.5 seconds and one in which the decision-maker responded at the lower boundary in 2 seconds. We can compute the likelihood and log-likelihood of all of those trials:\n\n\nCode\nWienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n\n\nFirst-passage time PDF\n\n[1] 0.43620517 0.22137809 0.04128626\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.8296426 -1.5078832 -3.1872255\n\n---------------------------\n\n\nNote two things: First, t and response are allowed to be vectors, where the \\(i\\)th entry in the t vector corresponds to the \\(i\\)th entry in the response vector. Second, we get the likelihood and log-likelihood for each trial individually. So if we want the total log-likelihood, we have to do that ourselves:\n\n\nCode\nresult &lt;- WienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n(total_log_likelihood &lt;- sum(result$logvalue))\n\n\n[1] -5.524751\n\n\nThe upshot of this is that WienerPDF gives us a way to evaluate the log-likelihood of a set of choices and response times given a set of values for the diffusion model’s parameters. WienerPDF also allows us to include variability in drift rates via the sv parameter, variability in boundaries via the sw parameter, and variability in residual time via the st0 parameter, like so:\n\n\nCode\nWienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2, sv = 0.5, sw = 0.1, st0 = 0.4)\n\n\n\nFirst-passage time PDF\n\n[1] 0.56113640 0.26562047 0.06165999\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.5777913 -1.3256868 -2.7861200\n\n---------------------------\n\n\nNotice that the likelihoods and log-likelihoods changed when we included those three new parameters (which, by default, are set to zero).\n\n\n5.2.2 Finding the best-fitting parameters\nTo find the diffusion model parameters that assign the highest log-likelihood to a given set of choices and RT’s, I have provided a helpful function called fit_wienr. To use this function, download the wienr_fit_utils.r R script to your working directory and run\n\n\nCode\nsource(\"wienr_fit_utils.r\")\n\n\nWe shall see later that the fit_wienr function has some useful bells-and-whistles, but for now let’s just see how it works in its basic form. To do this, let’s use another function from the WienR package called sampWiener which simulates a sample of data from a diffusion model, just like we did in the last chapter (actually, you could even use the diffusion_sim function you built for that purpose!):\n\n\nCode\n(sim_data &lt;- sampWiener(N = 50, a = 2, v = 0.5, w = 0.5, t0 = 0.2))\n\n\n$q\n [1] 1.0145267 0.7785001 0.4830922 0.7476763 0.6889558 0.3996333 0.7652827\n [8] 1.0678441 1.0589824 1.1778599 1.1916915 2.0070563 0.4737943 0.5687575\n[15] 0.9735880 0.7182124 0.7907633 1.5717658 0.6528604 0.8988441 0.6722051\n[22] 0.3394198 0.8275921 2.0176933 0.6527308 1.3267482 1.0114098 0.7283250\n[29] 1.6299191 1.8353343 1.2566600 1.2643379 2.0130723 1.5419533 1.0620593\n[36] 0.5713716 2.5825087 0.7561459 1.1029754 0.6381128 0.5454809 0.6359990\n[43] 3.0614166 1.6769220 0.8270179 2.9357647 1.0710890 0.3431315 0.4737332\n[50] 3.6870701\n\n$response\n [1] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[10] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[19] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[28] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[37] \"upper\" \"upper\" \"upper\" \"lower\" \"lower\" \"lower\" \"lower\" \"lower\" \"lower\"\n[46] \"lower\" \"lower\" \"lower\" \"lower\" \"lower\"\n\n$call\nsampWiener(N = 50, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\nattr(,\"class\")\n[1] \"Diffusion_samp\"\n\n\nThe simulated choices are in sim_data$response and the simulated RT’s are in sim_data$q.\nBecause we are using the diffusion model to simulate data, it’s worth asking how likely the data are given the parameter values we actually used for the simulation:\n\n\nCode\noriginal_likelihood &lt;- WienerPDF(t = sim_data$q, response = sim_data$response, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\nsum(original_likelihood$logvalue)\n\n\n[1] -66.06148\n\n\nRemember, though, that the optimization algorithm will actually be minimizing the negative log-likelihood. The negative log-likelihood given the original values of the parameters is\n\n\nCode\n-sum(original_likelihood$logvalue)\n\n\n[1] 66.06148\n\n\nIt may be that the “best-fitting” parameters differ from those used to simulate the data, just due to sampling variability. Thus, what we are about to do is a form of parameter recovery, in that we are seeing how well we can “recover” the original model parameters, despite this sampling variability.\nThe following code uses the fit_wienr function to find the best-fitting diffusion model parameter values for the simulated data above:\n\n\nCode\n(fit &lt;- fit_wienr(rt = sim_data$q, response = sim_data$response))\n\n\n$par\n     a[1]      v[1]      w[1]     t0[1] \n2.0672467 0.7208941 0.4525921 0.2034778 \n\n$value\n[1] 65.09442\n\n$convergence\n[1] 1\n\n$message\n[1] \"Stopped by small gradient (grtol).\"\n\n$invhessian.lt\n [1]  0.0233247552  0.0059470005 -0.0003678730 -0.0039030749  0.0343417878\n [6] -0.0053634481 -0.0010979615  0.0025483504  0.0004887555  0.0017438879\n\n$info\n maxgradient     laststep      stepmax        neval \n3.672341e-08 2.012289e-07 1.500625e-02 1.700000e+01 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nThe best negative log-likelihood that the algorithm was able to find is fit$value—as we can see it is slightly lower than the negative log-likelihood associated with the original simulating parameters, suggesting that the best-fitting parameters really do a slightly better job of “fitting” the data. Those parameter estimates reside in fit$par, where we can compare them against the values used to actually simulate the data.\n\n\n5.2.3 Visualizing model fit\nMinimizing the negative log-likelihood is well and good, but it doesn’t tell us much about how well the model actually “fits” the data. Does it predict similar choice and RT patterns?\nTo address this, it is helpful to visually inspect the fit of the model. There are many ways to do this, but here we will make use of the quantile-probability plots we introduced in previous chapters. We will overlay the quantile-probability plots of the original data with those that would be predicted by the best-fitting diffusion model parameters. To the extent that the model and data are close to one another, we can feel confident that the model is accurately reproducing the major features of the data.\nThe qp_fit function in the wienr_fit_utils.r script calculates the response probabilities and RT quantiles for both the observed data and the fitted model, like so:\n\n\nCode\n(obs_fit_data &lt;- qp_fit(rt = sim_data$q, response = sim_data$response, par = fit$par))\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\n# A tibble: 20 × 12\n# Groups:   drift_index, bound_index, resid_index, sv_index, sw_index,\n#   st0_index [1]\n   drift_index bound_index resid_index sv_index sw_index st0_index response\n         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   \n 1           1           1           1        1        1         1 lower   \n 2           1           1           1        1        1         1 lower   \n 3           1           1           1        1        1         1 lower   \n 4           1           1           1        1        1         1 lower   \n 5           1           1           1        1        1         1 lower   \n 6           1           1           1        1        1         1 upper   \n 7           1           1           1        1        1         1 upper   \n 8           1           1           1        1        1         1 upper   \n 9           1           1           1        1        1         1 upper   \n10           1           1           1        1        1         1 upper   \n11           1           1           1        1        1         1 upper   \n12           1           1           1        1        1         1 upper   \n13           1           1           1        1        1         1 upper   \n14           1           1           1        1        1         1 upper   \n15           1           1           1        1        1         1 upper   \n16           1           1           1        1        1         1 lower   \n17           1           1           1        1        1         1 lower   \n18           1           1           1        1        1         1 lower   \n19           1           1           1        1        1         1 lower   \n20           1           1           1        1        1         1 lower   \n# ℹ 5 more variables: n_resp &lt;int&gt;, p_resp &lt;dbl&gt;, rt_p &lt;dbl&gt;, rt_q &lt;dbl&gt;,\n#   source &lt;chr&gt;\n\n\nWe can then use the result to overlay the quantile-probabilities from the fitted model over those computed from the observed data:\n\n\nCode\nobs_fit_data %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\", title = \"50 simulated trials\")\n\n\n\n\n\n\n\n\n\nThis visualization highlights a few things: While the diffusion model fits the response probabilities and central tendency of the RT’s quite well, it doesn’t do as good a job with the error RT’s nor with the tails of the RT distributions. This is not because of a qualitative difference between the model and data—after all, we used the diffusion model to simulate these data! Rather, this apparent misfit is due to sampling error: With a small sample, it is harder to estimate RT’s for rare responses (like errors) and it is harder to estimate the tails of the RT distributions (since, by definition, we have fewer observations in the tails).\nSo let’s see what happens if we simulate 1000 trials instead of just 50.\n\n\nCode\nsim_data_large &lt;- sampWiener(N = 1000, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n(fit_large &lt;- fit_wienr(rt = sim_data_large$q, response = sim_data_large$response))\n\n\n$par\n     a[1]      v[1]      w[1]     t0[1] \n2.0145409 0.4891320 0.4895752 0.1936399 \n\n$value\n[1] 1394.557\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n  0.3267429   0.0000000   1.0000000   1.0000000 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nCode\nobs_fit_data_large &lt;- qp_fit(rt = sim_data_large$q, response = sim_data_large$response, par = fit_large$par)\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\nCode\nobs_fit_data_large %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\", title = \"1000 simulated trials\")\n\n\n\n\n\n\n\n\n\nMuch better! And notice that the best-fitting parameter values (fit_large$par, above) are quite close to those used to simulate the data.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-multiple-conditions",
    "href": "diffusion_fit.html#fitting-multiple-conditions",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.3 Fitting multiple conditions",
    "text": "5.3 Fitting multiple conditions\nImagine that we are modeling someone doing a recognition memory task. In this task, participants study a set of items like words or images. Later, during a test phase participants are shown many items and, for each one, they have to decide whether it had been on the study list or not. Therefore, on any given test trial, the item shown could have been studied—called a target—or not studied—called a foil. The participant needs to accumulate evidence from their memory in order to decide whether the item had or had not been studied. It seems reasonable to assume that, if the item is a target, the drift rate for that evidence would tend to be positive, i.e., supporting the choice that the item had been studied. If the item is a foil, the drift rate would tend to be negative, since the samples of evidence from memory would support the choice that the item wasn’t studied. Modeling this task would therefore require estimating two drift rate parameters, one for trials in which a target is shown and one for trials in which a foil is shown. However, because the participant cannot know which type of item they were shown, their response boundaries and residual time should be the same regardless of whether the trial shows a target or a foil.\nThe example above is just one case in which we need to model a decision task by assuming that some parameters differ between conditions (like between targets and foils) while others stay the same (like the response boundaries and residual time). For example, we could simulate the situation above by assuming that \\(v_1 = 0.5\\) is the drift rate for targets while \\(v_2 = -0.5\\) is the drift rate for foils, while keeping \\(a = 2\\), \\(w = 0.5\\), and \\(t_0 = 0.2\\) constant:\n\n\nCode\ntarget_trials &lt;- sampWiener(N = 80, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\nfoil_trials &lt;- sampWiener(N = 80, a = 2, v = -0.5, w = 0.5, t0 = 0.2)\n\n(all_trials &lt;- tibble(\n    rt = c(target_trials$q, foil_trials$q),\n    response = c(target_trials$response, foil_trials$response),\n    item = factor(rep(c(\"Target\", \"Foil\"), each = 80), levels = c(\"Target\", \"Foil\"))\n))\n\n\n# A tibble: 160 × 3\n      rt response item  \n   &lt;dbl&gt; &lt;chr&gt;    &lt;fct&gt; \n 1 1.77  upper    Target\n 2 1.95  upper    Target\n 3 0.486 upper    Target\n 4 0.396 upper    Target\n 5 0.543 upper    Target\n 6 1.40  upper    Target\n 7 0.748 upper    Target\n 8 0.721 upper    Target\n 9 0.938 upper    Target\n10 1.99  upper    Target\n# ℹ 150 more rows\n\n\nWe can use the fit_wienr function to fit these data by supplying it with a drift_index vector. This is a vector of positive integers (1, 2, 3, …) that indicate which drift rate to use when computing the log-likelihood of a particular trial. In this case, since we want drift rate to depend on the type of item shown, we can use the item column of our simulated data to define the drift index:\n\n\nCode\nas.numeric(all_trials$item)\n\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[149] 2 2 2 2 2 2 2 2 2 2 2 2\n\n\nHere is how we supply that to fit_wienr:\n\n\nCode\n(recog_fit &lt;- fit_wienr(rt = all_trials$rt, response = all_trials$response, drift_index = as.numeric(all_trials$item)))\n\n\n$par\n      a[1]       v[1]       v[2]       w[1]      t0[1] \n 2.0345129  0.3167632 -0.7274032  0.5145780  0.2058107 \n\n$value\n[1] 219.4175\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n 0.04339481  0.00000000  1.00000000  1.00000000 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nAs we can see, the estimated drift rates v[1] and v[2] go in the direction we would expect, given that drift_index = 1 indicates a target (positive drift) and drift_index = 2 indicates a foil (negative drift).\nAnd how well does the best-fitting model do? Again, we can supply drift_index to the qp_fit function and make a set of quantile-probability plots.\n\n\nCode\nrecog_obs_fit_data &lt;- qp_fit(rt = all_trials$rt, response = all_trials$response, par = recog_fit$par, drift_index = as.numeric(all_trials$item))\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\nCode\nrecog_obs_fit_data %&gt;%\n    mutate(drift_index_label = factor(drift_index, levels = 1:2, labels = c(\"Target\", \"Foil\"))) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"drift_index_label\") +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\")\n\n\n\n\n\n\n\n\n\nNot too bad, though as we saw earlier, the fit isn’t as good for errors or for the tails of the RT distributions.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#comparing-model-fits",
    "href": "diffusion_fit.html#comparing-model-fits",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.4 Comparing model fits",
    "text": "5.4 Comparing model fits\nContinuing with the recognition memory example, imagine that we wanted to address the question: Can this participant distinguish between studied and unstudied items? That question can be reframed in terms of diffusion model parameters: is the drift rate the same or different between target and foil trials?\nTo address that question, we can fit one version of a diffusion model that uses the drift_index vector to estimate separate drift rates for targets and foils, like we just did. We can then fit another version that does not include drift_index, so that it estimates a single drift rate for all trials. The second model would correspond to the hypothesis that the participant cannot distinguish between targets and foils, because they get the same quality of evidence from their memory either way. By comparing how well those two models account for the data, taking into account the fact that the one-drift-rate model is less complex, then we can get evidence to help us address our question.\nLater in the course, we will delve more deeply into the issue of model comparison. For now, we will just introduce the basic idea of “scoring” a model based on (a) how well it fits data; and (b) how complex the model is. As noted below, a more complex model will, in general, be able to fit a wider variety of data. Thus, we should only favor a more complex model to the extent that it fits data better than would be expected based on its complexity. As we will discuss later in the course, there are other reasons why we should be reticent to favor more complex models, but these reasons can sometimes be hard to quantify. Thus, for now, we introduce some simple quantitative methods by which models can be compared while still accounting for their complexity.\n\n5.4.1 Information criteria\nIn the previous section, we already fit the two-drift-rate model. Now let’s fit the one-drift-rate version:\n\n\nCode\n(recog_fit_onedrift &lt;- fit_wienr(rt = all_trials$rt, response = all_trials$response))\n\n\n$par\n      a[1]       v[1]       w[1]      t0[1] \n 1.9376960 -0.1943884  0.5129813  0.2166252 \n\n$value\n[1] 239.2321\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n 0.06124639  0.00000000  1.00000000  1.00000000 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nTo compare the fit of the two models, we have a number of techniques at our disposal, but one of the most common is to use an information criterion. These values essentially “score” a model, with higher scores being worse (like golf). The score takes into account how well the model fits the data as well as how complex the model is. Taking into account complexity is critical because, generally speaking, a more complex model will be able to fit data better, so it needs to be “handicapped” to account for this advantage (again, sort of like golf). The information criteria we will use here measure a model’s complexity in terms of the number of free parameters it has.\n\n5.4.1.1 Akaike Information Criterion (AIC)\nThe Akaike Information Criterion (AIC, Akaike, 1974) is defined: \\[\nAIC = 2 \\times NLL + 2 \\times k\n\\] where \\(NLL\\) is the negative log-likelihood of the fitted model (i.e., the quantity that is minimized during model fitting) and \\(k\\) is the number of free parameters in the model.\nWhen we use fit_wienr, the negative log-likelihood is the $value entry in the result. Meanwhile, we can get the number of free parameters as the length of the vector of best-fitting parameter estimates, as illustrated below:\n\n\nCode\naic_twodrift &lt;- 2 * recog_fit$value + 2 * length(recog_fit$par)\naic_onedrift &lt;- 2 * recog_fit_onedrift$value + 2 * length(recog_fit_onedrift$par)\n\nc(\"Two drift\" = aic_twodrift, \"One drift\" = aic_onedrift)\n\n\nTwo drift One drift \n 448.8351  486.4642 \n\n\nRecall that lower scores are better. Since the two-drift model has the lower AIC, we have evidence that this (simulated) participant is able to distinguish between targets and foils.\n\n\n5.4.1.2 Bayesian Information Criterion (BIC)\nThe Bayesian Information Criterion (BIC, Schwarz (1978)) is similar to the AIC but places a stronger penalty on the number of free parameters. Specifically, the penalty scales up with the logarithm of the number of observations. Letting \\(N\\) stand for the number of observed trials, the BIC is defined \\[\nBIC = 2 \\times NLL + k \\log N\n\\] where, again, \\(NLL\\) is the negative log-likelihood and \\(k\\) is the number of free parameters. We can now calculate BIC for each model:\n\n\nCode\nbic_twodrift &lt;- 2 * recog_fit$value + log(nrow(all_trials)) * length(recog_fit$par)\nbic_onedrift &lt;- 2 * recog_fit_onedrift$value + log(nrow(all_trials)) * length(recog_fit_onedrift$par)\n\nc(\"Two drift\" = bic_twodrift, \"One drift\" = bic_onedrift)\n\n\nTwo drift One drift \n 464.2109  498.7649 \n\n\nOnce again, the two-drift model gets the lower—and therefore better—score.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#shiny-app",
    "href": "diffusion_fit.html#shiny-app",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.5 Shiny App",
    "text": "5.5 Shiny App\nThe “Manual parameter fitting” tab of the Shiny app from the previous chapter allows you to try searching for optimal parameters yourself. You will find how difficult it is to do by hand! There is also a “Parameter recovery” tab that replicates what we did in this chapter, namely, using the diffusion model to simulate data and then fitting the diffusion model to the simulated data. Finally, note that the App allows you to play around with other parameters, like the trial-by-trial variability parameters, that we did not use in this chapter.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#exercises",
    "href": "diffusion_fit.html#exercises",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.6 Exercises",
    "text": "5.6 Exercises\n\nConsider a dataset with one particularly short RT. Would you want to allow for variability in residual time when fitting these data? Why or why not?\nUsing the Shiny App, see if you can “fool” the model! Specifically, try simulating data until there is a notable discrepancy between the best-fitting parameter values and the values you used to simulate the data. What features of the simulated data may have resulted in this discrepancy?\nWe saw an example in the chapter of how drift rates might vary between conditions of an experiment even while the other parameters of the model would stay the same.\n\nWhat other examples can you think of where the properties of the evidence change but other model parameters do not?\nGive an example of a situation in which you would expect response boundaries to differ between conditions, but not drift rates.\nGive an example of a situation in which you would expect residual time to differ between conditions, but not drift rates or boundaries.\n\nRepeat our recognition memory simulations and model comparisons, but instead of simulating data where the drift rate actually differs between targets and foils, simulate data in which targets and foils have the same drift rate. Use both AIC and BIC to compare the fits of the two-drift and one-drift models. Do these information criteria favor the “correct” model?\n\n\n\n\n\nAkaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19(6), 716–723.\n\n\nBlurton, S. P., Kesselmeier, M., & Gondan, M. (2012). Fast and accurate calculations for cumulative first-passage time distributions in wiener diffusion models. Journal of Mathematical Psychology, 56(6), 470–475. https://doi.org/https://doi.org/10.1016/j.jmp.2012.09.002\n\n\nGondan, M., Blurton, S. P., & Kesselmeier, M. (2014). Even faster and even more accurate first-passage time densities and distributions for the wiener diffusion model. Journal of Mathematical Psychology, 60, 20–22. https://doi.org/https://doi.org/10.1016/j.jmp.2014.05.002\n\n\nHartmann, R., & Klauer, K. C. (2021). Partial derivatives for the first-passage time distribution in wiener diffusion models. Journal of Mathematical Psychology, 103, 102550. https://doi.org/https://doi.org/10.1016/j.jmp.2021.102550\n\n\nHartmann, R., & Klauer, K. C. (2023). WienR: Derivatives of the first-passage time density and cumulative distribution function, and random sampling from the (truncated) first-passage time distribution. https://CRAN.R-project.org/package=WienR\n\n\nNavarro, D. J., & Fuss, I. G. (2009). Fast and accurate calculations for first-passage times in wiener diffusion models. Journal of Mathematical Psychology, 53(4), 222–230. https://doi.org/https://doi.org/10.1016/j.jmp.2009.02.003\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108.\n\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2), 461–464.\n\n\nTuerlincx, F. (2004). The efficient computation of the cumulative distribution and probability density functions in the diffusion model. Behavior Research Methods, Instruments, & Computers, 36(4), 702–716.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "model_comparison.html",
    "href": "model_comparison.html",
    "title": "6  Model complexity and model comparison",
    "section": "",
    "text": "6.1 Complexity and generalization\nIn a way, the issue with model complexity boils down to the same issue we have in statistics when using a sample to estimate some population quantity. In statistics, where we use models on the “descriptive” end of the modeling continuum, our goal is to identify patterns in our sample of data that we would expect to see in other samples from some broader population. In that way, we generalize whatever conclusions we draw about our sample to this broader population. We have essentially the same goal when applying a cognitive model, even though it falls on the “causal” end of the modeling continuum: By fitting the model to a sample of data, we are hoping to draw some inferences about how a sample of participants accomplished a particular task. We hope that those inferences apply more broadly, i.e., that we can make a general statement about how some broader population accomplishes that task.\nThe challenge we face in both statistics and cognitive modeling is that we know that not every sample from the same population is identical. This sampling variability has two consequences: First, it is possible that our observed data sample is biased, in the sense that it has some idiosyncratic property that is not representative of what we would expect to see in the population more broadly. In that case, what we conclude about our sample may not generalize to the broader population. Second, even if our sample were unbiased, variability in the population means that we cannot expect our conclusions to generalize equally well to every member of the population—all we can hope is that our conclusions apply on average.\nAddressing the consequences of sampling variability is challenging because, by definition, we do not know how variable the population is nor whether our sample is biased or not. In statistics, we address this lack of omniscience by constructing a descriptive model which enables us to estimate how wrong we might be. This is the meaning behind the “standard error” in traditional statistics or the posterior distribution in Bayesian statistics. In the end, we confine ourselves to conclusions that are supported by estimates that are strong enough to overcome this baseline level of wrongness, in which case we call our results “significant” or “credible”. Of course, this does not completely inoculate us from drawing improper generalizations, but it helps us pay attention to data patterns that are more likely to generalize while still acknowledging our uncertainty.\nOur techniques for comparing computational cognitive models serve the same function as a “standard error” or posterior distribution in descriptive statistical modeling. A good model fit may be due to idiosyncracies of the model or of the sample, neither of which may be representative of the broader population to which we are hoping to generalize. Because a more complex model has more flexibility to fit any possible sample, we want to avoid favoring a complex model unless it fits better over and above the degree to which we would expect it to fit better just due to its flexibility. As in statistics, model comparison is not guaranteed to identify the “true” model that explains performance on some task more generally. However, model comparison is a valuable tool that helps us identify the aspects of a model that are most essential for explaining performance and which are most likely to generalize.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "model_comparison.html#cross-validation",
    "href": "model_comparison.html#cross-validation",
    "title": "6  Model complexity and model comparison",
    "section": "6.2 Cross-validation",
    "text": "6.2 Cross-validation\nThe motivation behind many issues in model comparison is exemplified by the approach known as cross-validation (Arlot & Celisse, 2010; Browne, 2000; Zucchini, 2000). In cross-validation, one divides the sample of data into two parts, a training set and a testing set. The model is fit to the data in the training set and we then compute the log-likelihood of the data in the testing set, using the parameter values obtained by fitting the model to the training set. A model is preferred to the extent that is able to assign higher likelihood to the data in the training set. The rationale behind cross-validation is, thus, to evaluate a model on its ability to generalize from the training data to the test data. A model that is too flexible will tend to “over-fit” the various idiosyncratic features of the training data that are not reproduced in the testing data, meaning it will perform worse on average than a model that captures the systematic aspects that are common to both the training and testing data.\n\n6.2.1 Example\nTo make this situation concrete, let’s use a diffusion model to simulate some data and then use cross-validation to compare different potential models we could use to fit that data. Let’s again assume we are doing a recognition memory task, where target items have positive drift rates and foil items have negative drift rates. We will also assume that there is trial-by-trial variability in drift rates (the sv parameter) and that it is the same for both targets and foils.\n\n\nCode\nn_trials &lt;- 100\n\ntarget_trials &lt;- sampWiener(N = n_trials, a = 2, v = 0.5, w = 0.5, t0 = 0.2, sv = 0.3)\nfoil_trials &lt;- sampWiener(N = n_trials, a = 2, v = -0.5, w = 0.5, t0 = 0.2, sv = 0.3)\n\n(all_trials &lt;- tibble(\n    rt = c(target_trials$q, foil_trials$q),\n    response = factor(c(target_trials$response, foil_trials$response), levels = c(\"lower\", \"upper\")),\n    item = factor(rep(c(\"Target\", \"Foil\"), each = n_trials), levels = c(\"Target\", \"Foil\"))\n))\n\n\n# A tibble: 200 × 3\n      rt response item  \n   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n 1 1.29  upper    Target\n 2 0.973 upper    Target\n 3 0.695 upper    Target\n 4 1.75  upper    Target\n 5 1.17  upper    Target\n 6 1.18  upper    Target\n 7 1.91  upper    Target\n 8 1.46  upper    Target\n 9 0.988 upper    Target\n10 0.554 upper    Target\n# ℹ 190 more rows\n\n\nIf we were coming to this data “fresh”, like we would in a real experiment, we might consider applying a few models, since we wouldn’t know which one best accounts for our data. For the sake of the present example, let’s focus on three possible models:\n\nModel A assumes that both the mean drift rate (v) and the drift rate standard deviation (sv) are the same for both targets and foils. This model is “incorrect”, in the sense that it assumes equal parameters for both targets and foils. Nonetheless, we may want to verify that participants are actually able to distinguish between targets and foils. In a different experiment, we might be interested in comparing two conditions to see whether drift rate differs between them. In any case, we can think of model A as a sort of “null” model.\nModel B assumes that the mean drift rate (v) varies between targets and foils, but the drift rate standard deviation (sv) is the same for both targets and foils. This model is “correct”, in the sense that it allows parameters to vary in the same way that they did in our simulations.\nModel C assumes that both the mean drift rate (v) and drift rate standard deviation (sv) vary between targets and foils. This model is “incorrect”, in the sense that it is too flexible relative to how the parameters varied in simulation. Nonetheless, we expect that this model will probably fit better than the “correct” model (B) since the additional drift rate variability parameter will enable it to fit any quirks in the simulated data.\n\n\n6.2.1.1 The steps of cross-validation\nTo see how cross-validation works, let’s go through a single example of applying it to our simulated data. First, we need to split our data into “training” and “testing” sets. We will do this randomly, so as not to introduce any bias. Relatedly, we will need to make sure that all the conditions of the experiment are represented in both testing and training sets in the same proportion that they are in the full data. Again, this avoids introducing bias by not “over-representing” one condition or the other.\nFor our first pass, let’s have the training and testing data be of equal size. We will use R’s sample function to randomly assign each trial within each condition (defined by item) to either the training or testing set.\n\n\nCode\nall_trials_traintest &lt;- all_trials %&gt;%\n    group_by(item) %&gt;%\n    mutate(set = factor(\n            # In the line below, `n()` is the number of trials within the groups defined by the variables in the `group_by` line above\n            sample(rep(c(\"training\", \"testing\"), round(c(0.5, 0.5) * n())))[1:n()],\n            levels = c(\"training\", \"testing\")\n        )\n    )\n\n\nYou may already have noticed something important about cross-validation: Because we have to divide the data up at random, it can give different results each time you do it! We will return to this issue.\nFor now, though, once we have divided up our data, we need to fit each model to only the training data. This looks just like it did in the previous chapter, where we are using fit_wienr to find parameter estimates for each model.\n\n\nCode\nfit_a &lt;- with(\n    all_trials_traintest %&gt;%\n        filter(set == \"training\"),\n    fit_wienr(rt = rt, response = response, fit_sv = TRUE)\n)\n\nfit_b &lt;- with(\n    all_trials_traintest %&gt;%\n        filter(set == \"training\"),\n    fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), fit_sv = TRUE)\n)\n\nfit_c &lt;- with(\n    all_trials_traintest %&gt;%\n        filter(set == \"training\"),\n    fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE)\n)\n\n\nWe can take a look at each of the fits to see what the estimated parameters are and how well each model fared on the training data:\n\n\nCode\nfit_a\n\n\n$par\n        a[1]         v[1]         w[1]        t0[1]        sv[1] \n2.091667e+00 1.159507e-01 4.695512e-01 1.982995e-01 1.731908e-10 \n\n$value\n[1] 165.1481\n\n$convergence\n[1] 1\n\n$message\n[1] \"Stopped by small gradient (grtol).\"\n\n$invhessian.lt\n [1]  9.527092e-03  1.491059e-04  1.064512e-04 -1.656450e-03  3.294452e-04\n [6]  1.339079e-02 -2.183984e-03  2.129479e-04  2.940070e-05  1.135847e-03\n[11] -1.118024e-04 -7.466557e-06  8.637283e-04 -1.958818e-04  7.797146e-01\n\n$info\n maxgradient     laststep      stepmax        neval \n2.435416e-08 2.894598e-07 1.838266e-03 2.200000e+01 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nCode\nfit_b\n\n\n$par\n      a[1]       v[1]       v[2]       w[1]      t0[1]      sv[1] \n 2.3376486  0.8377254 -0.4882018  0.4610377  0.1776323  0.4922548 \n\n$value\n[1] 148.8284\n\n$convergence\n[1] 1\n\n$message\n[1] \"Stopped by small gradient (grtol).\"\n\n$invhessian.lt\n [1]  0.0541570486  0.0358211608 -0.0340917434  0.0001095013 -0.0048551547\n [6]  0.0931226495  0.0635757612 -0.0216317695 -0.0030307138 -0.0015420380\n[11]  0.0813262103  0.0578574019 -0.0027352232  0.0020638460 -0.0799306514\n[16]  0.0012060421 -0.0001094818  0.0001507737  0.0012252126 -0.0052349758\n[21]  0.2343820376\n\n$info\n maxgradient     laststep      stepmax        neval \n5.156144e-09 7.943901e-07 1.838266e-03 2.300000e+01 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nCode\nfit_c\n\n\n$par\n      a[1]       v[1]       v[2]       w[1]      t0[1]      sv[1]      sv[2] \n 2.3478544  0.8629154 -0.4818190  0.4583973  0.1775218  0.5569940  0.4829696 \n\n$value\n[1] 148.8213\n\n$convergence\n[1] 1\n\n$message\n[1] \"Stopped by small gradient (grtol).\"\n\n$invhessian.lt\n [1]  0.0588198407  0.0499271148 -0.0276548552 -0.0016398157 -0.0047462573\n [6]  0.1222239863  0.0814171946  0.1050278210 -0.0079168106 -0.0075676409\n[11] -0.0013898078  0.1741511816  0.0577339592  0.0584003179 -0.0039679555\n[16]  0.0019161317 -0.0412546271 -0.0804351293  0.0016883348 -0.0001103656\n[21] -0.0109935932  0.0020953431  0.0012042522 -0.0045784184 -0.0048449821\n[26]  0.4517784322  0.1613120906  0.2311467565\n\n$info\n maxgradient     laststep      stepmax        neval \n3.801980e-08 2.683823e-07 5.252187e-03 2.100000e+01 \n\nattr(,\"class\")\n[1] \"ucminf\"\n\n\nAs expected, model A had the highest negative log-likelihood (i.e., the worst fit), followed by model B, with model C only doing barely better than model B. The estimated parameters for the “correct” model (B) are pretty close to those we used to simulate the data. Meanwhile, the estimated parameters for models A and C also tend to correspond pretty well with those used to generate the data (for example, the boundary separation a, response bias w, and residual time t0 for those models are all pretty close to the values we used in simulation).\nBut the real question is how well each model does with the testing data. To do that, we need to compute the negative log-likelihood of the data using the parameters estimated above. We can do that by passing the par element of the fits above as the init_par argument to the fit_wienr function and setting the return_nll argument to TRUE.\n\n\nCode\nwith(\n    all_trials_traintest %&gt;%\n        filter(set == \"testing\"),\n    fit_wienr(rt = rt, response = response, init_par = fit_a$par, fit_sv = TRUE, return_nll = TRUE)\n)\n\n\n[1] 146.1184\n\n\nCode\nwith(\n    all_trials_traintest %&gt;%\n        filter(set == \"testing\"),\n    fit_wienr(rt = rt, response = response, init_par = fit_b$par, drift_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n)\n\n\n[1] 139.8552\n\n\nCode\nwith(\n    all_trials_traintest %&gt;%\n        filter(set == \"testing\"),\n    fit_wienr(rt = rt, response = response, init_par = fit_c$par, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n)\n\n\n[1] 140.3905\n\n\nBased on these results, model A is the worst of the three, as we might have expected. But when evaluated on the testing data, model B actually fares slightly better than model C, despite the fact that model C achieved a better negative log-likelihood on the training data. This is an example of cross-validation working as intended—it has identified that model C is too flexible in this context. Model C “overfit” the training data to such an extent that it did not generalize as well to the testing data as model B.\n\n\n6.2.1.2 Repeating cross-validation\nAs noted above, though, we would get different results from cross-validation if we split the data into training/testing sets differently. To get a sense of which models are consistently able to generalize better, we need to replicate the cross-validation procedure several times, each with a different training/test split. In the code below, I use a for loop to do this. In the cv_results tibble, I keep track of the negative log-likelihood that each model achieves on both the training and testing data, so I can plot those at the end.\n\n\nCode\nn_cv &lt;- 100\n\ncv_results &lt;- c()\n\nfor (cv_index in 1:n_cv) {\n    # Split data into training/testing sets\n    all_trials_traintest &lt;- all_trials %&gt;%\n        group_by(item) %&gt;%\n        mutate(set = factor(\n                sample(rep(c(\"training\", \"testing\"), round(c(0.5, 0.5) * n())))[1:n()],\n                levels = c(\"training\", \"testing\")\n            )\n        )\n    \n    # Fit each model to the training data\n    fit_a &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"training\"),\n        fit_wienr(rt = rt, response = response, fit_sv = TRUE)\n    )\n    \n    fit_b &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"training\"),\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    fit_c &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"training\"),\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    # Evaluate each model on the testing data\n    test_nll_a &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"testing\"),\n        fit_wienr(rt = rt, response = response, init_par = fit_a$par, fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_b &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"testing\"),\n        fit_wienr(rt = rt, response = response, init_par = fit_b$par, drift_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_c &lt;- with(\n        all_trials_traintest %&gt;%\n            filter(set == \"testing\"),\n        fit_wienr(rt = rt, response = response, init_par = fit_c$par, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    # Save results of current iteration\n    cv_results &lt;- rbind(\n        cv_results,\n        tibble(\n            set = \"training\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(fit_a$value, fit_b$value, fit_c$value)\n        ),\n        tibble(\n            set = \"testing\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(test_nll_a, test_nll_b, test_nll_c)\n        )\n    )\n}\n\ncv_results %&gt;%\n    mutate(set = factor(set, levels = c(\"training\", \"testing\"))) %&gt;%\n    ggplot(aes(x = model, y = nll, color = model)) +\n    geom_point(position = position_jitter(width = 0.4), alpha = 0.1, size = 0.5) +\n    stat_summary(fun.data = mean_cl_boot) +\n    facet_wrap(\"set\", scales = \"free_y\") +\n    labs(x = \"Model\", y = \"Negative log-likelihood\")\n\n\n\n\n\nSmall, light points show each individual cross-validation run, the large points show the mean and bootstrapped 95% confidence interval across runs.\n\n\n\n\nNotice that model C does, on average, achieve a slightly better NLL than model B on the training data. Specifically, the average NLL for model B on the training data is 141.9735778 and for model C is 141.4932351. However, model B achieves a slightly better NLL than model C on the testing data (146.5512123 for model B, 146.6566674 for model C). These differences are not particularly large, of course, but they show the basic idea behind cross-validation as an approach to model comparison.\n\n\n\n6.2.2 \\(K\\)-fold cross-validation\nIn the example above, the testing and training sets were the same size. This is not terribly efficient. Because the models are only being fit to half the data, there is more variability/uncertainty in the estimated parameters than there would be if they were fit to the entire dataset. As such, in most applications of cross-validation, the training set is larger than the testing set.\nThese applications are often referred to as “\\(K\\)-fold cross-validation” because they involve splitting the data into \\(K\\) evenly-sized sets and then performing cross-validation \\(K\\) times. Each time, a different one of the \\(K\\) sets is treated as the “testing” data, with the remaining \\(K - 1\\) sets used for training. A common choice for \\(K\\) is 10, such that the proportion of data “left out” for testing is 0.1, not 0.5.\nLet’s see how we would implement \\(K\\)-fold cross-validation in our running example. The first step is to split the data into \\(K\\) equal sets. The code below shows one way to do this using the sample function like we did in the example above. Notice that we use the rep function to repeat each index ceiling(n() / K) times. The ceiling function rounds any fractional amounts up, so we will always have at least as many indexes to sample from as we have trials. The [1:n()] truncates the vector of repeated indices so that it has exactly n() elements.\n\n\nCode\nK &lt;- 10\n\nall_trials_split &lt;- all_trials %&gt;%\n    group_by(item) %&gt;%\n    mutate(set = sample(rep(1:K, ceiling(n() / K))[1:n()]))\n\n\nThe result looks like this, although it is worth keeping in mind that different runs will produce different splits since they are done randomly.\n\n\nCode\nall_trials_split\n\n\n# A tibble: 200 × 4\n# Groups:   item [2]\n      rt response item     set\n   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt;\n 1 1.29  upper    Target     4\n 2 0.973 upper    Target     9\n 3 0.695 upper    Target     6\n 4 1.75  upper    Target     1\n 5 1.17  upper    Target     4\n 6 1.18  upper    Target     8\n 7 1.91  upper    Target     2\n 8 1.46  upper    Target    10\n 9 0.988 upper    Target     3\n10 0.554 upper    Target     2\n# ℹ 190 more rows\n\n\nOnce we have split the data, we can adapt the for loop we used earlier so that it loops over the \\(K\\) folds in the splitted data.\n\n\nCode\nk_fold_cv_results &lt;- c()\n\nfor (fold in 1:K) {\n    # Fit each model to the training data\n    fit_a &lt;- with(\n        all_trials_split %&gt;%\n            filter(set != fold),\n        fit_wienr(rt = rt, response = response, fit_sv = TRUE)\n    )\n    \n    fit_b &lt;- with(\n        all_trials_split %&gt;%\n            filter(set != fold),\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    fit_c &lt;- with(\n        all_trials_split %&gt;%\n            filter(set != fold),\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    # Evaluate each model on the testing data\n    test_nll_a &lt;- with(\n        all_trials_split %&gt;%\n            filter(set == fold),\n        fit_wienr(rt = rt, response = response, init_par = fit_a$par, fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_b &lt;- with(\n        all_trials_split %&gt;%\n            filter(set == fold),\n        fit_wienr(rt = rt, response = response, init_par = fit_b$par, drift_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_c &lt;- with(\n        all_trials_split %&gt;%\n            filter(set == fold),\n        fit_wienr(rt = rt, response = response, init_par = fit_c$par, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    # Save results of current iteration\n    k_fold_cv_results &lt;- rbind(\n        k_fold_cv_results,\n        tibble(\n            fold = fold,\n            set = \"training\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(fit_a$value, fit_b$value, fit_c$value)\n        ),\n        tibble(\n            fold = fold,\n            set = \"testing\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(test_nll_a, test_nll_b, test_nll_c)\n        )\n    )\n}\n\nk_fold_cv_results %&gt;%\n    mutate(set = factor(set, levels = c(\"training\", \"testing\"))) %&gt;%\n    ggplot(aes(x = model, y = nll, color = model)) +\n    geom_point(position = position_jitter(width = 0.1), alpha = 0.5, size = 0.5) +\n    stat_summary(fun.data = mean_cl_boot) +\n    facet_wrap(\"set\", scales = \"free_y\") +\n    labs(x = \"Model\", y = \"Negative log-likelihood\")\n\n\n\n\n\n\n\n\n\nThe result looks pretty similar to what we had previously, in that model C fits slightly better than model B on the training data, but they fare about equally well on the testing data.\n\n\n6.2.3 Leave-one-out cross-validation\nAs a reminder, each time we run \\(K\\)-fold cross-validation, we will get a slightly different result because of the random way in which we split the data. Moreover, using \\(K\\)-fold CV was motivated by an attempt to make efficient use of the data at hand, so as not to artificially inflate our uncertainty about estimated model parameters. If we take these two issues—randomness and efficiency—seriously, then the best way to do cross-validation would actually be to have as many “folds” as we have observations. In other words, we fit each model to all but one observation and then test them on the one that we left out and repeat this process for all \\(N\\) observations in our dataset. That solves the efficiency problem, since the models are able to train on essentially all of the data. It also solves the randomness problem because instead of doing CV with random subsets, we do it exhaustively, once for each observation. This approach is, prosaically, referred to as Leave-One-Out Cross-Validation (LOOCV).\nWe said LOOCV resolves the “efficiency” issue with cross-validation, but only in the sense that the models are able to make use of nearly all the data. LOOCV is certainly not efficient in terms of computing time, since it requires fitting each model \\(N\\) times, once for each left-out observation. We typically apply computational cognitive models to data from experiments where we have a few hundred trials per participant (and we would need to replicate LOOCV for each participant too). Moreover, as we’ve seen, estimating best-fitting parameters even for a relatively simple cognitive model like a diffusion model is not trivial. Therefore, LOOCV is almost never used in practice.\nFor fun, though, let’s try it with our running example, where the code below adapts the \\(K\\)-fold CV code we used in the previous section. Note the use of the “negative indexing” trick to exclude each observation i from the training data in the for loop.\n\n\nCode\nloocv_results &lt;- c()\n\nfor (i in 1:nrow(all_trials)) {\n    # Fit each model to the training data\n    fit_a &lt;- with(\n        all_trials[-i,],\n        fit_wienr(rt = rt, response = response, fit_sv = TRUE)\n    )\n    \n    fit_b &lt;- with(\n        all_trials[-i,],\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    fit_c &lt;- with(\n        all_trials[-i,],\n        fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE)\n    )\n    \n    # Evaluate each model on the testing data\n    test_nll_a &lt;- with(\n        all_trials[i,],\n        fit_wienr(rt = rt, response = response, init_par = fit_a$par, fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_b &lt;- with(\n        all_trials[i,],\n        fit_wienr(rt = rt, response = response, init_par = fit_b$par, drift_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    test_nll_c &lt;- with(\n        all_trials[i,],\n        fit_wienr(rt = rt, response = response, init_par = fit_c$par, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE, return_nll = TRUE)\n    )\n    \n    # Save results of current iteration\n    loocv_results &lt;- rbind(\n        loocv_results,\n        tibble(\n            fold = i,\n            set = \"training\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(fit_a$value, fit_b$value, fit_c$value)\n        ),\n        tibble(\n            fold = i,\n            set = \"testing\",\n            model = c(\"A\", \"B\", \"C\"),\n            nll = c(test_nll_a, test_nll_b, test_nll_c)\n        )\n    )\n}\n\nloocv_results %&gt;%\n    mutate(set = factor(set, levels = c(\"training\", \"testing\"))) %&gt;%\n    ggplot(aes(x = model, y = nll, color = model)) +\n    geom_point(position = position_jitter(width = 0.1), alpha = 0.1, size = 0.5) +\n    stat_summary(fun.data = mean_cl_boot) +\n    facet_wrap(\"set\", scales = \"free_y\") +\n    labs(x = \"Model\", y = \"Negative log-likelihood\")\n\n\n\n\n\n\n\n\n\nConsistent with the other varieties of CV above, LOOCV finds that model A generalizes the worst on average (mean testing NLL = 1.5718645), followed by model C (mean testing NLL = 1.4550586) then closely by model B ((mean testing NLL = 1.453186)). Again, the difference between models B and C is not dramatic, but consider that model C consistently outperforms model B on the training data—the message that we get from LOOCV is that this advantage is due to overfitting, not because model C captures anything systematic beyond that which is captured by model B. Therefore, we should prefer the simpler model B when deciding which model best explains our data.\n\n\n6.2.4 Summary\nCross-validation is not always the most practical approach to assessing model fit vs. complexity. That said, it shows one reason why we might prefer a simpler model: Such a model is less likely to “overfit” our data and is therefore better able to generalize to new data. This has practical advantages if we are using the model to make predictions about future unseen data. It is also theoretically meaningful because a model that generalizes better is probably one that has mechanisms that are important for producing the systematic features of our data.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "model_comparison.html#akaike-information-criterion",
    "href": "model_comparison.html#akaike-information-criterion",
    "title": "6  Model complexity and model comparison",
    "section": "6.3 Akaike Information Criterion",
    "text": "6.3 Akaike Information Criterion\nThe practical issues with cross-validation mean that it is rarely used to compare cognitive models. That said, one of the model comparison approaches we saw in the last chapter, the Akaike Information Criterion (AIC; Akaike (1974)), is in fact an asymptotic approximation to LOOCV. We won’t prove this fact here, but check out Stone (1977). For our purposes, we can simply appreciate that the asymptotic equivalence of AIC and LOOCV is very convenient because it means that we can often reasonably approximate LOOCV while only needing to fit the model once.\nLet’s calculate the AIC for each of the three models in our running example. To do this, we will first need to fit each model to the full dataset (no more splitting into testing/training sets). This is done in the chunk of code below.\n\n\nCode\nfit_a &lt;- with(\n    all_trials,\n    fit_wienr(rt = rt, response = response, fit_sv = TRUE)\n)\n\nfit_b &lt;- with(\n    all_trials,\n    fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), fit_sv = TRUE)\n)\n\nfit_c &lt;- with(\n    all_trials,\n    fit_wienr(rt = rt, response = response, drift_index = as.numeric(item), sv_index = as.numeric(item), fit_sv = TRUE)\n)\n\n\nNow recall that the AIC is defined as\n\\[\nAIC = 2 \\times NLL + 2 \\times N_p\n\\]\nwhere \\(NLL\\) is the negative log-likelihood of the fitted model and \\(N_p\\) is the number of free parameters in the model. Thus, the code below computes the AIC for each of the three models\n\n\nCode\n2 * fit_a$value + 2 * length(fit_a$par)\n\n\n[1] 630.4553\n\n\nCode\n2 * fit_b$value + 2 * length(fit_b$par)\n\n\n[1] 583.0139\n\n\nCode\n2 * fit_c$value + 2 * length(fit_c$par)\n\n\n[1] 583.6266\n\n\nLike with cross-validation above, AIC finds that model A is the worst and that model B has a slight advantage over model C.\nReturning to LOOCV for a moment, recall that the value we obtained was the mean negative log-likelihood across each of the \\(N\\) left-out observations. Meanwhile, the \\(NLL\\) we get from fitting the full model is the summed negative log-likelihood across all \\(N\\) observations. So if we want to put the results from LOOCV on the same scale as the results we get from AIC, we need to multiply them by \\(2N\\). I do this in the chunk of code below.\n\n\nCode\nloocv_results %&gt;%\n    filter(set == \"testing\") %&gt;%\n    group_by(model) %&gt;%\n    summarize(rescaled_result = 2 * sum(nll))\n\n\n# A tibble: 3 × 2\n  model rescaled_result\n  &lt;chr&gt;           &lt;dbl&gt;\n1 A                629.\n2 B                581.\n3 C                582.\n\n\nAlthough the reader is again referred to Stone (1977) for a formal proof, this example shows that, when appropriately rescaled, AIC and LOOCV give very similar results and will generally lead us to the same conclusions regarding which of a set of models to prefer.\nThis rough equivalence also shows that AIC ultimately assesses models on their predictive performance, that is, their ability to fit future unseen data generated by the same processes that produced our original data.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "model_comparison.html#bayes-factors-and-bayesian-information-criterion",
    "href": "model_comparison.html#bayes-factors-and-bayesian-information-criterion",
    "title": "6  Model complexity and model comparison",
    "section": "6.4 Bayes Factors and Bayesian Information Criterion",
    "text": "6.4 Bayes Factors and Bayesian Information Criterion\nIn the last chapter, we were introduced to another model comparison metric, the so-called “Bayesian” Information Criterion [BIC; Schwarz (1978)]. The BIC is, under certain very restrictive circumstances, asymptotically equivalent to a Bayes Factor (Raftery, 1995). The relationship between AIC/LOOCV and the Bayes factor/BIC can be summarized like this: AIC/LOOCV assess the ability of a model to fit future data conditional on the data that has already been observed; Bayes factors/BIC assess the ability of a model to fit any data, irrespective of the data that has already been observed. In other words, AIC/LOOCV assess the posterior predictive ability of a model whereas BIC/Bayes Factors assess the prior predictive ability of a model (Gelman et al., 2014; Piironen & Vehtari, 2017; Vehtari & Lampinen, 2002).\nIt is worth repeating that BIC does not have the same formal relationship to Bayes factors that AIC has to LOOCV, so BIC should not be thought of, outside of very special cases, as equivalent to a Bayes factor. Nonetheless, it has the same underlying motivation, which is to favor models that make more limited predictions a priori. This is why the formula for BIC imposes a stronger penalty for the number of free parameters in a model, because the flexibility afforded by those parameters doesn’t just allow the model to “overfit” the data we observed, it allows it to overfit any data we might have observed.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "model_comparison.html#simplicity-vs.-complexity",
    "href": "model_comparison.html#simplicity-vs.-complexity",
    "title": "6  Model complexity and model comparison",
    "section": "6.5 Simplicity vs. Complexity",
    "text": "6.5 Simplicity vs. Complexity\nUltimately, model comparison allows us to answer the question, “what is the simplest model, among those I am considering, that is sufficient to achieve a good quantiative fit to the data in my sample?” By laying out this question explicitly, we are in a position to see three of the important qualifiers on any conclusions we draw based on model comparisons:\n\nDefining “simplicity”: Different model comparison metrics have different operational definitions of “simplicity”. AIC and BIC each define it in terms of the number of free parameters in a model. Cross-validation defines it in terms of how well a model fit to training data can account for test data. A Bayes factor defines it in terms of the prior predictive distribution of a model, etc.\nConditional on the set of models being compared: Although it may be possible to identify a “preferred” model using a model comparison metric, that preference is only with respect to the set of models being compared. It is entirely possible that an additional unconsidered model would be preferred if it were included. It may also be the case that the “preferred” model is only the “least bad” model among those under consideration—that’s why it is always important to verify that a model is actually reproducing the data patterns that you think are most important in your application.\nConditional on the sample: It may be that a different sample would have lead to a different “preferred” model, although as noted above, model comparison metrics are usually designed to account for this form of sampling variability. This qualification is more important when attempting to generalize more broadly, for example, to other kinds of related tasks or to the same task but with different materials.\n\nOften, model comparison is analogized to “Occam’s Razor”, the famous principle that, if many explanations are available, we should prefer the simplest one. The issue with this analogy is that it conflates two ways in which a model can be “simple”: A model can be “simple” according to one of the operational definitions of simplicity/complexity employed by a particular model comparison metric. But a model can also be “simple” in the sense that it is easier for a scientist to understand or to describe to someone else. The first sense of “simplicity” can be quantified (as in the methods reviewed in this chapter), but the second sense of “simplicity” is more to do with the background and expertise of particular scientists, the means by which they communicate, and the broader culture in which they are working. In other words, the second sense of “simplicity” has to do with the fact that a causal model is not meant just to fit data, but also to help people understand why the data turned out that way. As the bumper sticker says, scientists are people too and, being limited creatures, cannot understand everything. This second sense of simplicity should not be dismissed, though: If someone can understand a model more easily, they may also be able to devise predictions, tests, and extensions of the model more easily too.\nBecause the two senses of “simplicity” are separate, they are not guaranteed to align with one another. There may be cases in which a model that is “simple” in the sense of having few free parameters or a narrow prior predictive distribution may be very difficult to explain or describe. It is also possible that a model that is easier to explain or describe might be more flexible or have more parameters than needed to account for any particular sample of data. The latter situation is likely to occur if a model is designed to account for a wide variety of phenomena—such a model may contain mechanisms (with associated parameters) that are only relevant for certain phenomena.\nIt is also worth repeating that a simpler model—regardless of the sense of “simplicity”—is not guaranteed to be any more “true” or “correct” than a complex model. The “truth”, whatever that is, is almost certainly more complex than any model we would devise. Rather, given that all models are deliberate simplifications, the virtue of a simpler model is that (a) it is more likely to generalize well because it is less likely that its ability to fit data is due to some idiosyncratic property of the model or the sample; and (b) it is often (but not always) easier to describe and explain.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "model_comparison.html#exercises",
    "href": "model_comparison.html#exercises",
    "title": "6  Model complexity and model comparison",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\n\nThe discussions of cross-validation and generalization in this chapter focused on situations in which we wanted to “generalize” to data from the same (simulated) participant in the same (simulated) task. How would you adapt cross-validation to assess other kinds of generalization, such as from one participant to another? Or from one task to another? In formulating your thoughts, you may want to read Busemeyer & Wang (2000) and Navarro (2018).\nUnlike in cognitive modeling, where cross-validation is rarely used, machine learning models are often compared using cross-validation. Models in machine learning sit on the “descriptive” end of the modeling spectrum. Machine learning models are typically applied to very large datasets and have a lot of free parameters (e.g., each weight in a neural network model is technically a free parameter). Why do you think cross-validation is more common in machine learning than in cognitive modeling?\nGiven that AIC and BIC judge models according to different criteria, which do you think is better suited for identifying the model the “best explains” a given set of data? What reasons might there be to prefer one approach over the other? Could the term “explain” have different interpretations in different applications?\n\n\n\n\n\nAkaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19(6), 716–723.\n\n\nArlot, S., & Celisse, A. (2010). A survey of cross-validation procedures for model selection. Statistics Surveys, 4, 40–79. https://doi.org/10.1214/09-SS054\n\n\nBrowne, M. W. (2000). Cross-validation methods. Journal of Mathematical Psychology, 44(1), 108–132. https://doi.org/10.1006/jmps.1999.1279\n\n\nBusemeyer, J. R., & Wang, Y.-M. (2000). Model comparisons and model selections based on generalization criterion methodology. Journal of Mathematical Psychology, 44(1), 171–189. https://doi.org/10.1006/jmps.1999.1282\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. Statistics and Computing, 24(6), 997–1016. https://doi.org/10.1007/s11222-013-9416-2\n\n\nNavarro, D. J. (2018). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior. https://doi.org/10.1007/s42113-018-0019-z\n\n\nPiironen, J., & Vehtari, A. (2017). Comparison of bayesian predictive methods for model selection. Statistics and Computing, 27(3), 711–735. https://doi.org/10.1007/s11222-016-9649-y\n\n\nRaftery, A. E. (1995). Bayesian model selection in social research. Sociological Methodology, 25, 111–163. https://doi.org/10.2307/271063\n\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2), 461–464.\n\n\nStone, M. (1977). An asymptotic equivalence of choice of model by cross-validation and Akaike’s criterion. Journal of the Royal Statistical Society. Series B (Methodological), 39(1), 44–47.\n\n\nVehtari, A., & Lampinen, J. (2002). Bayesian model assessment and comparison using cross-validation predictive densities. Neural Computation, 14(10), 2439–2468. https://doi.org/10.1162/08997660260293292\n\n\nZucchini, W. (2000). An introduction to model selection. Journal of Mathematical Psychology, 44(1), 41–61. https://doi.org/10.1006/jmps.1999.1276",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model complexity and model comparison</span>"
    ]
  },
  {
    "objectID": "blast_example.html",
    "href": "blast_example.html",
    "title": "7  A worked example",
    "section": "",
    "text": "7.1 The data\nThe data for this example were reported originally by Trueblood et al. (2018). There’s a lot about this study that we won’t get to here, and I encourage you to check out the original paper.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#the-data",
    "href": "blast_example.html#the-data",
    "title": "7  A worked example",
    "section": "",
    "text": "7.1.1 Participants and procedures\nParticipants in this study did several blocks of a categorization task. The stimuli used in this task were images of cells that were either indicative of cancer—these are called “blast” cells—or normal—these are “non-blast” cells. The images were further subdivided into “easy” and “hard” versions, based on expert judgments. The image below illustrates the kinds of images that participants would see in this task.\n\n\nCode\nknitr::include_graphics(\"img/blast_example_stimuli.png\")\n\n\n\n\n\n(a) An easy blast image. (b) A hard blast image. (c) An easy non-blast image. (d) A hard non-blast image.\n\n\n\n\nAfter several blocks of training in which participants became familiar with these kinds of images (if they were not already; see below), participants moved on to the categorization task. On each trial of this task, an image was shown. Blast and non-blast images were shown equally often. Easy and hard versions of each type were also shown at the same rates. The participant’s job was to decide whether or not each image was a “blast” cell. The categorization task was itself divided into several blocks, each of which was a different type. We will be looking at data from two types of block: “Accuracy” blocks in which participants were encouraged to take their time and be accurate in their categorization of each image; and “Speed” blocks in which participants were encouraged to make their decisions quickly without regard to accuracy.\nThe participants in this study came from three different groups. Novice participants were just that—typical undergraduate university students who had no prior experience with these kinds of medical images. Inexperienced participants were pathologists who had just begun their training, so while they would be knowledgeable about these kinds of images, they might not have much practice categorizing them. Experienced participants were pathologists who had completed at least four training rotations who would have had plenty of practice dealing with these kinds of images.\nFinally, I note that, in addition to the blast/non-blast categorization task, all participants did a “Novel Object Memory Task” (NOMT) designed to measure their general ability to recognize visual objects, not just medical images of cells.\n\n\n7.1.2 Getting the data\nYou can download the data from this study that we will be examining in this tutorial by running the code below. The first line downloads the data to a file called blast_data.rdata in your current working directory. The second line loads that data into your R environment.\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/blast_data.rdata\", \"blast_data.rdata\")\nload(\"blast_data.rdata\")\n\n\nThe data should now be in your R environment in a data frame called blast_data. Let’s take a look at that data now:\n\n\nCode\nglimpse(blast_data)\n\n\nRows: 21,628\nColumns: 15\n$ dateCompleted    &lt;chr&gt; \"30/6/2017 @ 10:15:24\", \"30/6/2017 @ 10:15:26\", \"30/6…\n$ block            &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ blockType        &lt;fct&gt; Speed, Speed, Speed, Speed, Speed, Speed, Speed, Spee…\n$ trial            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17…\n$ stimulus         &lt;chr&gt; \"nonBlastEasy/SNE_25598565.jpg\", \"blastHard/BL_406213…\n$ difficulty       &lt;fct&gt; Easy, Hard, Easy, Hard, Hard, Easy, Easy, Hard, Easy,…\n$ response         &lt;fct&gt; Non-blast, Blast, Blast, Blast, Non-blast, Non-blast,…\n$ rt               &lt;dbl&gt; 0.662, 0.496, 0.528, 0.431, 0.817, 0.495, 0.540, 0.68…\n$ correct_response &lt;fct&gt; Non-blast, Blast, Blast, Blast, Blast, Non-blast, Non…\n$ bias_shown       &lt;fct&gt; Bias not shown, Bias not shown, Bias not shown, Bias …\n$ subject          &lt;chr&gt; \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002…\n$ group            &lt;fct&gt; Experienced, Experienced, Experienced, Experienced, E…\n$ nomt_corr        &lt;dbl&gt; 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 9…\n$ nomt_n           &lt;int&gt; 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108…\n$ nomt             &lt;dbl&gt; 0.9166667, 0.9166667, 0.9166667, 0.9166667, 0.9166667…\n\n\nWe can already see the columns that will be most important for us:\n\nblockType: Whether the block instructions emphasized Accuracy or Speed.\ncorrect_response: Whether the image on that trial was a Blast or Non-blast cell.\ndifficulty: Whether the image on that trial was Easy or Hard.\nrt: The response time (RT) in seconds.\nresponse: Whether the participant classified the image as a Blast or Non-blast cell.\nsubject: An identifier for each individual participant.\ngroup: Which of the three groups the participant came from (Experienced, Inexperienced, or Novice).\nnomt: The score on the Novel Object Memory Test (NOMT) for the participant on that trial.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#a-single-participant",
    "href": "blast_example.html#a-single-participant",
    "title": "7  A worked example",
    "section": "7.2 A single participant",
    "text": "7.2 A single participant\nIn the next section, we will fit a diffusion model to data from every participant. Before we do that, though, let’s see how to do it for a single participant. We will replicate this procedure for each individual participant in the next section.\n\n7.2.1 A single participant’s data\nI arbitrarily picked the participant with ID “M003” for us to examine. The code below uses the filter function to extract the data from just this participant:\n\n\nCode\nsubj_data &lt;- blast_data %&gt;%\n    filter(subject == \"M003\")\n\n\n\n\n7.2.2 Grouping the trials\nFor the next bit, make sure that you have sourced the wienr_fit_utils.r script:\n\n\nCode\nsource(\"wienr_fit_utils.r\")\n\n\nIf we omit the par argument, we can use the qp_fit function to get the observed response proportions and RT quantiles and make a quantile-probability plot of the observed data. However, to do this, we need to decide how to group the individual trials using the “indexing” trick we used in the last chapter. The way we do this will ultimately inform what diffusion model parameters we will estimate, so it is worth putting in the thought now.\nSpecifically, we need to think about what factors would influence the drift rate of the evidence being accumulated on each trial, what factors would influence how the participant sets their response boundaries on a given trial, and what factors might influence the residual time on each trial. Later, we will also consider how trial-by-trial variability in these three aspects of the model might or might not vary between conditions.\n\n7.2.2.1 What factors influence drift rates?\nThe “evidence” in this task arises from some kind of evaluation of how much the image looks like what the participant thinks of as a “blast” cell versus a “non-blast” cell. In other words, the “evidence” should depend on whether the image on that trial shows a blast or non-blast cell, just like how “evidence” in recognition memory depends on whether the test item is a target or foil. In addition, we would expect “hard” images to yield worse evidence than “easy” images, by definition. These two aspects of the data are reflected in the difficulty and correct_response columns. So we can specify a drift_index based on the interaction between these two factors.\nThe emphasis of the current block—Accuracy vs. Speed—could also impact drift rates (Rae et al., 2014), though exploring that possibility is left as an exercise for the reader.\n\n\n7.2.2.2 What factors influence response boundaries?\nThe response boundaries cannot be influenced by the type of image shown on a trial—if they were, then the participant would already know what kind of image they were seeing! On the other hand, it is reasonable to expect that participants would adjust their response boundaries depending on whether the current block emphasized speed or accuracy. This suggests that we can define a bound_index using the blockType column in the data.\n\n\n7.2.2.3 What factors influence residual time?\nIf residual time reflects only the processes involved in executing the motor response associated with a choice, then we might expect it to be unaffected by any experimental factors. On the other hand, it may be that participants are able to adjust their “response vigor” in light of speed/accuracy emphasis. In addition, it may be that participants can more quickly orient their attention to a stimulus if speed is emphasized. So we can specify a resid_index that also depends on blockType.\n\n\n7.2.2.4 Defining indices\nOn the basis of the considerations above, we will define three indices: one that specifies what conditions can have different drift rates (drift_index), one that specifies what conditions can have different response boundaries (bound_index), and one that specifies what conditions can have different residual time (resid_index):\n\n\nCode\nsubj_data &lt;- subj_data %&gt;%\n    mutate(\n        drift_index = as.numeric(interaction(difficulty, correct_response)),\n        bound_index = as.numeric(blockType),\n        resid_index = as.numeric(blockType)\n    )\n\n\nIt is important to keep in mind that the grouping defined above is not necessarily the “one true grouping”! It is merely meant to give a sense of the kind of things to think about when deciding how different model parameters will be assigned to different conditions.\n\n\n\n7.2.3 Plotting the observed data\nHaving defined our indices, we can pass them to the qp_fit function so that we can make a quantile-probability plot of this participant’s data. Note that I had to\n\n\nCode\nobs_qp &lt;- qp_fit(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\n\n\nWhen making the plot, I found it helpful to “undo” the transformation of the different factors into numerical indices. That “undoing” is the purpose of the two mutate lines.\n\n\nCode\nobs_qp %&gt;%\n    mutate(item_type = factor(drift_index, levels = 1:4, labels = levels(interaction(blast_data$difficulty, blast_data$correct_response)))) %&gt;%\n    mutate(blockType = factor(bound_index, levels = 1:2, labels = levels(blast_data$blockType))) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = item_type, shape = response)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT quantile\") +\n    facet_wrap(\"blockType\")\n\n\n\n\n\n\n\n\n\nIt is worth noting a few features of these data that are apparent from the quantile-probability plot. First, this participant was indeed faster in the Speed block than the Accuracy block. Even the faster RT’s (the 0.1 quantiles) are faster in the Speed block, supporting the idea that residual time could differ between blocks if residual time represents the minimal time needed to respond. It also looks like this participant was less accurate in the Speed block—at least for Blast images, they had nearly perfect accuracy in the Accuracy block but not in the speed block. This participant was not very good in either block at categorizing Non-blast images. It doesn’t look like difficulty (Easy vs. Hard) made a big difference for this participant in terms of their choice/RT behavior. Finally, it looks like this participant’s errors tended to be a bit slower than their correct responses, suggesting that the diffusion model will need to allow for trial-by-trial variability in drift rates to accommodate these data. This same consideration suggests that we don’t need to assume variability in boundaries (since that would produce fast errors instead).\n\n\n7.2.4 Fitting a diffusion model\nWith all the preliminaries out of the way, let’s try fitting a diffusion model to this participant’s data. This will look just like it did in the last chapter, only with real data instead of simulated data!\nWe have already decided how to assign parameters to trials using the indices we defined in the previous section. We also have good reason to believe that drift rates can vary from trial to trial. We can estimate \\(s_v\\), the standard deviation of the trial-by-trial distribution of drift rates, by including the argument fit_sv = TRUE to the fit_wienr function. We don’t have reason to assume variability in boundaries, which would be reflected in the \\(s_w\\) parameter, but we could do so if we passed fit_sw = TRUE to fit_wienr. Finally, we will allow for variability in residual time by including fit_st0 = TRUE in the function call to fit_wienr.\nFor present purposes, we will only estimate one value of \\(s_v\\) and one value of \\(s_{t_0}\\) parameter, and these values will apply to all trials. If we wanted to allow them to vary, we could pass a sv_index, sw_index, or st0_index vector to the fit_wienr function—these index vectors work just like the drift_index, bound_index, and resid_index vectors we defined above.\nPutting it all together, the code below fits our desired diffusion model to this participant’s choice and RT data.\n\n\nCode\nsubj_fit &lt;- fit_wienr(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    fit_sv = TRUE,\n    fit_sw = FALSE,\n    fit_st0 = TRUE,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\n\nLet’s have a look at the estimated parameter values:\n\n\nCode\nsubj_fit$par\n\n\n      a[1]       a[2]       v[1]       v[2]       v[3]       v[4]       w[1] \n 1.3875689  0.9074497 -0.9075545 -0.3305451  1.5610599  1.6110799  0.6583813 \n      w[2]      t0[1]      t0[2]      sv[1]     st0[1] \n 0.6743305  0.3969458  0.3926721  0.7117295  0.1218538 \n\n\nThe first two parameters are the response caution parameters, with a[1] corresponding to the Accuracy blocks and a[2] to the Speed blocks. As we might expect, the fact thata a[2] \\(&lt;\\) a[1] tells us that this participant was less cautious in the Speed blocks, being more willing to sacrifice accuracy for speed. Skipping ahead to w[1] and w[2], these parameters tell us that this participant was biased toward calling images “Blast” images in both Accuracy and Speed blocks (the response caution and response bias parameters have the same indices). Although we allowed for residual time to vary between Accuracy and Speed blocks, the estimates t0[1] and t0[2] look pretty similar to one another.\nThe drift rate parameters also make some sense: v[1], for easy non-blast images, is negative and has a greater magnitude than v[2], for hard non-blast images. The magnitudes of the drift rates for Blast images, v[3] and v[4], are greater than for the non-blast images and are not too different from one another, in accord with our observation that this participant was better at identifying blast images than non-blasts and that the difficulty of the blast image didn’t seem to matter much.\nFinally, we can see that the drift-rate variability parameter sv[1] and the residual time variability parameter st0[1] are both greater than zero. That said, we did not have strong theoretical reasons to expect these parameters to take any particular value—we just suspected they would be important to account for the data. We can verify that intuition by fitting a model without any trial-by-trial variability and seeing whether AIC and/or BIC still prefers the more complex model with both forms of variability.\n\n\nCode\nsubj_fit_novar &lt;- fit_wienr(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    fit_sv = FALSE,\n    fit_sw = FALSE,\n    fit_st0 = FALSE,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\naic_wvar &lt;- 2 * subj_fit$value + 2 * length(subj_fit$par)\naic_novar &lt;- 2 * subj_fit_novar$value + 2 * length(subj_fit_novar$par)\n\nbic_wvar &lt;- 2 * subj_fit$value + log(nrow(subj_data)) * length(subj_fit$par)\nbic_novar &lt;- 2 * subj_fit_novar$value + log(nrow(subj_data)) * length(subj_fit_novar$par)\n\nc(aic_wvar, aic_novar)\n\n\n[1]  8.878357 64.029238\n\n\nCode\nc(bic_wvar, bic_novar)\n\n\n[1]  56.68559 103.86860\n\n\nBoth AIC and BIC are lower for the model with trial-by-trial variability, suggesting that this additional complexity is warranted in light of the data.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#all-the-participants",
    "href": "blast_example.html#all-the-participants",
    "title": "7  A worked example",
    "section": "7.3 All the participants",
    "text": "7.3 All the participants\nHaving fit a diffusion model to one participant, we will now replicate that procedure for every participant. First, it will be convenient to define our three index vectors using the whole dataset:\n\n\nCode\nblast_data &lt;- blast_data %&gt;%\n    mutate(\n        drift_index = as.numeric(interaction(difficulty, correct_response, drop = TRUE)),\n        bound_index = as.numeric(blockType),\n        resid_index = as.numeric(blockType)\n    )\n\n\nNow comes the big stuff. We will write a for loop that does the following for each participant:\n\nExtracts that participant’s data from the complete dataset.\nFits a diffusion model to that participant’s data.\nExtracts the estimated parameters for that participant and saves them in a data frame called model_pars. This is so we can examine the estimated parameters later.\nComputes both observed and model-produced RT quantiles and response probabilities and saves them in a data frame called model_qp. This is so we can verify that the model is fitting the data.\n\nAll of that is accomplished with the following chunk of R code, which begins by using the unique function to extract all the unique participant ID’s in the dataset. Note that this is used to define what the for loop iterates over. This will take a while to run, but patience is a virtue!\n\n\nCode\nsubj_to_fit &lt;- unique(blast_data$subject)\n\nmodel_pars &lt;- c()\nmodel_qp &lt;- c()\n\nfor (id in subj_to_fit) {\n    this_subj_data &lt;- blast_data %&gt;%\n        filter(subject == id)\n    \n    this_fit &lt;- fit_wienr(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        fit_sv = TRUE,\n        fit_sw = FALSE,\n        fit_st0 = TRUE,\n        drift_index = this_subj_data$drift_index,\n        bound_index = this_subj_data$bound_index,\n        resid_index = this_subj_data$resid_index\n    )\n    \n    model_pars &lt;- rbind(\n        model_pars,\n        tibble(subject = id, group = this_subj_data$group[1], par_name = names(this_fit$par), val = this_fit$par) %&gt;% extract(par_name, into = c(\"par\", \"index\"), regex = \"(.+)\\\\[(.+)\\\\]\")\n    )\n    \n    this_qp &lt;- qp_fit(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        par = this_fit$par,\n        drift_index = this_subj_data$drift_index,\n        bound_index = this_subj_data$bound_index,\n        resid_index = this_subj_data$resid_index\n    ) %&gt;%\n        mutate(subject = id, group = this_subj_data$group[1])\n    \n    model_qp &lt;- rbind(\n        model_qp,\n        this_qp\n    )\n}\n\n\n\n7.3.1 Comparing parameters between groups\nOnce we have our parameter estimates safely stored in model_pars, we can visualize the resulting estimates using color to distinguish between the three groups. The plot below was made by using tiny, slightly faded points for each individual participant (note the alpha = 0.5, size = 0.5 settings in the geom_point line). Overlaid on those is a big point with error bars that shows the mean and 95% confidence interval for the mean, computed separately for each group.\n\n\nCode\nmodel_pars %&gt;%\n    ggplot(aes(x = index, y = val, color = group, shape = group)) +\n    geom_point(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.4), alpha = 0.5, size = 0.5) +\n    stat_summary(geom = \"pointrange\", fun.data = mean_cl_boot, position = position_dodge(width = 0.4)) +\n    labs(x = \"Index\", y = \"Estimated value\", color = \"Group\") +\n    facet_wrap(\"par\", scales = \"free\")\n\n\n\n\n\n\n\n\n\n\n7.3.1.1 Response caution\nLet’s focus first on a, the response caution parameter. As we know, a[1] corresponds to the Accuracy blocks while a[2] corresponds to the Speed blocks. It certainly looks like participants, on average, had lower response caution in the Speed blocks than in the Accuracy blocks. It also looks like the more experienced participants tended to have greater response caution in both block types.\nTo get some statistical evidence for differences between groups and between conditions, we can use our old friend, the Analysis of Variance (ANOVA). While you might normally think of applying ANOVA to observed values, like mean response time or accuracy, it can be applied just as well to estimated parameter values. In both cases, we have a single value for each participant in each condition and we are testing the null hypothesis that the parameter estimate does not differ, on average, between conditions/groups.\nTo do ANOVA, I’ll use the afex R package and make sure to run its set_sum_contrasts() function (by default, R uses “treatment” contrasts, which are not always appropriate).\n\n\nCode\nlibrary(afex)\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n************\nWelcome to afex. For support visit: http://afex.singmann.science/\n\n\n- Functions for ANOVAs: aov_car(), aov_ez(), and aov_4()\n- Methods for calculating p-values with mixed(): 'S', 'KR', 'LRT', and 'PB'\n- 'afex_aov' and 'mixed' objects can be passed to emmeans() for follow-up tests\n- Get and set global package options with: afex_options()\n- Set sum-to-zero contrasts globally: set_sum_contrasts()\n- For example analyses see: browseVignettes(\"afex\")\n************\n\n\n\nAttaching package: 'afex'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nCode\nset_sum_contrasts()\n\n\nsetting contr.sum globally: options(contrasts=c('contr.sum', 'contr.poly'))\n\n\nNow, we can use the aov_ez function to do the ANOVA on the a parameter estimates.\n\n\nCode\naov_ez(\n    id = \"subject\",      # Specify the name of the column that identifies unique participants\n    dv = \"val\",          # Specify the name of the column that contains the values to be analyzed\n    data = model_pars %&gt;% filter(par == \"a\"), # The data for this ANOVA is stored in \"model_pars\", but we are only interested in the estimates of the \"a\" parameter\n    between = \"group\",   # Specify the name of the column that identifies between-subject comparisons\n    within = \"index\"     # Specify the name of the column that identifies within-subject comparisons\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n       Effect    df  MSE          F  ges p.value\n1       group 2, 52 0.15  17.86 *** .264   &lt;.001\n2       index 1, 52 0.14 129.70 *** .544   &lt;.001\n3 group:index 2, 52 0.14   9.23 *** .145   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nAs we can see, there is a main effect of “group”, consistent with our observation that more experienced participants had higher response caution. There is also a main effect of “index”, consistent with our observation that participants tended to set lower response caution in Speed blocks. Finally, there is a significant interaction between “group” and “index”, although it looks from the graph above that this is likely to be a “fan” interaction, with a bigger increase from Speed to Accuracy for the more experienced participants.\n\n\n7.3.1.2 Drift rates\nNow, let’s consider the drift rate parameters. Again, we will use ANOVA to look for statistical evidence of differences in drift rates between groups and between conditions. Things are a little more complicated, though, because drift rate was allowed to vary by both difficulty and image type (blast vs. non-blast). To properly specify the ANOVA, then, we should “undo” the drift rate indices back into those original two factors. That’s what the mutate lines in the data specification do in the code below.\n\n\nCode\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\"))),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\")\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                             Effect    df  MSE          F   ges p.value\n1                             group 2, 52 1.65       0.02 &lt;.001    .980\n2                        difficulty 1, 52 0.25  68.87 ***  .052   &lt;.001\n3                  group:difficulty 2, 52 0.25     3.24 *  .005    .047\n4                  correct_response 1, 52 3.37 252.60 ***  .728   &lt;.001\n5            group:correct_response 2, 52 3.37  21.45 ***  .313   &lt;.001\n6       difficulty:correct_response 1, 52 0.83 164.02 ***  .300   &lt;.001\n7 group:difficulty:correct_response 2, 52 0.83  16.01 ***  .077   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nThe ANOVA finds evidence for significant differences for all but “group” on its own. However, this analysis is a bit misleading in that, as you’ll recall, drift rates for non-blast images tend to be negative while drift rates for blast images tend to be positive. We may be more interested in analyzing how drift rates toward the correct response boundary may or may not differ between groups/conditions.\nTo do this, we can add another mutate line that reverses the sign of the estimated drift rates for non-blast images:\n\n\nCode\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\")),\n            val = if_else(correct_response == \"Blast\", val, -val)\n    ),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\")\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                             Effect    df  MSE          F   ges p.value\n1                             group 2, 52 3.37  21.45 ***  .313   &lt;.001\n2                        difficulty 1, 52 0.83 164.02 ***  .300   &lt;.001\n3                  group:difficulty 2, 52 0.83  16.01 ***  .077   &lt;.001\n4                  correct_response 1, 52 1.65       0.31  .002    .578\n5            group:correct_response 2, 52 1.65       0.02 &lt;.001    .980\n6       difficulty:correct_response 1, 52 0.25  68.87 ***  .052   &lt;.001\n7 group:difficulty:correct_response 2, 52 0.25     3.24 *  .005    .047\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nNow the ANOVA correctly detects a main effect of group that was obscured in the previous analysis, among other things.\n\n\n7.3.1.3 Individual differences\nFinally, recall that each participant also completed the “NOMT”, a test of general visual object processing ability. It would be reasonable to ask whether participants who have high NOMT scores also tend to have higher drift rates toward the correct response boundary. To analyze this, we need to first extract the NOMT scores for each participant, append them to the model parameter estimates, and include NOMT as a covariate in the ANOVA. For interpretability, I also “center” the NOMT scores by subtracting the group mean.\n\n\nCode\n# Extract NOMT scores and center them.\nnomt_scores &lt;- blast_data %&gt;%\n    group_by(group, subject) %&gt;%\n    summarize(nomt = first(nomt)) %&gt;%\n    mutate(nomt_centered = nomt - mean(nomt))\n\n\n`summarise()` has grouped output by 'group'. You can override using the\n`.groups` argument.\n\n\nCode\n# Append the NOMT scores to the parameter estimates\nmodel_pars_nomt &lt;- left_join(model_pars, nomt_scores)\n\n\nJoining with `by = join_by(group, subject)`\n\n\nCode\n# Run the same ANOVA as above, now including `nomt_centered` as a `covariate`\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars_nomt %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\")),\n            val = if_else(correct_response == \"Blast\", val, -val)\n    ),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\"),\n    covariate = \"nomt_centered\",\n    factorize = FALSE  # This last setting is necessary to ensure that \"nomt_centered\" isn't accidentally treated like a factor\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                                      Effect    df  MSE          F   ges\n1                                      group 2, 51 3.05  23.64 ***  .334\n2                              nomt_centered 1, 51 3.05     6.33 *  .063\n3                                 difficulty 1, 51 0.68 199.27 ***  .320\n4                           group:difficulty 2, 51 0.68  19.46 ***  .084\n5                   nomt_centered:difficulty 1, 51 0.68   12.18 **  .028\n6                           correct_response 1, 51 1.67       0.31  .002\n7                     group:correct_response 2, 51 1.67       0.02 &lt;.001\n8             nomt_centered:correct_response 1, 51 1.67       0.34  .002\n9                difficulty:correct_response 1, 51 0.24  71.48 ***  .057\n10         group:difficulty:correct_response 2, 51 0.24     3.36 *  .006\n11 nomt_centered:difficulty:correct_response 1, 51 0.24     2.97 +  .003\n   p.value\n1    &lt;.001\n2     .015\n3    &lt;.001\n4    &lt;.001\n5     .001\n6     .581\n7     .980\n8     .562\n9    &lt;.001\n10    .043\n11    .091\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nIn fact, it looks like NOMT not only has a main effect on drift rates, it also interacts with difficulty, suggesting that group differences alone do not account for individual differences in performance on this task—categorizing images of cells also seems to depend on general object processing ability.\n\n\n\n7.3.2 Visualizing model fit\nFinally, we come to the most challenging section: How to visualize the quality of the model fit. We could, of course, produce quantile-probability plots for each participant separately, but this would only be feasible with very few participants.\nInstead, the code below plots the observed and fitted RT quantiles and response probabilities averaged over the participants in each group. This is not meant to be the final word, but just a way to verify that the model is close to the data and that it is accurately reproducing the important aspects of the data.\n\n\nCode\nmodel_qp %&gt;%\n    mutate(\n        blockType = factor(bound_index, labels = levels(blast_data$blockType)),\n        item_type = factor(drift_index, labels = levels(interaction(blast_data$difficulty, blast_data$correct_response, sep = \" \", drop = T)))\n    ) %&gt;%\n    group_by(group, blockType, item_type, response, source, rt_p) %&gt;%\n    summarize(rt_q = mean(rt_q, na.rm = TRUE), p_resp = mean(p_resp, na.rm = TRUE)) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = item_type)) +\n    geom_point(aes(shape = source), fill = \"white\") +\n    scale_linetype_manual(values = c(\"Observed\" = \"solid\", \"Fitted\" = \"dashed\")) +\n    scale_shape_manual(values = c(\"Observed\" = 16, \"Fitted\" = 21)) +\n    facet_grid(blockType ~ group, scales = \"free_y\")\n\n\n`summarise()` has grouped output by 'group', 'blockType', 'item_type',\n'response', 'source'. You can override using the `.groups` argument.\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's linetype values.\n\n\n\n\n\n\n\n\n\nThe upshot is that it looks like the model is, at least on average, doing a very good job of capturing the response proportion and a pretty good one capturing the RT quantiles. That said, some of the misfits for the highest and lowest quantiles (see, e.g., the green points in the “Speed” conditions) may be due to sampling error, as discussed earlier.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#exercises",
    "href": "blast_example.html#exercises",
    "title": "7  A worked example",
    "section": "7.4 Exercises",
    "text": "7.4 Exercises\n\nRun an ANOVA analysis on other estimated model parameters, like bias (w), residual time (t0), and the two variability parameters (sv and st0). Do you find evidence for differences, on average, between groups or between conditions (for sv and st0, you can only compare between groups)?\nUsing the sv_index and st0_index parameters, modify the diffusion model we used above so that drift rate variability and residual time variability can also vary by block type. Does this more complex model provide a better account of the data, as scored by either AIC or BIC?\nModify the way we defined drift_index so that it allows drift rates to vary by blockType as well as difficulty and correct_response (this will just involve adding the additional factor to the interaction function). Leave everything else the same as we specified it in the main text and re-run the model fits. Using an ANOVA on the drift rates, do you find evidence that drift rates vary as a function of block type? Note that, to do this analysis, you will have to “reverse-engineer” the index number to recover the correct factor combination, like we did in the main text. The basic idea is shown below, where you’ll have to figure out how to correctly assign the labels in the mutate line below.\n\n\n\nCode\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:8, labels = c(___)),\n            correct_response = factor(index, levels = 1:8, labels = c(___)),\n            blockType = factor(index, levels = 1:8, labels = c(___)),\n            val = if_else(correct_response == \"Blast\", val, -val)\n    ),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\")\n)\n\n\n\n\n\n\nRae, B., Heathcote, A., Donkin, C., Averell, L., & Brown, S. (2014). The hare and the tortoise: Emphasizing speed can change the evidence used to make decisions. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(5), 1226–1243.\n\n\nTrueblood, J. S., Holmes, W. R., Seegmiller, A. C., Douds, J., Compton, M., Szentirmai, E., Woodruff, M., Huang, W., Stratton, C., & Eichbaum, Q. (2018). The impact of speed and bias on the cognitive processes of experts and novices in medical image decision-making. Cognitive Research: Principles and Implications, 3, 1–14.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html",
    "href": "accumulator_models.html",
    "title": "8  Accumulator models of choice and response time",
    "section": "",
    "text": "8.1 Race model simulations\nThe first kind of accumulator model we will build is called a race model for the simple reason that it models making a decision as a race between different evidence accumulation processes. Each option is associated with a level of evidence which can fluctuate over time as evidence that either favors or disfavors that option gets accumulated. Whichever accumulator first reaches a threshold level of evidence then determines the outcome of the choice, and the response time depends on how long the “winning” accumulator needed to reach threshold (plus residual time, of course).\nAs we will see, each accumulator can be modeled as a diffusion or random walk process. The only difference is that instead of stopping when it hits either an upper or lower boundary, there is only one upper boundary that acts as the “finishing line”. In general, different accumulators may have different threshold levels.\nThus, accumulator models instantiate the same four theoretical constructs as random walk/diffusion models: Decisions still depend on accumulating evidence regarding the available options. Decisions depend on accumulating until a threshold amount of evidence is reached, such that higher thresholds amount to greater response caution. However, because thresholds can be set at different levels for different options, there is the possibility of response bias. Finally, we must acknowledge the ever-present residual time that contributes to observed response times.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#race-model-simulations",
    "href": "accumulator_models.html#race-model-simulations",
    "title": "8  Accumulator models of choice and response time",
    "section": "",
    "text": "8.1.1 A single accumulator\nTo begin, let’s simulate just a single accumulator. Although there are a number of ways to do this (and we will consider some variations later on), we will make a minor modification to the diffusion_sim function we wrote already. We will simply remove the lower boundary, so that the process will stop only when hitting its upper threshold. The revised function is shown below, along with comments that indicate the meaning of each of the function arguments.\n\n\nCode\n# Function arguments\n# v: \"drift rate\", the average evidence in support of this option\n# a: threshold level of evidence\n# t0: residual time\n# dt: how long each tiny time interval lasts\n# t_max: optional \"cut off\" time to stop accumulating\naccum_sim &lt;- function(v = 0, a = 1, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; a & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = v * dt, sd = sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nLet’s see what the behavior of one of these single accumulators looks like. The chunk of code below simulates 1000 trials using a few different settings of the drift rate parameter v and the threshold parameter a. Note that because there is only one threshold and only one accumulator, there are no “choices” being made yet. We are just simulating how long it takes a single accumulator to reach its threshold.\n\n\nCode\nN_sims &lt;- 1000\n\nparamsToSim &lt;- expand_grid(a = c(1, 2), v = c(1, 2, 3))\n\nsim_rt_results &lt;- c()\n\nfor (param_index in 1:nrow(paramsToSim)) {\n    for (sim_index in 1:N_sims) {\n        this_sim &lt;- accum_sim(\n            v = paramsToSim$v[param_index],\n            a = paramsToSim$a[param_index]\n        )\n        \n        sim_rt_results &lt;- rbind(\n            sim_rt_results,\n            tibble(\n                sim_index = sim_index,\n                v = paramsToSim$v[param_index],\n                a = paramsToSim$a[param_index],\n                finishing_time = max(this_sim$t)\n            )\n        )\n    }\n}\n\n# Plot conditional RT distributions\ndens_plot &lt;- sim_rt_results %&gt;%\n    ggplot(aes(x = finishing_time, color = v, linetype = factor(a), group = interaction(v, a))) +\n    geom_density() +\n    scale_color_gradient2(mid = \"#bbbbbb\") +\n    coord_cartesian(xlim = c(0, 5)) +\n    labs(x = \"Finishing time\", y = \"Density\", color = \"Drift rate (v)\", linetype = \"Threshold (a)\")\n\ncdf_plot &lt;- sim_rt_results %&gt;%\n    ggplot(aes(x = finishing_time, color = v, linetype = factor(a), group = interaction(v, a))) +\n    stat_ecdf() +\n    scale_color_gradient2(mid = \"#bbbbbb\") +\n    coord_cartesian(xlim = c(0, 5), ylim = c(0, 1)) +\n    labs(x = \"Finishing time\", y = \"Cumulative\", color = \"Drift rate (v)\", linetype = \"Threshold (a)\")\n\nprint(\n    dens_plot + cdf_plot + plot_layout(nrow = 1, guides = \"collect\")\n)\n\n\n\n\n\n\n\n\n\nThe code below plots two graphs. The left graph shows the probability density function (PDF) of the simulated finishing times for each combination of drift rate (v) and threshold (a). The right graph shows the cumulative distribution function (CDF) of the simulated finishing times. The left graph shows the probability of finishing at time \\(t\\). The right graph shows the probability of having finished at or before time \\(t\\). Both the PDF and the CDF will turn out to be important when we simulate a race between multiple accumulators.\nFor now, though, we can appreciate two things, which are fairly intuitive:\n\nThe greater the drift rate v, the faster the accumulator is to finish.\nThe greater the threshold a, the slower the accumulator is to finish.\n\n\n\n8.1.2 A race between independent accumulators\nNow let’s introduce a second accumulator to the mix. To return to our visual search example, this would correspond to a search array with two items. For now, we will assume that each accumulator operates independently of the other, meaning that the evidence accumulated by each accumulator is not affected by the evidence level of the other. Shortly, we will relax this assumption for our simulations. Unfortunately, we will have to keep the independence assumption when we later write a function that computes the likelihood of a particular accumulator winning at a particular time. When accumulators can interact with one another, computing the likelihood is a lot harder and requires some bespoke numerical methods that are beyond this course.\nFor now, we need to modify our simulation code so that it treats x not as a single number, but as a vector where each element corresponds to the evidence level in each accumulator. As a corollary to that, we will also need to treat the v and a arguments as vectors, since they may differ between accumulators. That said, the first three lines of code in the function will repeat the values of v and a if necessary, so we can be lazy and provide just a single value if we want it to be equal across accumulators.\n\n\nCode\n# Function arguments\n# v: \"drift rate\", the average evidence in support of each option\n# a: threshold level of evidence for each accumulator\n# t0: residual time\n# dt: how long each tiny time interval lasts\n# t_max: optional \"cut off\" time to stop accumulating\nrace_sim &lt;- function(v = 0, a = 1, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    n_accum &lt;- max(length(v), length(a))\n    \n    v &lt;- rep(v, n_accum)[1:n_accum]\n    a &lt;- rep(a, n_accum)[1:n_accum]\n    \n    x &lt;- rep(0, n_accum)\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (all(x &lt; a) & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = n_accum, mean = v * dt, sd = sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- rbind(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    to_return &lt;- cbind(t_record, x_record)\n    \n    colnames(to_return) &lt;- c(\"t\", paste0(\"x\", 1:n_accum))\n    \n    return(as_tibble(to_return))\n}\n\n\nNote that each time we run the simulation, we get the trajectory of accumulated evidence for both accumulators, labeled x1 and x2.\n\n\nCode\nrace_sim(v = c(1, 0), a = 1, t0 = 0.2)\n\n\n# A tibble: 35 × 3\n       t     x1       x2\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.2  0       0      \n 2  0.21 0.0595 -0.114  \n 3  0.22 0.141  -0.0747 \n 4  0.23 0.282   0.00144\n 5  0.24 0.392  -0.125  \n 6  0.25 0.504  -0.0206 \n 7  0.26 0.383  -0.0453 \n 8  0.27 0.353  -0.0878 \n 9  0.28 0.464  -0.221  \n10  0.29 0.555  -0.162  \n# ℹ 25 more rows\n\n\nThis makes for some lovely plots:\n\n\nCode\nrace_sim(v = c(1, 0), a = 1, t0 = 0.2) %&gt;%\n    pivot_longer(matches(\"x(\\\\d+)\"), names_to = \"accumulator\", values_to = \"x\") %&gt;%\n    ggplot(aes(x = t, y = x, color = accumulator)) +\n    geom_line() +\n    geom_hline(yintercept = 1, linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", color = \"Accumulator\")\n\n\n\n\n\n\n\n\n\nWe can also easily simulate situations with more than two options. For example, maybe there are four items in the search array. Say that item 1 is the search target, a red square. Item 2 is a red circle—it matches the target in color but not shape. Item 3 is a blue square—it matches the target in shape but not color. Finally, item 4 is a blue circle, which matches in neither color nor shape. If “evidence” reflects the degree of match between an item and the search target, then it would make sense for the drift rate for item 1 to be the greatest, the drift rate for item 4 to be the smallest, and the drift rates for items 2 and 3 to be intermediate (whether the drift rate for item 2 is greater than for item 3 may depend on how much attention is devoted to each feature). I picked some sensible-seeming values for those drift rates in the simulation below, also assuming the same threshold of a = 2 across all accumulators.\n\n\nCode\nrace_sim(v = c(1, 0.4, 0.2, 0), a = 2, t0 = 0.2) %&gt;%\n    pivot_longer(matches(\"x(\\\\d+)\"), names_to = \"accumulator\", values_to = \"x\") %&gt;%\n    ggplot(aes(x = t, y = x, color = accumulator)) +\n    geom_line() +\n    geom_hline(yintercept = 2, linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", color = \"Accumulator\")\n\n\n\n\n\n\n\n\n\nAlthough the graph above is just one simulated trial, it gives a visual sense of how evidence accumulation works in a race model. It also shows how the option with the highest drift rate (accumulator x1) need not always win the race!\nOf course, to get a sense of the full distribution of behavior this model predicts, we can return to our old friend, the Quantile-Probability plot. The code below simulates 1000 trials using the same parameter values as those used in the plot above.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (i in 1:n_sims) {\n    current_result &lt;- race_sim(c(1, 0.4, 0.2, 0), a = 2, t0 = 0.2)\n    \n    # Extract just the choice and RT\n    rt &lt;- current_result$t[nrow(current_result)]\n    choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        tibble(\n            sim_index = i,\n            rt = rt,\n            choice = choice\n        )\n    )\n}\n\n# Plot conditional RT distributions\nsim_results %&gt;%\n    ggplot(aes(x = rt, color = factor(choice))) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\nThere’s a couple things worth noting in the simulations above. First, looking at the QP plot, it is clear that accumulators with higher drift rates tend to “win” the race more often—the target item (item 1) gets chosen more often than the other items. However, you may also have noticed that the RT distributions look pretty similar regardless of which item was actually chosen in the end. This is somewhat reminiscent of how error and correct RT distributions were the same in the diffusion/random walk until we introduced trial-by-trial variability in drift rates.\nThe next set of simulations illustrate how we can model response bias by allowing the threshold to vary between accumulators. In the simulations below, I use four accumulators representing the factorial combination of two values of drift rate (v is either 1 or 0) and two values of threshold (a is either 1 or 2).\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (i in 1:n_sims) {\n    current_result &lt;- race_sim(c(1, 1, 0, 0), a = c(2, 1, 2, 1), t0 = 0.2)\n    \n    # Extract just the choice and RT\n    rt &lt;- current_result$t[nrow(current_result)]\n    choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        tibble(\n            sim_index = i,\n            rt = rt,\n            choice = choice\n        )\n    )\n}\n\n# Plot conditional RT distributions\nsim_results %&gt;%\n    ggplot(aes(x = rt, color = factor(choice))) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\nThe results show that, as would make sense, accumulators with lower thresholds (2 and 4) tend to win more quickly than those with higher thresholds (1 and 3). The simulations also illustrate a tendency which we are about to explore: Accumulators with lower drift rates (3 and 4) tend to be associated with faster responses.\nTo get a better sense of what’s going on, let’s run another set of simulations. In the following, we assume only two items, a target and a distractor. The target will always have a drift rate of 1 but we will vary the drift rate associated with the distractor. This might happen, for example, if we make the distractor progressively more similar to the target. We will keep a threshold of 2 on both accumulators and residual time of 0.2.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (distractor_drift in c(0, 0.5, 0.9)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, distractor_drift), a = 2, t0 = 0.2)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                distractor_drift = distractor_drift,\n                sim_index = i,\n                rt = rt,\n                choice = choice\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    count() %&gt;%\n    group_by(distractor_drift) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"distractor_drift\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(distractor_drift, choice)`\n\n\n\n\n\n\n\n\n\nAs the drift rate for the distractor (item 2) increases, two things happen: The probability of choosing the distractor increases and response times decrease. Meanwhile, if you choose the distractor, you tend to do so a bit faster than when you pick the target.\nSpeeding up when the competition gets more heated—that seems a bit counterintuitive, no? However, it is a consequence of statistical facilitation (Raab, 1962), which is a general phenomenon exhibited by race models. It happens because, for an accumulator to “win” the race, it must have been faster than its competition. Therefore, when the distractor has a high drift rate, the target must be even faster in order to win.\nFor the same reason, if we introduce more distractors—and therefore more “runners” in the race—the race model also produces faster responses. This is shown in the simulations below, which vary the number of distractors in the array, assuming each distractor has a drift rate of 0.1.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (num_distractors in c(1, 3, 7)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, rep(0.1, num_distractors)), a = 2, t0 = 0.2)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                num_distractors = num_distractors,\n                sim_index = i,\n                rt = rt,\n                # Note that I don't bother to keep track of which distractor was selected\n                choice = factor(ifelse(choice == 1, \"Target\", \"Distractor\"), levels = c(\"Target\", \"Distractor\"))\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    count() %&gt;%\n    group_by(num_distractors) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"num_distractors\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(num_distractors, choice)`\n\n\n\n\n\n\n\n\n\nFirst, it is clear that introducing more distractors means the probability of selecting the target decreases, which makes intuitive sense. But paradoxically, making the decision harder and more error-prone by introducing more distractors has sped up the model. This is statistical facilitation once again—for any single accumulator to “win” the race it has to be faster than all of its competitors.\nFinally, it is worth remarking once again that errors (i.e., selecting a distractor) take about the same amount of time as correct responses, regardless of the number of distractors.\n\n\n8.1.3 Introducing competition\nTo enable the race model to be a bit more flexible—and potentially more psychologically realistic—we will introduce two kinds of competition between the accumulators. As noted above, some forms of competition do not permit easy computation of likelihoods, but they are still important from a theoretical standpoint.\n\n8.1.3.1 Feedforward competition\nThe first kind of competition we introduce is feedforward competition. This mechanism treats the drift rate for an accumulator as something that can be inhibited by the drift rates for other accumulators.\nTo get mathy about it, let \\(v_i\\) stand for the drift rate to accumulator \\(i\\), assuming \\(N\\) total accumulators. Then the inhibited drift rate \\(v_i'\\) is\n\\[\nv_i' = v_i - \\alpha \\sum_{i \\neq j}^n v_j\n\\]\nwhere \\(\\sum_{i \\neq j}^n v_j\\) is the sum of the drift rates for all other accumulators and \\(\\alpha\\) is a free parameter representing the strength of feedforward competition.\nThe code below introduces such a parameter, but calls it feedforward_comp instead of \\(\\alpha\\). This parameter is used to define a new vector of drift rates v_comp which represents the drift rates v after being subject to feedforward competition.\n\n\nCode\n# Function arguments\n# v: \"drift rate\", the average evidence in support of each option\n# a: threshold level of evidence for each accumulator\n# t0: residual time\n# dt: how long each tiny time interval lasts\n# t_max: optional \"cut off\" time to stop accumulating\n# feedforward_comp: strength of feed-forward competition between accumulators\nrace_sim &lt;- function(v = 0, a = 1, t0 = 0.2, dt = 0.01, t_max = Inf, feedforward_comp = 0) {\n    n_accum &lt;- max(length(v), length(a))\n    \n    v &lt;- rep(v, n_accum)[1:n_accum]\n    a &lt;- rep(a, n_accum)[1:n_accum]\n    \n    v_comp &lt;- rep(0, n_accum)\n    \n    for (i in 1:n_accum) {\n        v_comp[i] &lt;- v[i] - feedforward_comp * sum(v[-i])\n    }\n    \n    x &lt;- rep(0, n_accum)\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (all(x &lt; a) & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = n_accum, mean = v_comp * dt, sd = sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- rbind(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    to_return &lt;- cbind(t_record, x_record)\n    \n    colnames(to_return) &lt;- c(\"t\", paste0(\"x\", 1:n_accum))\n    \n    return(as_tibble(to_return))\n}\n\n\nLet’s take the new model out for a spin! First, let’s repeat the simulations varying distractor strength, but now set feedforward_comp = 0.5.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (distractor_drift in c(0, 0.5, 0.9)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, distractor_drift), a = 2, t0 = 0.2, feedforward_comp = 0.5)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                distractor_drift = distractor_drift,\n                sim_index = i,\n                rt = rt,\n                choice = choice\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    count() %&gt;%\n    group_by(distractor_drift) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"distractor_drift\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(distractor_drift, choice)`\n\n\n\n\n\n\n\n\n\nAdding feedforward competition now causes the model to slow down when the distractor is more similar to a target. This matches the intuition we may have about many tasks that a harder choice should take longer, on average. Feedforward competition produces this behavior because strong competitors with high drift rates reduce the drift rates for all accumulators.\nWhat about increasing the number of options? The simulations below replicate our earlier simulations in which we varied the number of distractors. By introducing feedforward competition, each additional distractor now acts to suppress the drift rate for the target accumulator.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (num_distractors in c(1, 3, 7)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, rep(0.1, num_distractors)), a = 2, t0 = 0.2, feedforward_comp = 0.5)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                num_distractors = num_distractors,\n                sim_index = i,\n                rt = rt,\n                # Note that I don't bother to keep track of which distractor was selected\n                choice = factor(ifelse(choice == 1, \"Target\", \"Distractor\"), levels = c(\"Target\", \"Distractor\"))\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    count() %&gt;%\n    group_by(num_distractors) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"num_distractors\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(num_distractors, choice)`\n\n\n\n\n\n\n\n\n\nAs shown above, with feedforward competition between accumulators, adding more distractors slows responding, in keeping with intuition. That said, it is still the case that the race model predicts errors (selecting a distractor) to be faster than correct responses. Again, statistical facilitation is at work—the only way for a race model to make an error is for the “wrong” accumulator (i.e., one with a comparatively low drift rate) to be even faster than the “right” accumulator (i.e., one with a comparatively high drift rate).\n\n\n8.1.3.2 Lateral competition\nA different form of competition enables race models to predict slower errors than correct responses: lateral competition. Lateral competition occurs between accumulators during the accumulation process, unlike feedforward competition which only affects the “inputs” to the accumulators. With lateral competition, the level of evidence in one accumulator acts to suppress the level of evidence in other accumulators.\nMathematically, lateral competition enters into the equation that describes how evidence evolves from one moment in time to the next: \\[\n\\overbrace{x_i(t + \\Delta t)}^{\\text{Updated evidence}} = \\underbrace{x_i(t)}_{\\text{Current accumulated evidence}} + \\overbrace{\\Delta x_i(t)}^{\\text{Current sample of evidence}} - \\underbrace{\\beta \\Delta t \\sum_{j \\neq i}^N x_j(t)}_{\\text{Lateral competition}}\n\\] As described in the equation above, during each interval of time, the evidence in accumulator \\(i\\) not only receives a new sample of evidence, it loses some evidence in proportion to how much evidence has accumulated in the other accumulators (accumulators \\(j\\), where \\(j \\neq i\\)). Conceptually, lateral competition embodies the idea that having accumulated a lot of evidence for one option counts as evidence against picking the other options, encouraging a sort of “winner-take-all” competition. Metaphorically, we can think of lateral competition as sort of like the famous chariot race scene in Ben Hur, where instead of the competitors running in their own separate lanes, they are able to “jostle” with one another during the event.\nThe chunk of code below amends our race model simulation to include lateral competition. It also includes a new argument to the function min_x, which sets the minimum allowable value for accumulated evidence. By default, min_x = -Inf, such that evidence is allowed to be negative. However, we will see that allowing negative evidence results in some interesting (not necessarily incorrect!) behavior from the model.\n\n\nCode\n# Function arguments\n# v: \"drift rate\", the average evidence in support of each option\n# a: threshold level of evidence for each accumulator\n# t0: residual time\n# dt: how long each tiny time interval lasts\n# t_max: optional \"cut off\" time to stop accumulating\n# feedforward_comp: strength of feed-forward competition between accumulators\n# lateral_comp: strength of lateral competition between accumulators\n# min_x: accumulators are constrained to have at minimum *this much* evidence\nrace_sim &lt;- function(v = 0, a = 1, t0 = 0.2, dt = 0.01, t_max = Inf, feedforward_comp = 0, lateral_comp = 0, min_x = -Inf) {\n    n_accum &lt;- max(length(v), length(a))\n    \n    v &lt;- rep(v, n_accum)[1:n_accum]\n    a &lt;- rep(a, n_accum)[1:n_accum]\n    \n    v_comp &lt;- rep(0, n_accum)\n    \n    for (i in 1:n_accum) {\n        v_comp[i] &lt;- v[i] - feedforward_comp * sum(v[-i])\n    }\n    \n    x &lt;- rep(0, n_accum)\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (all(x &lt; a) & t &lt; t_max) {\n        # Compute the total amount of lateral competition for each accumulator\n        lat &lt;- rep(0, n_accum)\n        for (i in 1:n_accum) {\n            lat[i] &lt;- sum(x[-i])\n        }\n        \n        x_sample &lt;- rnorm(n = n_accum, mean = v_comp * dt, sd = sqrt(dt))\n        \n        # Updated values account for lateral competition and use \"pmax\" to keep them above \"min_x\"\n        x &lt;- pmax(min_x, x + x_sample - dt * lateral_comp * lat)\n        t &lt;- t + dt\n        x_record &lt;- rbind(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    to_return &lt;- cbind(t_record, x_record)\n    \n    colnames(to_return) &lt;- c(\"t\", paste0(\"x\", 1:n_accum))\n    \n    return(as_tibble(to_return))\n}\n\n\nTo see the effect of lateral competition, let’s take a look at some simulated trials. For comparison purposes, I have set R’s “random seed” to the same value prior to each simulation, which has the effect of making the sequence of random evidence samples the same for each simulated trial. This allows us to focus on the effects of lateral competition and of enforcing a minimum evidence level.\n\n\nCode\nset.seed(2)\nbaseline_sim &lt;- race_sim(v = c(1, 0), a = 2, t0 = 0.2, lateral_comp = 0, min_x = -Inf)\n\nset.seed(2)\nlateral_sim &lt;- race_sim(v = c(1, 0), a = 2, t0 = 0.2, lateral_comp = 1, min_x = -Inf)\n\nset.seed(2)\nlateral_min_sim &lt;- race_sim(v = c(1, 0), a = 2, t0 = 0.2, lateral_comp = 1, min_x = 0)\n\nall_sims &lt;- rbind(\n    baseline_sim %&gt;% mutate(label = \"No lateral competition,\\nno minimum value\"),\n    lateral_sim %&gt;% mutate(label = \"Lateral competition,\\nno minimum value\"),\n    lateral_min_sim %&gt;% mutate(label = \"Lateral competition,\\nnonnegative evidence\")\n) %&gt;%\n    mutate(label = factor(label, levels = c(\"No lateral competition,\\nno minimum value\", \"Lateral competition,\\nno minimum value\", \"Lateral competition,\\nnonnegative evidence\")))\n\nall_sims %&gt;%\n    pivot_longer(matches(\"x(\\\\d+)\"), names_to = \"accumulator\", values_to = \"x\") %&gt;%\n    ggplot(aes(x = t, y = x, color = accumulator)) +\n    geom_line() +\n    geom_hline(yintercept = 2, linetype = \"dashed\") +\n    geom_hline(yintercept = 0, linetype = \"dotted\") +\n    facet_wrap(\"label\", nrow = 1) +\n    labs(x = \"Time\", y = \"Accumulated evidence\", color = \"Accumulator\")\n\n\n\n\n\n\n\n\n\nComparing the first two plots (with and without lateral competition), we can see that the effect of lateral competition is twofold: the “stronger” accumulator (x1) suppresses the “weaker” accumulator (x2), causing its evidence level to diminish over time. Comparing the second two plots, we can see that an accumulator with negative evidence can actually accelerate accumulation for its competitors—after all, subtracting a negative is a positive! When evidence is constrained to be non-negative (as in the third plot), that kind of acceleration is no longer possible.\nIt is worth noting that many models with lateral competition are inspired by the ways that individual neurons interact, making an analogy between the level of accumulated evidence and the amount of activity in either a single neuron or group of neurons (Purcell et al., 2010; Purcell et al., 2012; Teodorescu & Usher, 2013; Usher & McClelland, 2001). Because neural activity cannot be negative, these models also constrain evidence to be non-negative. As a result, most models that include some form of lateral competition also assume that the level of accumulated evidence cannot be negative, although this assumption is not strictly required.\nNow let’s see the effect of lateral competition on the model’s predictions regarding distractor similarity and number of distractors. The simulations below set the lateral competition parameter to 1 and, in keeping with the majority of models with lateral competition, do not allow for negative evidence.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (distractor_drift in c(0, 0.5, 0.9)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, distractor_drift), a = 2, t0 = 0.2, feedforward_comp = 0, lateral_comp = 1, min_x = 0)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                distractor_drift = distractor_drift,\n                sim_index = i,\n                rt = rt,\n                choice = choice\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    count() %&gt;%\n    group_by(distractor_drift) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(distractor_drift, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"distractor_drift\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(distractor_drift, choice)`\n\n\n\n\n\n\n\n\n\nWith lateral inhibition, errors (choosing 2) are generally slower than correct responses (choosing 1). This is because errors tend to occur when the correct response has more competition from the error accumulators. Notice, though, that making the distractor stronger does not slow responding overall—it actually speeds responses. Statistical facilitation still occurs even in the presence of lateral competition.\nBut while increasing the strength of competition doesn’t necessarily slow responding, the simulations below show that increasing the number of competitors does slow responding if there is lateral competition. The more competitors in the race, the more lateral competition there is, slowing down all the accumulators.\n\n\nCode\nn_sims &lt;- 1000\n\nsim_results &lt;- c()\n\nfor (num_distractors in c(1, 3, 7)) {\n    for (i in 1:n_sims) {\n        current_result &lt;- race_sim(c(1, rep(0.1, num_distractors)), a = 2, t0 = 0.2, lateral_comp = 1, min_x = 0)\n        \n        # Extract just the choice and RT\n        rt &lt;- current_result$t[nrow(current_result)]\n        choice &lt;- which.max(current_result[nrow(current_result), 2:ncol(current_result)])\n        \n        # \"Bind\" the current simulation to the ongoing record of simulation results\n        sim_results &lt;- rbind(\n            sim_results,\n            tibble(\n                num_distractors = num_distractors,\n                sim_index = i,\n                rt = rt,\n                # Note that I don't bother to keep track of which distractor was selected\n                choice = factor(ifelse(choice == 1, \"Target\", \"Distractor\"), levels = c(\"Target\", \"Distractor\"))\n            )\n        )\n    }\n}\n\n# Quantile-probability plot\nsim_choice_p &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    count() %&gt;%\n    group_by(num_distractors) %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- sim_results %&gt;%\n    group_by(num_distractors, choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = factor(choice))) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"num_distractors\", labeller = label_both) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", color = \"Choice\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(num_distractors, choice)`\n\n\n\n\n\n\n\n\n\n\n\n8.1.3.3 Summary\nFeedforward competition diminishes the drift rates for each accumulator, with the result that stronger competition tends to slow responding overall. However, feedforward competition still generally predicts fast errors because errors occur when the accumulators for incorrect responses happen to be fast enough to “beat” the accumulator associated with the correct response.\nLateral competition does not always predict that stronger competition will slow responding. Lateral competition can produce slow errors because they arise in trials where the incorrect accumulators happened to be strong enough to impede the correct accumulator.\nNote that the race model theory for slow errors is different from how slow errors were explained with a diffusion model. With a diffusion model, slow errors arose from trial-by-trial variability in the drift rate. One of your exercises will be to compare and contrast these two theories of slow errors.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#race-model-likelihood-function",
    "href": "accumulator_models.html#race-model-likelihood-function",
    "title": "8  Accumulator models of choice and response time",
    "section": "8.2 Race model likelihood function",
    "text": "8.2 Race model likelihood function\nIn the previous section, we built code to simulate a race model, where each accumulator was associated with a particular response. We will now write a function to calculate the negative log-likelihood (NLL) of a response at a particular time. This will enable us to fit a race model to data. The process of building the function will also illustrate the essential ingredients in any NLL function, namely\n\nTranslating a mathematical expression of the likelihood into code.\nDeciding how to represent the data to be fit, along with any experimental factors relevant to the model.\nExtracting the values for the model’s parameters from a vector (this last step is necessary for using most parameter search algorithms).\n\n\n8.2.1 Math to Code\nIn the previous section, we began by simulating just a single accumulator with a single boundary. There were three parameters describing the accumulator: the drift rate, the threshold, and the residual time. There is, in fact, a mathematical expression for the distribution of finishing times for this process: the shifted Wald distribution (also called the shifted inverse Gaussian distribution).\nAs you can see in the Wikipedia entry, it is possible to write a mathematical expression for both the probability density function (PDF) (the probability of finishing at a particular time) and the cumulative distribution function (CDF) (the probability of finishing by a particular time). Since the Wikipedia entry doesn’t explicitly include residual time in its formulae, let’s write them out ourselves for our own reference.\n\n8.2.1.1 Probability density function for a single accumulator\nThe PDF, describing the probability that accumulator \\(i\\) reaches its threshold at time \\(t\\), can be written \\[\nf_i \\left( t \\mid a_i, v_i, t_{0i} \\right) = \\frac{a_i}{\\sqrt{2 \\pi \\left(t - t_{0i} \\right)^3}} \\exp \\left\\lbrace -\\frac{\\left[a_i - v_i \\left(t - t_{0i} \\right) \\right]^2}{2 \\left(t - t_{0i} \\right)} \\right\\rbrace\n\\] where \\(a_i\\) is the threshold, \\(v_i\\) is the drift rate, and \\(t_{0i}\\) is the residual time. While the expression above may look a bit cumbersome, it only involves elementary mathematical operations which are already implemented in R (and almost all programming languages). Therefore, we can write an R function that will compute the PDF for a single accumulator. That’s what I’ve done below. Note the comments in the code below explain the purpose of each line.\n\n\nCode\naccum_pdf &lt;- function(t, a, v, t0) {\n    # Because the term \"t - t0\" shows up multiple times in the formula, it's easier\n    # to compute it once and then refer back to it whenever we need it.  It also\n    # gives us a way to \"clip\" the values so they cannot be negative, since that\n    # would otherwise give a weird result.\n    t_minus_t0 &lt;- pmax(0, t - t0)\n    \n    # The next line is a direct implementation of the formula above.\n    pdf &lt;- a * exp(-(a - v * t_minus_t0)^2 / (2 * t_minus_t0)) / sqrt(2 * pi * t_minus_t0^3)\n    \n    # This does some final error-checking, ensuring that there is zero probability\n    # of finishing in zero (or negative) time.\n    pdf[t_minus_t0 &lt;= 0] &lt;- 0\n    \n    # Finally, we use an explicit \"return\" statement to say exactly what the\n    # function gives back.\n    return(pdf)\n}\n\n\nCool. Let’s take this function out for a spin!\n\n\nCode\naccum_pdf(\n    t = 1,\n    a = 2,\n    v = 1,\n    t0 = 0.2\n)\n\n\n[1] 0.4533567\n\n\nNice! But perhaps even more impressive is that the function will also accept vectors for its arguments, not just single numbers. This is very convenient for us because we will often want to compute the likelihood for many trials all at once. While we could use a for loop for that purpose, R code runs much faster if we can use vectors instead.\nFor example, here’s what we get if we want to compute the likelihood of a single accumulator finishing at a range of times:\n\n\nCode\naccum_pdf(\n    t = c(0, 0.5, 1, 1.5, 2, 2.5, 3),\n    a = 2,\n    v = 1,\n    t0 = 0.2\n)\n\n\n[1] 0.00000000 0.03930126 0.45335671 0.44583815 0.32674264 0.22431135 0.15190405\n\n\nNotice that we get a vector back from the function, which is the likelihood for each finishing time in the vector we supplied for the t argument.\nWe can also supply vectors for the other arguments to the function if we want. This is illustrated in the example below.\n\n\nCode\naccum_pdf(\n    t = c(0.5, 0.5, 0.5, 1, 1, 1, 2, 2, 2),\n    a = c(2, 2, 1, 2, 2, 1, 2, 2, 1),\n    v = c(1, 2, 3, 1, 2, 3, 1, 2, 3),\n    t0 = 0.2\n)\n\n\n[1] 0.0393012555 0.1851666937 2.3877559853 0.4533567093 1.0089639117\n[6] 0.1637813117 0.3267426369 0.1622555916 0.0007628903\n\n\nJust be aware that you can supply vectors with unequal lengths and R will “recycle” them until they are the length of the longest vector you supplied. This is generally a bad idea, though, because it can lead to all sorts of “silent” errors.\n\n\nCode\naccum_pdf(\n    t = c(0.5, 1, 1.5, 2),\n    a = c(2, 1),\n    v = 1,\n    t0 = 0.2\n)\n\n\n[1] 0.03930126 0.54377310 0.44583815 0.13829084\n\n\nAt least R will give you a warning if you supply vectors that can’t be recycled evenly.\n\n\nCode\naccum_pdf(\n    t = c(0.5, 1, 1.5, 2),\n    a = c(2, 1, 3),\n    v = 1,\n    t0 = 0.2\n)\n\n\nWarning in a - v * t_minus_t0: longer object length is not a multiple of\nshorter object length\n\n\nWarning in a * exp(-(a - v * t_minus_t0)^2/(2 * t_minus_t0)): longer object\nlength is not a multiple of shorter object length\n\n\n[1] 0.03930126 0.54377310 0.26569371 0.32674264\n\n\nBut in general, you should adhere to the following rule: For each argument to the function, provide either a single number or a vector that is the same length as any other vectors you might supply.\nOne nice side-effect of being able to provide vectors to our accum_pdf function is that we can use it to make some nice plots of the distributions of finishing times for different combinations of parameter values:\n\n\nCode\nexpand_grid(a = c(1, 2), v = c(1, 2, 3), t0 = 0.2, t = seq(0, 5, length.out = 201)) %&gt;%\n    mutate(pdf = accum_pdf(t = t, a = a, v = v, t0 = t0)) %&gt;%\n    ggplot(aes(x = t, y = pdf, color = v, linetype = factor(a), group = interaction(v, a))) +\n    geom_line() +\n    labs(x = \"Time (s)\", y = \"PDF\", color = \"Drift rate (v)\", linetype = \"Threshold (a)\")\n\n\n\n\n\n\n\n\n\n\n\n8.2.1.2 Cumulative distribution function for a single accumulator\nJust like there’s a mathematical expression for the PDF, we have one for the CDF too. As a reminder, the CDF is the probability that accumulator \\(i\\) reached threshold by time \\(t\\). The formula is given below, using the same parameters as the formula for the PDF above: \\[\nF_i \\left( t \\mid a_i, v_i, t_{0i} \\right) = \\Phi \\left[ \\frac{v_i \\left( t - t_{0i} \\right) - a_i}{\\sqrt{t - t_{0i}}} \\right] + \\exp \\left( 2 a_i v_i \\right) \\Phi \\left[ -\\frac{v_i \\left( t - t_{0i} \\right) + a_i}{\\sqrt{t - t_{0i}}} \\right]\n\\] The only new thing in the CDF formula is \\(\\Phi \\left( \\cdot \\right)\\), which is a shorthand for the CDF of the standard normal distribution. Recall that the standard normal distribution has a mean of zero and a standard deviation of one. Fortunately, this is built into R in the form of the pnorm function. Although you can supply a mean and sd to pnorm, if you don’t, it will use default settings of mean = 0 and sd = 1, amounting to a standard normal distribution.\nWe can thus write an R function to calculate the expression in the formula above for the CDF. This function is shown below.\n\n\nCode\naccum_cdf &lt;- function(t, a, v, t0) {\n    # As with the pdf function, I compute \"t - t0\" once at the very beginning,\n    # which also offers an opportunity to \"clip\" any negative values that result.\n    t_minus_t0 &lt;- pmax(0, t - t0)\n    \n    # This expression is a direct translation of the formula above\n    cdf &lt;- pnorm((v * t_minus_t0 - a) / sqrt(t_minus_t0)) + exp(2 * a * v) * pnorm(-(v * t_minus_t0 + a) / sqrt(t_minus_t0))\n    \n    # This formula doesn't give weird results when t_minus_t0 == 0, so we can just\n    # return the result as-is.\n    return(cdf)\n}\n\n\nLike accum_pdf, accum_cdf can accept vectors for its arguments too (with the same caveat that you should be sure to supply only single values or vectors of the same length to avoid unpredictable “recycling” issues). We can thus make some very nice plots, just like we did for the PDF:\n\n\nCode\nexpand_grid(a = c(1, 2), v = c(1, 2, 3), t0 = 0.2, t = seq(0, 5, length.out = 201)) %&gt;%\n    mutate(cdf = accum_cdf(t = t, a = a, v = v, t0 = t0)) %&gt;%\n    ggplot(aes(x = t, y = cdf, color = v, linetype = factor(a), group = interaction(v, a))) +\n    geom_line() +\n    expand_limits(y = c(0, 1)) +\n    labs(x = \"Time (s)\", y = \"CDF\", color = \"Drift rate (v)\", linetype = \"Threshold (a)\")\n\n\n\n\n\n\n\n\n\n\n\n8.2.1.3 Likelihood expression\nArmed with functions for calculating the PDF and CDF for a single accumulator, we are now in a position to write a function that computes the likelihood of a particular accumulator winning at a particular time \\(t\\). We will first write the likelihood mathematically and then translate it into an R function, like we did for the PDF and CDF.\nTo understand the math, it may help to think conceptually first: If accumulator \\(i\\) is the first of \\(N\\) accumulators to reach its threshold at time \\(t\\), that means two things must be true: First, and most obvious, accumulator \\(i\\) must have hit threshold at time \\(t\\). Second, and perhaps less obvious, is that none of the other accumulators must have hit threshold by time \\(t\\). The likelihood must therefore express the probability that both of these things are true.\nThere are two more conceptual ingredients we need to express the likelihood function: First, we need to know how to express the probability that a non-winning accumulator hasn’t hit threshold by time \\(t\\). Since the CDF is the probability that an accumulator has hit threshold by time \\(t\\), the probability that it hasn’t is just one minus the CDF, since “has already hit threshold” and “hasn’t already hit threshold” are mutually exclusive and exhaustive possibilities. Second, we have to remember that the joint probability of multiple independent events being true is the product of the individual probabilities.\nFinally, we can express the likelihood that accumulator \\(i\\) is the first out of \\(N\\) accumulators to reach its threshold at time \\(t\\): \\[\n\\overbrace{L \\left(i, t \\right)}^{\\text{Likelihood that } i \\text{ wins at } t} = \\underbrace{f_i \\left( t \\mid a_i, v_i, t_{0i} \\right)}_{i \\text{ finishes at } t} \\overbrace{\\prod_{j \\neq i}^N \\left[1 - F_j \\left(t \\mid a_j, v_j, t_{0j} \\right) \\right]}^{\\text{Nothing else has finished by } t}\n\\]\nIt is worth emphasizing that the formula above only works when the accumulators are (conditionally) independent of one another. As a result, the race model cannot include lateral competition or any other interactions between accumulators that would cause them to be dependent on one another. It can, however, accommodate feedforward competition, since that affects the drift rates but not how the accumulators evolve from moment to moment. We will return to feedforward competition later in this section.\nTo translate the likelihood formula above into R code, we will first see how to compute it for a single trial. We will then generalize that approach so we can compute the likelihood for many trials, exploiting the fact that our accum_pdf and accum_cdf functions can accept vectors as arguments.\nBut first, let’s imagine a concrete situation: Say we present an array of three items in a visual search task. The target is a red square and the job of the participant is to select which of the three items is the target. The item in position 1 is a blue circle and so doesn’t resemble the target at all; let’s say it has a drift rate of 0. The item in position 2 is the target—let’s say it has a drift rate of 2. Finally, the item in position 3 is a red circle, matching the target’s color but not its shape—let’s say it has a drift rate of 1. Let’s assume that all accumulators have the same threshold value (2) and the same residual time (0.2). We can now write the parameters for all three accumulators as vectors, although we will be pedantic and write out the same value 3 times for the threshold and residual time:\n\n\nCode\nv &lt;- c(0, 2, 1)\na &lt;- c(2, 2, 2)\nt0 &lt;- c(0.2, 0.2, 0.2)\n\n\nWhat is the likelihood of selecting the target (item 2) in 1 second? Based on the formula above, we can compute that likelihood in R using the accum_pdf and accum_cdf functions from earlier:\n\n\nCode\nv &lt;- c(0, 2, 1)\na &lt;- c(2, 2, 2)\nt0 &lt;- c(0.2, 0.2, 0.2)\n\naccum_pdf(t = 1, a = a[2], v = v[2], t0 = t0[2]) *\n    (1 - accum_cdf(t = 1, a = a[1], v = v[1], t0 = t0[1])) *\n    (1 - accum_cdf(t = 1, a = a[3], v = v[3], t0 = t0[3]))\n\n\n[1] 0.8481769\n\n\nWe are going to make the expression above a bit more general and more compact. First, rather than refer explicitly to a response time of 1, we will refer to a variable rt (which we can set to one):\n\n\nCode\nv &lt;- c(0, 2, 1)\na &lt;- c(2, 2, 2)\nt0 &lt;- c(0.2, 0.2, 0.2)\n\nrt &lt;- 1\n\naccum_pdf(t = rt, a = a[2], v = v[2], t0 = t0[2]) *\n    (1 - accum_cdf(t = rt, a = a[1], v = v[1], t0 = t0[1])) *\n    (1 - accum_cdf(t = rt, a = a[3], v = v[3], t0 = t0[3]))\n\n\n[1] 0.8481769\n\n\nSecond, we can use the prod function to multiply together the two terms at the end, making use of the fact that accum_cdf can accept vectors as arguments:\n\n\nCode\nv &lt;- c(0, 2, 1)\na &lt;- c(2, 2, 2)\nt0 &lt;- c(0.2, 0.2, 0.2)\n\nrt &lt;- 1\n\naccum_pdf(t = rt, a = a[2], v = v[2], t0 = t0[2]) *\n    prod(1 - accum_cdf(t = rt, a = a[c(1, 3)], v = v[c(1, 3)], t0 = t0[c(1, 3)]))\n\n\n[1] 0.8481769\n\n\nThird, instead of explicitly referring to individual accumulators, we can define a variable called response (and set it to 2), and use the “negative indexing trick” for the second term:\n\n\nCode\nv &lt;- c(0, 2, 1)\na &lt;- c(2, 2, 2)\nt0 &lt;- c(0.2, 0.2, 0.2)\n\nrt &lt;- 1\nresponse &lt;- 2\n\naccum_pdf(t = rt, a = a[response], v = v[response], t0 = t0[response]) *\n    prod(1 - accum_cdf(t = rt, a = a[-response], v = v[-response], t0 = t0[-response]))\n\n\n[1] 0.8481769\n\n\nNice! The only problem now is that our code only applies to a single trial at a time. In the next section, we confront the issue of how to compute the likelihood for multiple trials.\n\n\n\n8.2.2 Likelihood for multiple trials\nIn the previous section, we effectively translated a mathematical expression of the model into R code that performs the relevant computations to find the likelihood of a given response at a given time. To apply this code to an entire dataset, which contains many trials, we need to think about how to specify the details of each individual trial.\n\n8.2.2.1 Characterizing each trial\nAgain, it will help to think about a concrete task like visual search. Any given trial involves a number of items, each of which can occupy a given position in the visual search array. For example, one trial might have 3 items with the target occupying the second position while another trial might have 6 items with the target occupying the fifth position. The distractors occupying the non-target positions could be of varying types depending on whether they are more or less similar to the target. Therefore, to characterize any individual trial in this experiment, we need to know, for each possible location that could contain an item, whether or not it does contain an item and, if so, what kind of item it is.\nThere are a few ways we could represent this information in an R data structure, but the simplest is in the form of a matrix. Each row of the matrix will correspond to a different trial in the experiment and each column of the matrix corresponds to a different location that may or may not contain an item on that trial. We can give each type of item a numerical index. For example, maybe 1 corresponds to targets, 2 corresponds to similar distractors, and 3 corresponds to dissimilar distractors. To indicate that a location does not contain an item, we can give it the value NA. For example, the following matrix could describe four trials in a search experiment with six possible display locations:\n\n\nCode\nmatrix(c(\n    1, NA, NA,  2, NA, NA,\n    2,  1,  2,  3,  3,  3,\n    NA, NA, 3,  1,  3, NA,\n    NA,  3, NA,  2, NA, 1\n), nrow = 4, ncol = 6, byrow = TRUE)\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1   NA   NA    2   NA   NA\n[2,]    2    1    2    3    3    3\n[3,]   NA   NA    3    1    3   NA\n[4,]   NA    3   NA    2   NA    1\n\n\nAlternatively, we could imagine a decision making task in which each trial presents three options selected from a set of six possible products:\n\n\nCode\nmatrix(c(\n    1, 2, 3,\n    1, 4, 5,\n    6, 4, 2,\n    5, 2, 6\n), nrow = 4, ncol = 3, byrow = TRUE)\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    1    4    5\n[3,]    6    4    2\n[4,]    5    2    6\n\n\nThese concrete examples suggest the general structure of the tasks to which we can typically apply a race model: Each trial presents a number of options, each of which is selected from a set of possible options. Moreover, sometimes the ordering/location of the options may matter (like in visual search) but sometimes it may not (like in the decision task).\n\n\n8.2.2.2 Defining model parameters\nThese examples also suggest what kind of parameters our model will need to have. Specifically, we will need to have a drift rate parameter for each type of item in the experiment. We could have a single threshold parameter that applies to all accumulators. Alternatively, we could allow different locations to have different thresholds, modeling the idea that there may be a bias in favor of choosing options in particular locations. Similarly, we could have a single residual time parameter for all accumulators or we could allow residual time to vary by location, allowing us to model situations in which processing begins earlier for some locations than others.\nLet’s again make this concrete and return to the visual search experiment. We will keep things simple and assume just one threshold parameter and one residual time parameter apply to all accumulators, regardless of location. We will have three possible values of drift rate for three categories of item:\n\nTargets\nSimilar distractors\nDissimilar distractors\n\nTo compute the likelihood for each trial, we will need to refer to the corresponding row in the matrix and use the drift rates that correspond to the items shown on that trial.\n\n\nCode\n# Specify item types/locations for each trial\nitems &lt;- matrix(c(\n    1, NA, NA,  2, NA, NA,\n    2,  1,  2,  3,  3,  3,\n    NA, NA, 3,  1,  3, NA,\n    NA,  3, NA,  2, NA, 1\n), nrow = 4, ncol = 6, byrow = TRUE)\n\n# Responses and response times for each trial\n# Notice that responses refer to the *position* of the chosen item!\nresponse &lt;- c(1, 2, 4, 4)\nrt &lt;- c(0.6, 1.5, 0.7, 1.2)\n\nn_trials &lt;- nrow(items)\nn_locations &lt;- ncol(items)\n\n# Model parameters\n# One drift rate for each type of item\nv &lt;- c(2, 1, 0)\n# One threshold for each possible location\na &lt;- rep(2, n_locations)\n# One residual time for each possible location\nt0 &lt;- rep(0.2, n_locations)\n\n# Allocate vector that will eventually contain the negative log-likelihood\n# for each trial\nnll &lt;- rep(0, n_trials)\n\n# Calculate the log-likelihood for each trial\nfor (i in 1:n_trials) {\n    # Note that the whole thing is wrapped in \"-log()\" so we get the negative log-likelihood\n    # Note also the use of \"na.rm = TRUE\" in the \"prod()\" function to ignore any locations\n    # that don't contain an item\n    nll[i] &lt;- -log(\n        accum_pdf(t = rt[i], a = a[response[i]], v = v[items[i, response[i]]], t0 = t0[response[i]]) *\n            prod(1 - accum_cdf(t = rt[i], a = a[-response[i]], v = v[items[i, -response[i]]], t0 = t0[-response[i]]), na.rm = TRUE)\n    )\n}\n\nprint(nll)\n\n\n[1] 0.6611439 1.9408143 0.1954480 1.6747733\n\n\nYou’ll note that the NLL for each trial is calculated using a for loop at the end—there are ways to make this more efficient, but I will leave those as an exercise for the reader!\n\n\n\n8.2.3 Extracting parameters\nWe are almost there! We have code that will take a set of model parameters and a representation of the options on each trial and compute the negative log-likelihood of each response made on each trial. All that is left is to “wrap” this code into a function. However, we will need to define the arguments of this function in a particular way in order to get the function to play nicely with the parameter search functions we will use. Specifically, the function will need to take the following arguments:\n\nThe matrix that specifies the options on each trial; we called this items in the code above.\nThe vector of responses made on each trial; we called this response in the code above.\nThe vector of response times on each trial; we called this rt in the code above.\nFinally, and this is the tricky part, we need a single vector that contains all the parameters of our model. As we will see, the “trick” is to extract the parameter values from this vector based on the names of the elements in the vector.\n\nLet’s lay out the outline of our function before we get to the tricky part:\n\n\nCode\nrace_nll &lt;- function(par, response, rt, items) {\n    n_trials &lt;- nrow(items)\n    n_locations &lt;- ncol(items)\n    \n    # TRICKY PART HERE\n    v &lt;- ...\n    a &lt;- ...\n    t0 &lt;- ...\n    \n    nll &lt;- rep(0, n_trials)\n    \n    for (i in 1:n_trials) {\n        nll[i] &lt;- -log(\n            accum_pdf(t = rt[i], a = a[response[i]], v = v[items[i, response[i]]], t0 = t0[response[i]]) *\n                prod(1 - accum_cdf(t = rt[i], a = a[-response[i]], v = v[items[i, -response[i]]], t0 = t0[-response[i]]), na.rm = TRUE)\n        )\n    }\n    \n    return(sum(nll))\n}\n\n\nTo get a grasp on the problem we have to solve, it’ll be good to have in mind a picture of what par looks like. It will be a named vector, meaning it will look something like this:\n\n\nCode\npar &lt;- c(\n    \"v[1]\" = 2,\n    \"v[2]\" = 1,\n    \"v[3]\" = 0,\n    \"a\" = 2,\n    \"t0\" = 0.2\n)\n\n\nWe can use the names of the elements to extract them, like so:\n\n\nCode\npar[\"a\"]\n\n\na \n2 \n\n\nWe can also get a bit clever by using the paste0 function:\n\n\nCode\npar[paste0(\"v[\", 1:3, \"]\")]\n\n\nv[1] v[2] v[3] \n   2    1    0 \n\n\nFinally, we can check to see whether the vector contains an element with a particular name by using is.na, which is TRUE if an element does not exist in the vector:\n\n\nCode\nis.na(par[\"t0\"])\n\n\n   t0 \nFALSE \n\n\nCode\nis.na(par[\"t0[1]\"])\n\n\n&lt;NA&gt; \nTRUE \n\n\nThe latter trick will allow us to make our race_nll function more general, because we can check to see whether the par vector contains, for example, several threshold parameters or only one. The whole shebang is illustrated in the complete function below:\n\n\nCode\nrace_nll &lt;- function(par, response, rt, items, n_items = max(items, na.rm = TRUE)) {\n    n_trials &lt;- nrow(items)\n    n_locations &lt;- ncol(items)\n    \n    if (is.na(par[\"v\"])) {\n        v &lt;- par[paste0(\"v[\", 1:n_items, \"]\")]\n    } else {\n        v &lt;- rep(par[\"v\"], n_items)\n    }\n    \n    if (is.na(par[\"a\"])) {\n        a &lt;- par[paste0(\"a[\", 1:n_locations, \"]\")]\n    } else {\n        a &lt;- rep(par[\"a\"], n_locations)\n    }\n    \n    if (is.na(par[\"t0\"])) {\n        t0 &lt;- par[paste0(\"t0[\", 1:n_locations, \"]\")]\n    } else {\n        t0 &lt;- rep(par[\"t0\"], n_locations)\n    }\n    \n    nll &lt;- rep(0, n_trials)\n    \n    for (i in 1:n_trials) {\n        nll[i] &lt;- -log(\n            accum_pdf(t = rt[i], a = a[response[i]], v = v[items[i, response[i]]], t0 = t0[response[i]]) *\n                prod(1 - accum_cdf(t = rt[i], a = a[-response[i]], v = v[items[i, -response[i]]], t0 = t0[-response[i]]), na.rm = TRUE)\n        )\n    }\n    \n    return(sum(nll))\n}\n\n\nFor each parameter, we check to see whether the par vector contains an element named without an index after it. If so, then the corresponding value is “recycled” for each item/location. Otherwise, we assume that the par vector contains different indexed values for each item/location and we extract those from the par vector for later use. Notice that I added a function argument called n_items so we can specify how many different item types there could be; the default value (the largest number specified in the items matrix) should work, but there may be situations in which it doesn’t.\nBefore closing this section, you may have noticed something missing! We could include a feedforward competition parameter too. However, that is left as an exercise for the reader.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#fitting-the-race-model",
    "href": "accumulator_models.html#fitting-the-race-model",
    "title": "8  Accumulator models of choice and response time",
    "section": "8.3 Fitting the race model",
    "text": "8.3 Fitting the race model\nFinally, we have our race_nll function which we can use to fit the race model to data, that is, to find the parameters of the model that assign the highest likelihood to some set of data.\n\n8.3.1 Simulating some data\nTo do that, we’ll first need some data! For example purposes, we can simulate some plausible data. Like we did with the diffusion model, the advantage of fitting simulated data is that we know the “ground truth” and can therefore see how well we can recover the parameters we used to generate the data.\nThe chunk of code below simulates data in a visual search experiment in which two factors are manipulated, set size and target-distractor similarity. Since the simulations don’t allow for different parameters for different locations, I keep things simple and have the target always appear in location 1.\n\n\nCode\nv &lt;- c(2, 1, 0)\na &lt;- 2\nt0 &lt;- 0.2\n\nn_trials_per_cond &lt;- 50\n\nset_size_vals &lt;- c(2, 4, 8)\n\nitems &lt;- c()\nresponse &lt;- c()\nrt &lt;- c()\n\nfor (set_size in set_size_vals) {\n    for (td_sim in c(\"low\", \"high\")) {\n        distractor_type &lt;- ifelse(td_sim == \"low\", 3, 2)\n        \n        for (i in 1:n_trials_per_cond) {\n            items &lt;- rbind(\n                items,\n                c(1, rep(distractor_type, set_size - 1), rep(NA, max(set_size_vals) - set_size))\n            )\n            \n            current_result &lt;- race_sim(v = c(v[1], rep(v[distractor_type], set_size - 1)), a = a, t0 = t0, dt = 0.001)\n            \n            # Extract just the choice and RT\n            rt &lt;- c(rt, current_result$t[nrow(current_result)])\n            response &lt;- c(response, which.max(current_result[nrow(current_result), 2:ncol(current_result)]))\n        }\n    }\n}\n\n\nIn the end, we have our matrix specifying what is in each display:\n\n\nCode\nitems\n\n\n       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n  [1,]    1    3   NA   NA   NA   NA   NA   NA\n  [2,]    1    3   NA   NA   NA   NA   NA   NA\n  [3,]    1    3   NA   NA   NA   NA   NA   NA\n  [4,]    1    3   NA   NA   NA   NA   NA   NA\n  [5,]    1    3   NA   NA   NA   NA   NA   NA\n  [6,]    1    3   NA   NA   NA   NA   NA   NA\n  [7,]    1    3   NA   NA   NA   NA   NA   NA\n  [8,]    1    3   NA   NA   NA   NA   NA   NA\n  [9,]    1    3   NA   NA   NA   NA   NA   NA\n [10,]    1    3   NA   NA   NA   NA   NA   NA\n [11,]    1    3   NA   NA   NA   NA   NA   NA\n [12,]    1    3   NA   NA   NA   NA   NA   NA\n [13,]    1    3   NA   NA   NA   NA   NA   NA\n [14,]    1    3   NA   NA   NA   NA   NA   NA\n [15,]    1    3   NA   NA   NA   NA   NA   NA\n [16,]    1    3   NA   NA   NA   NA   NA   NA\n [17,]    1    3   NA   NA   NA   NA   NA   NA\n [18,]    1    3   NA   NA   NA   NA   NA   NA\n [19,]    1    3   NA   NA   NA   NA   NA   NA\n [20,]    1    3   NA   NA   NA   NA   NA   NA\n [21,]    1    3   NA   NA   NA   NA   NA   NA\n [22,]    1    3   NA   NA   NA   NA   NA   NA\n [23,]    1    3   NA   NA   NA   NA   NA   NA\n [24,]    1    3   NA   NA   NA   NA   NA   NA\n [25,]    1    3   NA   NA   NA   NA   NA   NA\n [26,]    1    3   NA   NA   NA   NA   NA   NA\n [27,]    1    3   NA   NA   NA   NA   NA   NA\n [28,]    1    3   NA   NA   NA   NA   NA   NA\n [29,]    1    3   NA   NA   NA   NA   NA   NA\n [30,]    1    3   NA   NA   NA   NA   NA   NA\n [31,]    1    3   NA   NA   NA   NA   NA   NA\n [32,]    1    3   NA   NA   NA   NA   NA   NA\n [33,]    1    3   NA   NA   NA   NA   NA   NA\n [34,]    1    3   NA   NA   NA   NA   NA   NA\n [35,]    1    3   NA   NA   NA   NA   NA   NA\n [36,]    1    3   NA   NA   NA   NA   NA   NA\n [37,]    1    3   NA   NA   NA   NA   NA   NA\n [38,]    1    3   NA   NA   NA   NA   NA   NA\n [39,]    1    3   NA   NA   NA   NA   NA   NA\n [40,]    1    3   NA   NA   NA   NA   NA   NA\n [41,]    1    3   NA   NA   NA   NA   NA   NA\n [42,]    1    3   NA   NA   NA   NA   NA   NA\n [43,]    1    3   NA   NA   NA   NA   NA   NA\n [44,]    1    3   NA   NA   NA   NA   NA   NA\n [45,]    1    3   NA   NA   NA   NA   NA   NA\n [46,]    1    3   NA   NA   NA   NA   NA   NA\n [47,]    1    3   NA   NA   NA   NA   NA   NA\n [48,]    1    3   NA   NA   NA   NA   NA   NA\n [49,]    1    3   NA   NA   NA   NA   NA   NA\n [50,]    1    3   NA   NA   NA   NA   NA   NA\n [51,]    1    2   NA   NA   NA   NA   NA   NA\n [52,]    1    2   NA   NA   NA   NA   NA   NA\n [53,]    1    2   NA   NA   NA   NA   NA   NA\n [54,]    1    2   NA   NA   NA   NA   NA   NA\n [55,]    1    2   NA   NA   NA   NA   NA   NA\n [56,]    1    2   NA   NA   NA   NA   NA   NA\n [57,]    1    2   NA   NA   NA   NA   NA   NA\n [58,]    1    2   NA   NA   NA   NA   NA   NA\n [59,]    1    2   NA   NA   NA   NA   NA   NA\n [60,]    1    2   NA   NA   NA   NA   NA   NA\n [61,]    1    2   NA   NA   NA   NA   NA   NA\n [62,]    1    2   NA   NA   NA   NA   NA   NA\n [63,]    1    2   NA   NA   NA   NA   NA   NA\n [64,]    1    2   NA   NA   NA   NA   NA   NA\n [65,]    1    2   NA   NA   NA   NA   NA   NA\n [66,]    1    2   NA   NA   NA   NA   NA   NA\n [67,]    1    2   NA   NA   NA   NA   NA   NA\n [68,]    1    2   NA   NA   NA   NA   NA   NA\n [69,]    1    2   NA   NA   NA   NA   NA   NA\n [70,]    1    2   NA   NA   NA   NA   NA   NA\n [71,]    1    2   NA   NA   NA   NA   NA   NA\n [72,]    1    2   NA   NA   NA   NA   NA   NA\n [73,]    1    2   NA   NA   NA   NA   NA   NA\n [74,]    1    2   NA   NA   NA   NA   NA   NA\n [75,]    1    2   NA   NA   NA   NA   NA   NA\n [76,]    1    2   NA   NA   NA   NA   NA   NA\n [77,]    1    2   NA   NA   NA   NA   NA   NA\n [78,]    1    2   NA   NA   NA   NA   NA   NA\n [79,]    1    2   NA   NA   NA   NA   NA   NA\n [80,]    1    2   NA   NA   NA   NA   NA   NA\n [81,]    1    2   NA   NA   NA   NA   NA   NA\n [82,]    1    2   NA   NA   NA   NA   NA   NA\n [83,]    1    2   NA   NA   NA   NA   NA   NA\n [84,]    1    2   NA   NA   NA   NA   NA   NA\n [85,]    1    2   NA   NA   NA   NA   NA   NA\n [86,]    1    2   NA   NA   NA   NA   NA   NA\n [87,]    1    2   NA   NA   NA   NA   NA   NA\n [88,]    1    2   NA   NA   NA   NA   NA   NA\n [89,]    1    2   NA   NA   NA   NA   NA   NA\n [90,]    1    2   NA   NA   NA   NA   NA   NA\n [91,]    1    2   NA   NA   NA   NA   NA   NA\n [92,]    1    2   NA   NA   NA   NA   NA   NA\n [93,]    1    2   NA   NA   NA   NA   NA   NA\n [94,]    1    2   NA   NA   NA   NA   NA   NA\n [95,]    1    2   NA   NA   NA   NA   NA   NA\n [96,]    1    2   NA   NA   NA   NA   NA   NA\n [97,]    1    2   NA   NA   NA   NA   NA   NA\n [98,]    1    2   NA   NA   NA   NA   NA   NA\n [99,]    1    2   NA   NA   NA   NA   NA   NA\n[100,]    1    2   NA   NA   NA   NA   NA   NA\n[101,]    1    3    3    3   NA   NA   NA   NA\n[102,]    1    3    3    3   NA   NA   NA   NA\n[103,]    1    3    3    3   NA   NA   NA   NA\n[104,]    1    3    3    3   NA   NA   NA   NA\n[105,]    1    3    3    3   NA   NA   NA   NA\n[106,]    1    3    3    3   NA   NA   NA   NA\n[107,]    1    3    3    3   NA   NA   NA   NA\n[108,]    1    3    3    3   NA   NA   NA   NA\n[109,]    1    3    3    3   NA   NA   NA   NA\n[110,]    1    3    3    3   NA   NA   NA   NA\n[111,]    1    3    3    3   NA   NA   NA   NA\n[112,]    1    3    3    3   NA   NA   NA   NA\n[113,]    1    3    3    3   NA   NA   NA   NA\n[114,]    1    3    3    3   NA   NA   NA   NA\n[115,]    1    3    3    3   NA   NA   NA   NA\n[116,]    1    3    3    3   NA   NA   NA   NA\n[117,]    1    3    3    3   NA   NA   NA   NA\n[118,]    1    3    3    3   NA   NA   NA   NA\n[119,]    1    3    3    3   NA   NA   NA   NA\n[120,]    1    3    3    3   NA   NA   NA   NA\n[121,]    1    3    3    3   NA   NA   NA   NA\n[122,]    1    3    3    3   NA   NA   NA   NA\n[123,]    1    3    3    3   NA   NA   NA   NA\n[124,]    1    3    3    3   NA   NA   NA   NA\n[125,]    1    3    3    3   NA   NA   NA   NA\n[126,]    1    3    3    3   NA   NA   NA   NA\n[127,]    1    3    3    3   NA   NA   NA   NA\n[128,]    1    3    3    3   NA   NA   NA   NA\n[129,]    1    3    3    3   NA   NA   NA   NA\n[130,]    1    3    3    3   NA   NA   NA   NA\n[131,]    1    3    3    3   NA   NA   NA   NA\n[132,]    1    3    3    3   NA   NA   NA   NA\n[133,]    1    3    3    3   NA   NA   NA   NA\n[134,]    1    3    3    3   NA   NA   NA   NA\n[135,]    1    3    3    3   NA   NA   NA   NA\n[136,]    1    3    3    3   NA   NA   NA   NA\n[137,]    1    3    3    3   NA   NA   NA   NA\n[138,]    1    3    3    3   NA   NA   NA   NA\n[139,]    1    3    3    3   NA   NA   NA   NA\n[140,]    1    3    3    3   NA   NA   NA   NA\n[141,]    1    3    3    3   NA   NA   NA   NA\n[142,]    1    3    3    3   NA   NA   NA   NA\n[143,]    1    3    3    3   NA   NA   NA   NA\n[144,]    1    3    3    3   NA   NA   NA   NA\n[145,]    1    3    3    3   NA   NA   NA   NA\n[146,]    1    3    3    3   NA   NA   NA   NA\n[147,]    1    3    3    3   NA   NA   NA   NA\n[148,]    1    3    3    3   NA   NA   NA   NA\n[149,]    1    3    3    3   NA   NA   NA   NA\n[150,]    1    3    3    3   NA   NA   NA   NA\n[151,]    1    2    2    2   NA   NA   NA   NA\n[152,]    1    2    2    2   NA   NA   NA   NA\n[153,]    1    2    2    2   NA   NA   NA   NA\n[154,]    1    2    2    2   NA   NA   NA   NA\n[155,]    1    2    2    2   NA   NA   NA   NA\n[156,]    1    2    2    2   NA   NA   NA   NA\n[157,]    1    2    2    2   NA   NA   NA   NA\n[158,]    1    2    2    2   NA   NA   NA   NA\n[159,]    1    2    2    2   NA   NA   NA   NA\n[160,]    1    2    2    2   NA   NA   NA   NA\n[161,]    1    2    2    2   NA   NA   NA   NA\n[162,]    1    2    2    2   NA   NA   NA   NA\n[163,]    1    2    2    2   NA   NA   NA   NA\n[164,]    1    2    2    2   NA   NA   NA   NA\n[165,]    1    2    2    2   NA   NA   NA   NA\n[166,]    1    2    2    2   NA   NA   NA   NA\n[167,]    1    2    2    2   NA   NA   NA   NA\n[168,]    1    2    2    2   NA   NA   NA   NA\n[169,]    1    2    2    2   NA   NA   NA   NA\n[170,]    1    2    2    2   NA   NA   NA   NA\n[171,]    1    2    2    2   NA   NA   NA   NA\n[172,]    1    2    2    2   NA   NA   NA   NA\n[173,]    1    2    2    2   NA   NA   NA   NA\n[174,]    1    2    2    2   NA   NA   NA   NA\n[175,]    1    2    2    2   NA   NA   NA   NA\n[176,]    1    2    2    2   NA   NA   NA   NA\n[177,]    1    2    2    2   NA   NA   NA   NA\n[178,]    1    2    2    2   NA   NA   NA   NA\n[179,]    1    2    2    2   NA   NA   NA   NA\n[180,]    1    2    2    2   NA   NA   NA   NA\n[181,]    1    2    2    2   NA   NA   NA   NA\n[182,]    1    2    2    2   NA   NA   NA   NA\n[183,]    1    2    2    2   NA   NA   NA   NA\n[184,]    1    2    2    2   NA   NA   NA   NA\n[185,]    1    2    2    2   NA   NA   NA   NA\n[186,]    1    2    2    2   NA   NA   NA   NA\n[187,]    1    2    2    2   NA   NA   NA   NA\n[188,]    1    2    2    2   NA   NA   NA   NA\n[189,]    1    2    2    2   NA   NA   NA   NA\n[190,]    1    2    2    2   NA   NA   NA   NA\n[191,]    1    2    2    2   NA   NA   NA   NA\n[192,]    1    2    2    2   NA   NA   NA   NA\n[193,]    1    2    2    2   NA   NA   NA   NA\n[194,]    1    2    2    2   NA   NA   NA   NA\n[195,]    1    2    2    2   NA   NA   NA   NA\n[196,]    1    2    2    2   NA   NA   NA   NA\n[197,]    1    2    2    2   NA   NA   NA   NA\n[198,]    1    2    2    2   NA   NA   NA   NA\n[199,]    1    2    2    2   NA   NA   NA   NA\n[200,]    1    2    2    2   NA   NA   NA   NA\n[201,]    1    3    3    3    3    3    3    3\n[202,]    1    3    3    3    3    3    3    3\n[203,]    1    3    3    3    3    3    3    3\n[204,]    1    3    3    3    3    3    3    3\n[205,]    1    3    3    3    3    3    3    3\n[206,]    1    3    3    3    3    3    3    3\n[207,]    1    3    3    3    3    3    3    3\n[208,]    1    3    3    3    3    3    3    3\n[209,]    1    3    3    3    3    3    3    3\n[210,]    1    3    3    3    3    3    3    3\n[211,]    1    3    3    3    3    3    3    3\n[212,]    1    3    3    3    3    3    3    3\n[213,]    1    3    3    3    3    3    3    3\n[214,]    1    3    3    3    3    3    3    3\n[215,]    1    3    3    3    3    3    3    3\n[216,]    1    3    3    3    3    3    3    3\n[217,]    1    3    3    3    3    3    3    3\n[218,]    1    3    3    3    3    3    3    3\n[219,]    1    3    3    3    3    3    3    3\n[220,]    1    3    3    3    3    3    3    3\n[221,]    1    3    3    3    3    3    3    3\n[222,]    1    3    3    3    3    3    3    3\n[223,]    1    3    3    3    3    3    3    3\n[224,]    1    3    3    3    3    3    3    3\n[225,]    1    3    3    3    3    3    3    3\n[226,]    1    3    3    3    3    3    3    3\n[227,]    1    3    3    3    3    3    3    3\n[228,]    1    3    3    3    3    3    3    3\n[229,]    1    3    3    3    3    3    3    3\n[230,]    1    3    3    3    3    3    3    3\n[231,]    1    3    3    3    3    3    3    3\n[232,]    1    3    3    3    3    3    3    3\n[233,]    1    3    3    3    3    3    3    3\n[234,]    1    3    3    3    3    3    3    3\n[235,]    1    3    3    3    3    3    3    3\n[236,]    1    3    3    3    3    3    3    3\n[237,]    1    3    3    3    3    3    3    3\n[238,]    1    3    3    3    3    3    3    3\n[239,]    1    3    3    3    3    3    3    3\n[240,]    1    3    3    3    3    3    3    3\n[241,]    1    3    3    3    3    3    3    3\n[242,]    1    3    3    3    3    3    3    3\n[243,]    1    3    3    3    3    3    3    3\n[244,]    1    3    3    3    3    3    3    3\n[245,]    1    3    3    3    3    3    3    3\n[246,]    1    3    3    3    3    3    3    3\n[247,]    1    3    3    3    3    3    3    3\n[248,]    1    3    3    3    3    3    3    3\n[249,]    1    3    3    3    3    3    3    3\n[250,]    1    3    3    3    3    3    3    3\n[251,]    1    2    2    2    2    2    2    2\n[252,]    1    2    2    2    2    2    2    2\n[253,]    1    2    2    2    2    2    2    2\n[254,]    1    2    2    2    2    2    2    2\n[255,]    1    2    2    2    2    2    2    2\n[256,]    1    2    2    2    2    2    2    2\n[257,]    1    2    2    2    2    2    2    2\n[258,]    1    2    2    2    2    2    2    2\n[259,]    1    2    2    2    2    2    2    2\n[260,]    1    2    2    2    2    2    2    2\n[261,]    1    2    2    2    2    2    2    2\n[262,]    1    2    2    2    2    2    2    2\n[263,]    1    2    2    2    2    2    2    2\n[264,]    1    2    2    2    2    2    2    2\n[265,]    1    2    2    2    2    2    2    2\n[266,]    1    2    2    2    2    2    2    2\n[267,]    1    2    2    2    2    2    2    2\n[268,]    1    2    2    2    2    2    2    2\n[269,]    1    2    2    2    2    2    2    2\n[270,]    1    2    2    2    2    2    2    2\n[271,]    1    2    2    2    2    2    2    2\n[272,]    1    2    2    2    2    2    2    2\n[273,]    1    2    2    2    2    2    2    2\n[274,]    1    2    2    2    2    2    2    2\n[275,]    1    2    2    2    2    2    2    2\n[276,]    1    2    2    2    2    2    2    2\n[277,]    1    2    2    2    2    2    2    2\n[278,]    1    2    2    2    2    2    2    2\n[279,]    1    2    2    2    2    2    2    2\n[280,]    1    2    2    2    2    2    2    2\n[281,]    1    2    2    2    2    2    2    2\n[282,]    1    2    2    2    2    2    2    2\n[283,]    1    2    2    2    2    2    2    2\n[284,]    1    2    2    2    2    2    2    2\n[285,]    1    2    2    2    2    2    2    2\n[286,]    1    2    2    2    2    2    2    2\n[287,]    1    2    2    2    2    2    2    2\n[288,]    1    2    2    2    2    2    2    2\n[289,]    1    2    2    2    2    2    2    2\n[290,]    1    2    2    2    2    2    2    2\n[291,]    1    2    2    2    2    2    2    2\n[292,]    1    2    2    2    2    2    2    2\n[293,]    1    2    2    2    2    2    2    2\n[294,]    1    2    2    2    2    2    2    2\n[295,]    1    2    2    2    2    2    2    2\n[296,]    1    2    2    2    2    2    2    2\n[297,]    1    2    2    2    2    2    2    2\n[298,]    1    2    2    2    2    2    2    2\n[299,]    1    2    2    2    2    2    2    2\n[300,]    1    2    2    2    2    2    2    2\n\n\nas well as our vectors for the response on each trial\n\n\nCode\nresponse\n\n\nx1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x2 x1 x1 \n 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1 \nx1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x2 x1 x1 x1 x1 x1 x1 \n 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1 \nx1 x1 x1 x1 x1 x1 x1 x1 x2 x1 x1 x2 x2 x2 x1 x1 x1 x1 x2 x1 x1 x1 x1 x1 x1 x1 \n 1  1  1  1  1  1  1  1  2  1  1  2  2  2  1  1  1  1  2  1  1  1  1  1  1  1 \nx1 x1 x1 x1 x1 x1 x2 x2 x1 x2 x2 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 \n 1  1  1  1  1  1  2  2  1  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 \nx1 x1 x2 x1 x1 x1 x3 x2 x1 x1 x2 x1 x1 x3 x1 x1 x2 x1 x1 x1 x2 x1 x1 x4 x1 x1 \n 1  1  2  1  1  1  3  2  1  1  2  1  1  3  1  1  2  1  1  1  2  1  1  4  1  1 \nx1 x1 x1 x1 x4 x1 x1 x1 x1 x1 x1 x1 x1 x1 x1 x4 x1 x1 x1 x1 x3 x4 x1 x3 x3 x3 \n 1  1  1  1  4  1  1  1  1  1  1  1  1  1  1  4  1  1  1  1  3  4  1  3  3  3 \nx3 x1 x4 x1 x2 x1 x2 x1 x2 x1 x1 x4 x1 x1 x4 x1 x3 x1 x2 x1 x2 x3 x2 x1 x1 x1 \n 3  1  4  1  2  1  2  1  2  1  1  4  1  1  4  1  3  1  2  1  2  3  2  1  1  1 \nx1 x2 x1 x1 x1 x3 x1 x2 x1 x1 x2 x2 x3 x1 x4 x1 x1 x1 x5 x1 x1 x1 x8 x1 x1 x1 \n 1  2  1  1  1  3  1  2  1  1  2  2  3  1  4  1  1  1  5  1  1  1  8  1  1  1 \nx1 x1 x1 x1 x4 x1 x1 x1 x1 x1 x1 x6 x3 x1 x1 x1 x1 x6 x1 x1 x1 x6 x8 x1 x1 x1 \n 1  1  1  1  4  1  1  1  1  1  1  6  3  1  1  1  1  6  1  1  1  6  8  1  1  1 \nx1 x1 x1 x1 x1 x1 x5 x5 x1 x8 x1 x1 x1 x1 x1 x2 x7 x7 x1 x2 x4 x1 x1 x1 x2 x1 \n 1  1  1  1  1  1  5  5  1  8  1  1  1  1  1  2  7  7  1  2  4  1  1  1  2  1 \nx8 x4 x1 x1 x7 x1 x1 x3 x1 x1 x1 x2 x1 x1 x7 x1 x4 x2 x1 x8 x8 x1 x4 x6 x7 x7 \n 8  4  1  1  7  1  1  3  1  1  1  2  1  1  7  1  4  2  1  8  8  1  4  6  7  7 \nx1 x2 x1 x3 x8 x1 x4 x1 x4 x5 x6 x2 x2 x1 \n 1  2  1  3  8  1  4  1  4  5  6  2  2  1 \n\n\nand the response time on each trial\n\n\nCode\nrt\n\n\n  [1] 1.136 1.101 1.486 0.996 2.043 1.382 0.707 0.847 2.243 0.693 0.730 0.806\n [13] 0.802 1.124 1.344 1.546 2.010 1.841 0.872 0.842 1.963 0.713 1.208 1.815\n [25] 0.835 1.085 1.266 1.825 1.375 1.861 1.673 1.858 1.324 1.014 1.641 0.946\n [37] 1.185 1.218 1.597 1.051 0.693 1.790 0.637 0.715 0.562 2.067 2.230 1.848\n [49] 1.058 1.741 0.622 0.820 0.513 0.949 1.324 0.818 1.033 0.604 0.741 0.890\n [61] 0.635 0.671 0.612 1.055 0.878 1.054 1.021 1.444 0.844 1.069 0.843 1.347\n [73] 1.013 1.190 0.664 1.068 0.780 0.887 0.678 1.048 0.939 0.522 0.610 0.759\n [85] 0.928 1.490 1.495 0.810 1.180 1.248 0.948 1.064 0.696 1.127 0.703 1.098\n [97] 0.925 1.023 0.802 0.857 1.059 0.643 0.906 1.362 1.182 1.383 1.069 0.721\n[109] 0.966 1.766 1.186 1.764 1.200 0.802 0.957 0.870 0.762 1.328 0.717 0.875\n[121] 1.167 0.762 0.881 2.739 2.425 1.378 1.231 1.073 0.900 1.812 0.860 0.782\n[133] 1.676 0.699 2.438 1.013 1.322 0.765 0.735 1.546 1.098 1.013 1.553 0.842\n[145] 1.384 1.729 0.851 0.900 1.505 1.736 0.607 1.279 0.704 0.537 0.933 1.349\n[157] 1.739 0.805 0.991 0.864 1.159 0.799 0.855 1.569 0.513 0.802 1.416 1.123\n[169] 1.201 0.764 0.658 1.417 1.054 0.757 0.795 0.799 1.025 0.986 0.792 0.898\n[181] 0.661 1.025 0.791 1.323 0.847 1.377 1.034 0.571 0.939 1.207 1.283 2.040\n[193] 1.200 0.986 0.736 1.062 0.549 0.677 0.863 0.847 1.065 0.929 1.000 0.792\n[205] 0.774 0.823 0.997 0.831 0.938 0.968 1.329 1.726 1.359 0.555 0.770 1.358\n[217] 0.492 1.361 0.806 1.713 1.617 1.124 0.846 1.028 0.494 1.828 0.637 1.457\n[229] 1.964 0.636 1.435 0.970 0.652 0.755 1.287 0.801 1.091 0.698 1.575 0.613\n[241] 0.777 0.717 0.640 1.480 0.759 0.567 1.047 0.693 1.204 0.756 0.644 0.944\n[253] 0.662 1.048 0.969 0.692 1.024 0.990 0.561 0.752 0.941 0.657 0.672 1.156\n[265] 0.647 1.046 0.683 0.583 0.699 0.977 0.823 0.698 0.536 0.888 0.840 0.882\n[277] 0.694 0.848 0.589 0.586 0.880 0.616 1.350 0.755 0.728 1.024 0.574 1.259\n[289] 1.166 0.738 0.841 0.621 0.761 0.611 0.908 1.407 1.049 1.232 0.754 1.079\n\n\nThese will be the data to which we will fit our race model.\n\n\n8.3.2 Fitting parameters\nFinally, we are in a position to fit the race model to our (simulated) data. We will be using R’s built-in nlminb function for this purpose, which operates very similarly to the optim function in R. The reason we are using nlminb here is because our model parameters should be bounded, i.e., restricted to fall within particular ranges. nlminb is a bit less clunky in this situation.\nGenerally speaking, calling nlminb will look like this:\n\n\nCode\nnlminb(\n    # A vector of initial values that are the \"starting point\" for the search\n    start = ___,\n    # The function that we want to optimize (i.e., get to be as small as possible)\n    objective = ___,\n    # Lower and upper bounds on model parameters (these can be infinite)\n    lower = ___, upper = ___,\n    # Other options to set\n    control = list(___),\n    # Other arguments which will be conveyed to the `objective` to be optimized\n    ...\n)\n\n\nIt is clear that we first need an initial set of parameter values. Our initial guess does not need to be very good, but it should at least be sensible. We will fit the model assuming different drift rates for each item type and a single threshold and residual time:\n\n\nCode\nstart &lt;- c(\n    \"v[1]\" = 0,\n    \"v[2]\" = 0,\n    \"v[3]\" = 0,\n    \"a\" = 1,\n    \"t0\" = 0\n)\n\n\nThe values above were chosen because they are typical of what we might use as a “default” when fitting real data and we don’t know what the true values might be. We also need to specify the lower and upper bounds on each parameter; these bounds are also named vectors:\n\n\nCode\nlower &lt;- c(\n    \"v[1]\" = -Inf, # Drift rates allowed to be negative\n    \"v[2]\" = -Inf,\n    \"v[3]\" = -Inf,\n    \"a\" = 0,       # Thresholds must be nonnegative, since accumulators start at zero\n    \"t0\" = 0       # Minimum residual time is zero\n)\n\nupper &lt;- c(\n    \"v[1]\" = Inf, # Drift rates and threshold can be as high as they need\n    \"v[2]\" = Inf,\n    \"v[3]\" = Inf,\n    \"a\" = Inf,\n    \"t0\" = min(rt) # Residual time cannot be larger than the smallest RT\n)\n\n\nFinally, we have everything we need to fit the model:\n\n\nCode\nfit &lt;- nlminb(\n    start = start,\n    objective = race_nll,\n    lower = lower, upper = upper,\n    # Other options to set (\"eval.max\" is the most common one to play with)\n    control = list(eval.max = 1000),\n    rt = rt,\n    response = response,\n    items = items\n)\n\n\nNow let’s open our present:\n\n\nCode\nfit\n\n\n$par\n      v[1]       v[2]       v[3]          a         t0 \n2.02086803 0.95210575 0.02240357 1.98372419 0.20802590 \n\n$objective\n[1] 350.1683\n\n$convergence\n[1] 0\n\n$iterations\n[1] 44\n\n$evaluations\nfunction gradient \n      54      242 \n\n$message\n[1] \"relative convergence (4)\"\n\n\nAs we can see, the fit we got back from the nlminb function is actually a list. fit$par is a named vector giving us the best-fitting parameters, fit$objective is the best (smallest) value of NLL the model found. We also get some additional information, the most pertinent of which being fit$convergence—if this value is 0, we are probably okay. Be sure to check out the help page on nlminb for more information and examples!\nFor now, it is worth noting that the estimated values of the model parameters are pretty close to those we actually used to simulate the data.\n\n\n8.3.3 Model comparison\nRecall that our simulated data was from a visual search task in which distractors were allowed to vary in how similar they were to the target. Specifically, there were high-similarity distractor (with drift rates of 1) and low-similarity distractors (with drift rates of 0). In a real research context, we might be interested in testing the hypothesis that the two distractor types have different drift rates. We would address that question by fitting the model we used above, which allows for different drift rates for the two types, and also fitting a model in which we allow only a single drift rate parameter that applies to all distractors. We would then use AIC and BIC to decide whether the additional drift rate parameter improved the model fit enough to justify adding the parameter.\nLet’s see how that would go. How can we implement a model that assigns a single drift rate to both types of distractors? We will create a modified version of the items matrix that replaces all the 3s with 2s. We can then fit the model using this modified version. The effect of this will be to apply the same drift rate (which will be v[2] in our simpler model) to both types of foils. The code below accomplishes this.\n\n\nCode\n# Create simpler version of the items matrix\nitems_simple &lt;- items\n# Replace all 3's with 2's\nitems_simple[items_simple == 3] &lt;- 2\n\nstart_simple &lt;- c(\n    \"v[1]\" = 0,\n    \"v[2]\" = 0,\n    \"a\" = 1,\n    \"t0\" = 0\n)\n\nlower_simple &lt;- c(\n    \"v[1]\" = -Inf, # Drift rates allowed to be negative\n    \"v[2]\" = -Inf,\n    \"a\" = 0,       # Thresholds must be nonnegative, since accumulators start at zero\n    \"t0\" = 0       # Minimum residual time is zero\n)\n\nupper_simple &lt;- c(\n    \"v[1]\" = Inf, # Drift rates and threshold can be as high as they need\n    \"v[2]\" = Inf,\n    \"a\" = Inf,\n    \"t0\" = min(rt) # Residual time cannot be larger than the smallest RT\n)\n\nfit_simple &lt;- nlminb(\n    start = start_simple,\n    objective = race_nll,\n    lower = lower_simple, upper = upper_simple,\n    control = list(eval.max = 1000),\n    rt = rt,\n    response = response,\n    items = items_simple\n)\n\n\nAnd here’s the result:\n\n\nCode\nfit_simple\n\n\n$par\n     v[1]      v[2]         a        t0 \n1.7622345 0.1271764 1.6013550 0.2934703 \n\n$objective\n[1] 374.5381\n\n$convergence\n[1] 0\n\n$iterations\n[1] 26\n\n$evaluations\nfunction gradient \n      38      121 \n\n$message\n[1] \"relative convergence (4)\"\n\n\nAs before, we can compute AIC for each model:\n\n\nCode\n2 * fit$objective + 2 * length(fit$par)\n\n\n[1] 710.3365\n\n\nCode\n2 * fit_simple$objective + 2 * length(fit_simple$par)\n\n\n[1] 757.0762\n\n\nas well as BIC\n\n\nCode\n2 * fit$objective + log(length(rt)) * length(fit$par)\n\n\n[1] 728.8554\n\n\nCode\n2 * fit_simple$objective + log(length(rt)) * length(fit_simple$par)\n\n\n[1] 771.8914\n\n\nOn both counts, the original model (fit) is preferred, confirming that the two distractor types are best explained as having two different drift rates.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#decision-rules",
    "href": "accumulator_models.html#decision-rules",
    "title": "8  Accumulator models of choice and response time",
    "section": "8.4 Decision rules",
    "text": "8.4 Decision rules\nOne final thing to note is that the race models we have explored so far assume that responses are based on whichever accumulator wins the race. This represents a decision rule that is self-terminating or minimum time. Alternatively, one could imagine tasks in which decisions could only be made once all accumulators had finished, amounting to an exhaustive or maximum time decision rule.\nFor example, if the visual search task required participants not to pick which item was the target, but to decide whether or not a target was present at all, this would imply different decision rules for different responses. Responding that a target was present at all could be done using a self-terminating rule—if any accumulator reaches threshold, that could cause a participant to decide that there was a target in the display. On the other hand, saying that there were no targets in the display would require exhaustively processing each item to verify that it was not a target. This latter task constraint could imply that each accumulator has both upper and lower bounds, where the lower bound corresponds to a decision that the item is not a target. Alternatively, each item might be associated with two accumulators, one that accumulates evidence that supports the item being a target and another that accumulates evidence that the item is not a target. Finally, one could retain the same racing diffusion model we’ve been developing but include an additional no target accumulator that races against the accumulators for each item—if the “no target” accumulator wins, the participant decides that none of the items were targets.\nThe point in laying out these possibilities is that, once we consider models with many possibly overlapping and interacting processes, we must also think carefully about how the results of those processes translate into observed behavior. There are many different ways of processing and combining information from multiple sources, each of which could lead to a different model of the task. The value of modeling is that this cornucopia of possibilities need not be overwhelming—we can build models that instantiate these different possibilities and see which best account for our data. There are even methods, known as Systems Factorial Technology (Harding et al., 2016; Houpt et al., 2014; Townsend & Nozawa, 1995), that are specifically designed to obtain data to distinguish between different models in these situations.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#excursus-accumulators-with-negative-drift-rates",
    "href": "accumulator_models.html#excursus-accumulators-with-negative-drift-rates",
    "title": "8  Accumulator models of choice and response time",
    "section": "8.5 Excursus: Accumulators with negative drift rates",
    "text": "8.5 Excursus: Accumulators with negative drift rates\nYou may have noticed above that, when we fit our race model, we allowed the drift rates for accumulators to be negative. When we were working with diffusion models, this was no big deal—a negative drift rate just means that samples of evidence are more likely to favor the choice associated with the lower bound than the upper bound. The accumulators in our race model, though, do not have a lower bound and so an accumulator with a negative drift rate could actually keep going forever without reaching threshold.\nMathematically, we can actually compute how often that would happen. This involves taking a look at the formula for the CDF. Since the CDF is the probability that the accumulator has reached threshold by time \\(t\\), we can find the probability that the accumulator ever reaches threshold by taking the limit of the CDF as \\(t\\) approaches infinity. As illustrated below, when the drift rate \\(v_i \\geq 0\\), this limit equals 1, meaning with nonnegative drift rates the accumulator will eventually reach threshold (though it may take a long time). When the drift rate \\(v_i &lt; 0\\), though, the limit is \\(\\exp \\left( 2 a_i v_i \\right)\\).\n\\[\\begin{align}\n\\lim_{t \\rightarrow \\infty} F_i \\left( t \\mid a_i, v_i, t_{0i} \\right) & =\n    \\begin{cases}\n        \\Phi \\left( \\infty \\right) + \\exp \\left( 2 a_i v_i \\right) \\Phi \\left( -\\infty \\right) & \\text{if } v_i &gt; 0 \\\\\n        \\Phi \\left( 0 \\right) + \\exp \\left( 0 \\right) \\Phi \\left( 0 \\right) & \\text{if } v_i = 0 \\\\\n        \\Phi \\left( -\\infty \\right) + \\exp \\left( 2 a_i v_i \\right) \\Phi \\left( \\infty \\right) & \\text{if } v_i &lt; 0\n    \\end{cases} \\\\\n    & = \\begin{cases}\n        1 + \\exp \\left( 2 a_i v_i \\right) \\times 0 & \\text{if } v_i &gt; 0 \\\\\n        \\frac{1}{2} + 1 \\times \\frac{1}{2} & \\text{if } v_i = 0 \\\\\n        0 + \\exp \\left( 2 a_i v_i \\right) \\times 1 & \\text{if } v_i &lt; 0\n    \\end{cases} \\\\\n    & = \\begin{cases}\n        1 & \\text{if } v_i \\geq 0 \\\\\n        \\exp \\left( 2 a_i v_i \\right) & \\text{if } v_i &lt; 0\n    \\end{cases}\n\\end{align}\\]\nThis behavior is illustrated in the graphs below. In particular, note the asymptotic level of the CDF functions in the right set of plots as the drift rate grows more negative.\n\n\nCode\ntoPlot &lt;- expand_grid(t = seq(0, 3, length.out = 101), a = c(1, 2), v = seq(-3, 3, length.out = 7)) %&gt;%\n    mutate(threshold_factor = factor(a, levels = sort(unique(a)), labels = paste(\"Threshold =\", sort(unique(a))))) %&gt;%\n    mutate(d = accum_pdf(t = t, a = a, v = v, t0 = 0)) %&gt;%\n    mutate(p = accum_cdf(t = t, a = a, v = v, t0 = 0))\n\npdf_plot &lt;- toPlot %&gt;%\n    ggplot(aes(x = t, y = d, color = v, group = factor(v))) +\n    geom_line() +\n    scale_color_gradient2(mid = \"#bbbbbb\") +\n    facet_wrap(\"threshold_factor\", ncol = 1) +\n    labs(x = \"Time (s)\", y = \"Accumulator PDF\", color = \"Drift rate\")\n\ncdf_plot &lt;- toPlot %&gt;%\n    ggplot(aes(x = t, y = p, color = v, group = factor(v))) +\n    geom_line() +\n    scale_color_gradient2(mid = \"#bbbbbb\") +\n    expand_limits(y = c(0, 1)) +\n    facet_wrap(\"threshold_factor\", ncol = 1) +\n    labs(x = \"Time (s)\", y = \"Accumulator CDF\", color = \"Drift rate\")\n\nprint(\n    pdf_plot + cdf_plot + plot_layout(guides = \"collect\", nrow = 1)\n)\n\n\n\n\n\n\n\n\n\nIf there were only one accumulator involved, we would generally not want to allow for negative drift rates, since this would predict situations in which someone literally never responded. (To my knowledge, no one has reported such a result, but maybe we just haven’t waited long enough.) In models with multiple accumulators, though, all that matters is that at least one accumulator has a nonnegative drift rate—that way, there will always be a winner that will initiate a response. Indeed, in models with feedforward competition, it may be reasonable to allow that competition to result in negative drift rates, since this would effectively suppress responses associated with those accumulators.\nThe larger point is that negative drift rates need not be excluded outright. There may be theoretical reasons to allow for negative drift rates. Moreover, in models that allow for negative drift rates, the optimization algorithm will tend to avoid combinations of parameter values that result in too many negative drift rates since these would be associated with a low likelihood of making a response.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "accumulator_models.html#exercises",
    "href": "accumulator_models.html#exercises",
    "title": "8  Accumulator models of choice and response time",
    "section": "8.6 Exercises",
    "text": "8.6 Exercises\n\nConsider potential psychological interpretations of feedforward inhibition and lateral inhibition. In particular, see if you can relate these two forms of competition to the constructs of attention and capacity.\nAs noted above, diffusion models explain slow errors in terms of trial-by-trial variability in drift rates, while accumulator models explain slow errors in terms of lateral competition between options. Compare and contrast theses. Are there circumstances in which one explanation may be more plausible than the other? Would it be possible to ascribe trial-by-trial variability to lateral competition?\nAs noted in the chapter, it is possible to calculate the negative log-likelihood for the race model including feedforward competition. Implement this mechanism in the race_nll function. To get you started, the chunk of code below contains comments that suggest how this might be done.\n\n\n\nCode\nrace_nll &lt;- function(par, response, rt, items, n_items = max(items, na.rm = TRUE)) {\n    n_trials &lt;- nrow(items)\n    n_locations &lt;- ncol(items)\n    \n    if (is.na(par[\"v\"])) {\n        v &lt;- par[paste0(\"v[\", 1:n_items, \"]\")]\n    } else {\n        v &lt;- rep(par[\"v\"], n_items)\n    }\n    \n    if (is.na(par[\"a\"])) {\n        a &lt;- par[paste0(\"a[\", 1:n_locations, \"]\")]\n    } else {\n        a &lt;- rep(par[\"a\"], n_locations)\n    }\n    \n    if (is.na(par[\"t0\"])) {\n        t0 &lt;- par[paste0(\"t0[\", 1:n_locations, \"]\")]\n    } else {\n        t0 &lt;- rep(par[\"t0\"], n_locations)\n    }\n    \n    # Similar to the above, you can check and see whether a feedforward competition parameter is or is not included; if not, you'll want to set the value of feedforward to zero.\n    if (is.na(par[\"feedforward\"])) {\n        feedforward &lt;- ...\n    } else {\n        feedforward &lt;- ...\n    }\n    \n    nll &lt;- rep(0, n_trials)\n    \n    for (i in 1:n_trials) {\n        # Since drift rates depend on the items presented on each trial, we'll need to calculate them\n        trial_v &lt;- v[items[i, ]]\n        \n        for (j in 1:length(trial_v)) {\n            trial_v[j] &lt;- ...\n        }\n        \n        # Note that the drift rates now refer to \"trial_v\"\n        nll[i] &lt;- -log(\n            accum_pdf(t = rt[i], a = a[response[i]], v = trial_v[response[i]], t0 = t0[response[i]]) *\n                prod(1 - accum_cdf(t = rt[i], a = a[-response[i]], v = trial_v[-response[i]], t0 = t0[-response[i]]), na.rm = TRUE)\n        )\n    }\n    \n    return(sum(nll))\n}\n\n\n\nThe Leaky Competing Accumulator (LCA) model was proposed by Usher & McClelland (2001). In addition to lateral competition, the LCA (as the name implies) assumes that evidence “leaks” out of accumulators at a constant rate. Take a look at their paper (specifically equation 4 on page 559) and modify our race model simulation code to include a leakage parameter. Describe how you did this (and share your code too!).\nAn extension to the racing diffusion model explored in this chapter was proposed by Tillman et al. (2020). Their model allows for trial-by-trial variability in the thresholds of the accumulators. Their Equation 5 and Appendix A provide formulae for the PDF and CDF of the resulting accumulators. Translate these formulae into R code that implements their extended racing diffusion model.\nThe accumulator models we explored in the chapter are all stochastic accumulators, since value of the evidence being accumulated fluctuates randomly around a mean. Brown & Heathcote (2008) proposed a Linear Ballistic Accumulator (LBA) model which only has between-trial variability but is otherwise deterministic. Despite this unrealistic assumption, the model fits data well and often leads to similar conclusions as drawn from stochastic models of evidence accumulation (Donkin et al., 2011). Referring to the equations provided by Brown & Heathcote (2008) for the PDF and CDF of their Linear Ballistic Accumulators, implement their model.\n\n\n\n\n\nBrown, S., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive Psychology, 57, 153–178.\n\n\nDonkin, C., Brown, S., Heathcote, A., & Wagenmakers, E.-J. (2011). Diffusion versus linear ballistic accumulation: Different models but the same conclusions about psychological processes? Psychonomic Bulletin & Review, 55, 140–151.\n\n\nHarding, B., Goulet, M.-A., Jolin, S., Tremblay, C., Villeneuve, S.-P., & Durand, G. (2016). Systems factorial technology explained to humans. The Quantitative Methods for Psychology, 12(1), 39–56.\n\n\nHoupt, J. W., Blaha, L. M., McIntire, J. P., Havig, P. R., & Townsend, J. T. (2014). Systems factorial technology with R. Behavior Research Methods, 46, 307–330.\n\n\nPurcell, B. A., Heitz, R. P., Cohen, J. Y., Schall, J. D., Logan, G. D., & Palmeri, T. J. (2010). Neurally constrained modeling of perceptual decision making. Psychological Review, 117(4), 1113–1143. https://doi.org/10.1037/a0020311\n\n\nPurcell, B. A., Schall, J. D., Logan, G. D., & Palmeri, T. J. (2012). From salience to saccades: Multiple-alternative gated stochastic accumulator model of visual search. Journal of Neuroscience, 32(10), 3433–3446. https://doi.org/10.1523/JNEUROSCI.4622-11.2012\n\n\nRaab, D. H. (1962). Statistical facilitation of simple reaction times. Transactions of the New York Academy of Sciences, 24(5 Series II), 574–590.\n\n\nTeodorescu, A. R., & Usher, M. (2013). Disentangling decision models: From independence to competition. Psychological Review, 120(1), 1–38.\n\n\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability: The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27(5), 911–936. https://doi.org/10.3758/s13423-020-01719-6\n\n\nTownsend, J. T., & Nozawa, G. (1995). Spatio-temporal properties of elementary perception: An investigation of parallel, serial, and coactive theories. Journal of Mathematical Psychology, 39, 321–359.\n\n\nUsher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological Review, 108(3), 550–592.",
    "crumbs": [
      "Modeling behavior",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Accumulator models of choice and response time</span>"
    ]
  },
  {
    "objectID": "ebrw.html",
    "href": "ebrw.html",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "9.1 Summed similarity\nFor concreteness, we imagine an experiment in which several color patches were studied. Colors can be described in terms of three features: hue, chroma (or “saturation”), and luminance (or “brightness”). Imagine that you saw many reddish-hued colors that varied in chroma and luminance. According to the EBRW, each of the colors you saw would leave a trace in memory. Each trace would consist of the values of the color you saw along those three dimensions. In this example, all the colors have the same value for “hue”, which is 0. The value of “0” for “hue” corresponds to a reddish color. The colors differ in their values for chroma and luminance, as illustrated in the graph below:\nCode\ncolDF &lt;- expand_grid(h = hue, c = seq(30, 70, length.out = 5), l = seq(30, 70, length.out = 5)) %&gt;%\n    mutate(col = hcl(h, c, l))\n\ncolDF %&gt;%\n    ggplot(aes(x = c, y = l, fill = col)) +\n    geom_tile(width = 2.5, height = 2.5) +\n    scale_fill_identity() +\n    coord_equal() +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", caption = bquote(plain(hue) == .(round(hue))))\nYour memory traces can also be written as a matrix, where each row corresponds to an item (color) and each column corresponds to a feature (h for “hue”, c for “chroma”, and l for “luminance”):\nCode\nknitr::kable(head(colDF %&gt;% select(h, c, l), 10), row.names = TRUE)\n\n\n\n\n\n\nh\nc\nl\n\n\n\n\n1\n0\n30\n30\n\n\n2\n0\n30\n40\n\n\n3\n0\n30\n50\n\n\n4\n0\n30\n60\n\n\n5\n0\n30\n70\n\n\n6\n0\n40\n30\n\n\n7\n0\n40\n40\n\n\n8\n0\n40\n50\n\n\n9\n0\n40\n60\n\n\n10\n0\n40\n70\nThese coordinates will often be derived using Multidimensional Scaling (MDS) (Nosofsky, 1992; Shepard, 1962a, 1962b). This type of analysis derives a spatial representation of a set of stimuli on the basis of similarity judgments provided by raters.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#summed-similarity",
    "href": "ebrw.html#summed-similarity",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "9.1.1 Perceived distance and similarity\nThe perceived distance between any two of these colors is the Euclidean distance between their feature values, weighted by the degree of attention given to each feature: \\[\nd_{ij} = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{ik} - x_{jk} \\right)^2}\n\\] where \\(w_k\\) is the weight given to feature \\(k\\), \\(x_{ik}\\) is the value of item \\(i\\) on feature \\(k\\), \\(x_{jk}\\) is the value of item \\(j\\) on feature \\(k\\), \\(d_{ij}\\) is the perceived distance between items \\(i\\) and \\(j\\), and \\(N_F\\) is the number of features which in this example is 3 (hue, chroma, and luminance). Note also that while Euclidean distance is appropriate for colors, other types of distance metrics may be more appropriate for other kinds of stimuli, particularly those with separable dimensions which are perceived independently from one another (e.g., Garner & Felfoldy, 1970).\nPerceived similarity between two items, \\(s_{ij}\\), is an exponential function of the psychological distance between those items: \\[\ns_{ij} = \\exp(-c d_{ij})\n\\] where \\(c\\) is a sensitivity parameter that controls how quickly perceived similarity decreases with distance, as illustrated in the graph below:\n\n\nCode\nexpand_grid(d = seq(0, 10, length.out = 151), c = seq(0.25, 3, by = 0.25)) %&gt;%\n    mutate(s = exp(-c * d)) %&gt;%\n    ggplot(aes(x = d, y = s, color = c, group = c)) +\n    geom_line() +\n    scale_color_continuous_sequential() +\n    labs(x = expression(d[ij]), y = expression(s[ij])) +\n    theme(legend.position = \"inside\", legend.position.inside = c(1, 1), legend.justification = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\n9.1.2 Summed similarity\nImagine that you have just been shown two colors from among the set shown earlier. We then present you with a third color—a probe item—and ask whether it was one of the two you just saw. You answer this question on the basis of the summed similarity between the probe item and the two items in memory. The probe item has its own vector of feature values, \\(\\mathbf{x_q}\\). The perceived distance between the probe item and each of the memory items is, as above, the Euclidean distance between the probe’s feature values and those of the memory item: \\[\n\\begin{align}\nd_{qj} & = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{qk} - x_{jk} \\right)^2} \\\\\ns_{qj} & = \\exp \\left( -c d_{qj} \\right) \\\\\nS & = \\sum_{j = 1}^{N_M} s_{qj}\n\\end{align}\n\\] and, again, the perceived similarity \\(s_{qj}\\) between the probe \\(q\\) and memory item \\(j\\) is an exponential function of perceived distance \\(d_{qj}\\). Finally, summed similarity \\(S\\) is the sum of the perceived similarities across all \\(N_M\\) items in memory.\nThe graphs below illustrate how this works. The left graph shows contours of equal similarity from each of two study items. The right graph shows summed similarity as a function of the chroma and luminance of a probe item (assuming the same hue).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d))\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 1, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n9.1.2.1 Trace strength\nIt is reasonable to believe that some memory traces are stronger than others, likely due to things like primacy and recency. In GCM/EBRW, “strength” is operationalized as a scaling factor \\(m_j\\) applied to perceived similarity: \\[\ns_{qj} = m_j \\exp \\left( -c d_{qj} \\right)\n\\]\nStronger traces have their similarity multiplied by a large value (\\(m_j\\) is large if trace \\(j\\) is strong) while weaker traces have their similarity multiplied by a small value (\\(m_j\\) is small if trace \\(j\\) is weak). This is illustrated in the pair of graphs below. A probe item does not need to be as similar to a strong item in order to evoke the same level of perceived similarity.\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n9.1.2.2 Trace specificity\nThe specificity parameter \\(c\\) represents the fact that items are assumed to be encoded with some degree of error/uncertainty. Just as items may be encoded with more or less strength, it is reasonable to assume that items can be encoded in memory with more or less specificity. Thus, we add a subscript to the \\(c\\) parameter corresponding to each study item: \\[\ns_{qj} = m_j \\exp \\left( -c_j d_{qj} \\right)\n\\]\nIf an item is encoded with high specificity, then it will only be perceived as similar to the probe if the probe is very close in psychological space. This is illustrated in the pair of graphs below, where item 2 is not only stronger (\\(m_2 = 2\\) vs. \\(m_1 = 1\\)) but also more precise (\\(c_2 = 0.1\\) vs. \\(c_1 = 0.05\\)).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nspecificity &lt;- c(0.05, 0.1)\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-specificity[item] * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "href": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.2 Making a recognition decision: From random walk to diffusion",
    "text": "9.2 Making a recognition decision: From random walk to diffusion\nAccording to the EBRW, each trace \\(j\\) in memory races to be retrieved at a rate proportional to its perceived similarity to the probe item, \\(s_{qj}\\). Traces race not just against one another, but against a criterion. If a memory trace wins the race, this is taken as evidence that the probe item matches something in memory, thus favoring a “yes” recognition response. If the criterion wins the race instead, this is taken as evidence that the probe item does not match anything in memory, thus favoring a “no” recognition response.\nThe idea is that, if the probe item matches something in memory, then the corresponding memory trace (or one sufficiently similar to probably match) should be able to win against the criterion. If nothing wins against the criterion, then this suggests there are no traces in memory that are a good match to the probe.\n\n9.2.1 Accumulating memory evidence\nThe outcome of each race is added to a running tally which starts at zero. The value of the tally at any given time \\(t\\), which we can denote \\(x(t)\\), constitutes the current state of evidence from memory for making a recognition decision. Assume that each race takes \\(\\Delta t\\) seconds to complete. Each time a memory trace wins the race, the tally gets incremented by one; each time the criterion wins the race, the tally gets decremented by one. Put formally, we can write this process as \\[\nx\\left( t + \\Delta t \\right) =\n\\begin{cases}\nx\\left( t \\right) + 1 & \\text{if trace wins} \\\\\nx\\left( t \\right) - 1 & \\text{if criterion wins}\n\\end{cases}\n\\] where \\(x(0) = 0\\).\n\n\n9.2.2 Step probabilities\nAlthough we have specified that whether memory evidence goes up or down depends on whether a trace or the criterion wins the race, we have not yet specified how the outcome of that race is determined. The winner of each race is random but depends on the similarity \\(s_{qj}\\) between each trace \\(j\\) and the probe \\(q\\). Specifically, trace \\(j\\) wins the race with probability: \\[\n\\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa}\n\\] where \\(\\kappa\\) is a nonnegative number that represents how stringent the criterion is. In other words, the equation above says that the probability that trace \\(j\\) wins the race is the similarity between trace \\(j\\) and the probe \\(q\\) divided by the summed similarity across all traces plus the criterion \\(\\kappa\\). In a sense, we can think of the criterion is like a “virtual memory trace” that races alongside the \\(N\\) actual memory traces.\nRemember that we increment memory strength whenever any trace wins the race, regardless of which one it is. Because only one trace can win each race, the probability that any trace wins is just the sum of the probabilities of winning across all \\(N\\) traces, i.e.: \\[\np = \\sum_{j = 1}^N \\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa} = \\frac{1}{\\sum_{k = 1}^N s_{qk} + \\kappa} \\left( \\sum_{j = 1}^Ns_{qj} \\right) = \\frac{S}{S + \\kappa}\n\\] where \\(S = \\sum_{j = 1}^N s_{qj}\\) is the summed similarity across all \\(N\\) traces. The quantity \\(p\\) is the probability that the random walk takes a step up.\nThe EBRW models the speed of decision making in terms of how many races must be run until the accumulated win advantage in favor of either a “yes” or “no” response reaches a decision boundary. To convert this to “real time”, we must say how long each race takes and allow for a residual time. Above, we used \\(\\Delta t\\) to stand for the amount of time (in seconds) each race takes to run. It will be convenient later to think instead of \\(\\nu = \\frac{1}{\\Delta t}\\), where \\(\\nu\\) is the number of races per second.\nThe figure below shows an example of how memory evidence evolves during a single trial in which \\(p = 0.55\\), \\(\\nu = 40\\), \\(B_{Upper} = 7\\), \\(B_{Lower} = -8\\), and \\(t_0 = 0.2\\). In addition, the graphs above and below the evidence trajectory illustrate the relative frequency with which, across many identical trials, each type of response would be made at each unit of time. Note that these distributions are discrete because the random walk operates in discrete time intervals, each of duration \\(\\Delta t\\) (which in this example is \\(\\Delta t = \\frac{1}{\\nu} = 0.025\\) seconds).\n\n\nCode\nset.seed(1)\n\nnu &lt;- 40\np &lt;- 0.55\n\nB &lt;- c(-8, 7)\nresid &lt;- 0.2\n\n### RT distributions\n\nY_rw &lt;- seq(B[1], B[2])\nP_rw &lt;- matrix(0, nrow = length(Y_rw), ncol = length(Y_rw))\nP_rw[cbind(2:(nrow(P_rw) - 1), 1:(ncol(P_rw) - 2))] &lt;- 1 - p\nP_rw[cbind(2:(nrow(P_rw) - 1), 3:ncol(P_rw))] &lt;- p\nP_rw[1, 1] &lt;- P_rw[nrow(P_rw), ncol(P_rw)] &lt;- 1\n\n### Simulation\n\nwhile (TRUE) {\n    winner &lt;- 0\n    x_rw &lt;- 0\n\n    while (TRUE) {\n        s &lt;- 2 * (runif(n = 1) &lt; p) - 1\n        x_rw &lt;- c(x_rw, x_rw[length(x_rw)] + s)\n        if (x_rw[length(x_rw)] &lt;= B[1]) {\n            winner &lt;- 1\n            break\n        } else if (x_rw[length(x_rw)] &gt;= B[2]) {\n            winner &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == 2 & (length(x_rw) / nu) &gt; 1.5) {\n        break\n    }\n}\n\nRT_rw &lt;- matrix(0, nrow = 2, ncol = length(x_rw))\nZ_rw &lt;- 1 * c(Y_rw == 0)\n\nfor (i in 1:length(x_rw)) {\n    Z_rw &lt;- Z_rw %*% P_rw\n    RT_rw[1, i] &lt;- Z_rw[1]\n    RT_rw[2, i] &lt;- Z_rw[length(Z_rw)]\n}\n\ndRT_rw &lt;- apply(RT_rw, MARGIN = 1, FUN = diff) * nu / 2\n\nrtPlot1 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#eeb211\", color = NA, width = 1 / nu) +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_rw)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#46166b\", color = NA, width = 1 / nu) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_rw)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + 1:length(x_rw) / nu, x = x_rw) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step(linewidth = 1.5) +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))\n\n\n\n\n\n\n\n\n\n\n\n9.2.3 From discrete random walk to continuous diffusion\nA random walk takes discrete-valued steps either up or down in discrete units of time. A Wiener diffusion process takes continuous-valued steps sampled from a normal distribution in infinitely small units of time, thus effectively operating in continuous time. We are going to approximate the discrete EBRW with a continuous diffusion process (so technically we should call this model the EBD for Exemplar-Based Diffusion, but we will keep calling it the EBRW for posterity).\nIn going from a random walk to a diffusion model, we are making an important psychological claim: We are saying that, instead of memory evidence arriving in discrete units at regular intervals, memory evidence is a continuous value that continually evolves as new information arrives. We can think of this as saying that, instead of only knowing the outcome of each race, you can see who is ahead and who is behind at any given time; this is the move from discrete time to continuous time. Moreover, instead of only scoring each race as a win or loss for the memory traces, the races are assigned a continuous value depending on how clear the winner is; this is the move from discrete evidence to continuous evidence.\n\n9.2.3.1 Mean and standard deviation of diffusion\nWe can write the update equation for the random walk like we did above: \\[\n\\begin{align}\nx \\left( t + \\Delta t \\right) & = \\begin{cases} x(t) + 1 & \\text{with probability } p \\\\ x(t) - 1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & = \\begin{cases} 1 & \\text{with probability } p \\\\ -1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & \\sim 2 \\times \\text{Bernoulli} \\left( p \\right) - 1\n\\end{align}\n\\] where we have rearranged terms and used the shorthand in the final line to emphasize the idea that each step of the random walk can be thought of as a sample from a Bernoulli distribution with parameter \\(p\\) that is then transformed from \\(\\lbrace 0, 1 \\rbrace\\) to \\(\\lbrace -1, 1 \\rbrace\\).\nTo turn this into a continuous diffusion process, we need to swap out the transformed Bernoulli distribution with a normal distribution that has the same mean and variance. The mean is \\(2 p - 1\\) and the variance is \\(4 p \\left(1 - p \\right)\\). One more thing: remember that we run \\(\\nu\\) races per second, so we need to multiply the mean and variance by \\(\\nu\\). Therefore, the mean drift rate is \\(v = \\nu \\left(2 p - 1 \\right)\\) and the variance is \\(\\sigma^2 = 4 \\nu p (1 - p)\\).\nNote that this is different from the typical diffusion model where the variance of the evidence samples is arbitrarily fixed to 1. Notice an important property of this variance: It is largest when \\(p = 0.5\\) and approaches zero as \\(p\\) approaches either 0 or 1. In other words, the more uncertain the outcome of each race, the more noise there is in the diffusion. This is illustrated below:\n\n\nCode\nexpand_grid(p = seq(0, 1, length.out = 101), nu = seq(10, 40, by = 10)) %&gt;%\n    mutate(sigma2 = 4 * nu * p * (1 - p)) %&gt;%\n    ggplot(aes(x = p, y = sigma2, color = nu, group = nu)) +\n    geom_line() +\n    labs(x = p, y = expression(sigma^2), color = expression(nu)) +\n    theme(legend.position = c(1, 1), legend.justification = c(1, 1))\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\nTo summarize, the difference between the random walk and the diffusion is that we have swapped out a discrete binomial distribution of evidence increments per unit time with a continuous normal distribution of evidence increments per unit time. Everything else is the same: You still respond “yes” if and when the accumulated evidence \\(x(t)\\) reaches either the upper boundary or the lower boundary.\n\n\n9.2.3.2 Closeness of predictions\nTo illustrate how well the diffusion process approximates the random walk, the graphs below show the diffusion approximation to the same random walk example used above. The smooth lines in the upper and lower graphs are the probability of responding per unit time (i.e., the probability density function) according to the Wiener diffusion model. The open bars are the same probabilities from the random walk. The diffusion model’s predictions hew very closely to those of the random walk!\n\n\nCode\nmu &lt;- nu * (2 * p - 1)\nsigma2 &lt;- 4 * nu * p * (1 - p)\nboundsep &lt;- B[2] - B[1]\nbias &lt;- (0 - B[1]) / (B[2] - B[1])\ndelta_t &lt;- 0.001\n\nwhile (TRUE) {\n    winner_diff &lt;- NA\n    x_diff &lt;- 0\n    \n    while (TRUE) {\n        x_diff &lt;- c(x_diff, x_diff[length(x_diff)] + rnorm(n = 1, mean = mu * delta_t, sd = sqrt(sigma2 * delta_t)))\n        if (x_diff[length(x_diff)] &lt;= B[1]) {\n            winner_diff &lt;- 1\n            break\n        } else if (x_diff[length(x_diff)] &gt;= B[2]) {\n            winner_diff &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == winner_diff & abs((length(x_diff) * delta_t) - (length(x_rw) / nu)) &lt; (1 / nu)) {\n        break\n    }\n}\n\nx_diff &lt;- pmax(pmin(x_diff, B[2]), B[1])\n\nt &lt;- seq(1, length(x_diff)) * delta_t\n\ndRT_diff &lt;- cbind(\n    WienerPDF(t = t, response = \"lower\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value,\n    WienerPDF(t = t, response = \"upper\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value\n)\n\nrtPlot1 &lt;- tibble(t = resid + t, p = dRT_diff[,2]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])), color = \"#eeb211aa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#eeb21177\", color = \"#eeb211\") +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_diff)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + t, p = dRT_diff[,1]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])), color = \"#46166baa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#46166b77\", color = \"#46166b\") +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_diff)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + t, x = x_diff) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_line() +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu), v == .(signif(mu, 3)), sigma == .(signif(sqrt(sigma2), 3)))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#implementation-in-r",
    "href": "ebrw.html#implementation-in-r",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.3 Implementation in R",
    "text": "9.3 Implementation in R\nTo find the EBRW parameters that best fit the recognition data from a participant, let’s implement the diffusion version of the EBRW in R using the WienR package. We must define a function to compute the negative log-likelihood (NLL) for a set of observed responses/RT’s, given a set of parameters. The function itself, in outline form, looks like the one below. I have written comments for the things that the function needs to accomplish to get from what is given to the function (in the parentheses following function) to what the function needs to return at the end.\nFor example purposes, this implementation doesn’t include all of the bells and whistles that the full model includes. It will not allow for varying trace strength nor will it include attention weights on each dimension. This is meant to illustrate the basic idea that we can define a diffusion model in which the drift rates are derived from a theory, rather than just estimated.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responded \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\nLet’s now fill in each of those sections in turn.\n\n9.3.1 Parameters\nThe vector par that is the first argument to the ebrw_nll function should be a named vector that has the following entries:\n\n\nCode\npar &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\n\n\n9.3.2 Computing the mean and SD of the drift for each trial\nRecall that the drift rates depend on the distances between each of the stimulus items. Since the function is provided with stim_coords, we can make our job a little easier by using the dist function to compute the matrix of distances between all pairs of items. This saves us from “recomputing” the distances between pairs of items that occur on multiple trials:\n\n\nCode\nstim_dists &lt;- as.matrix(dist(stim_coords))\n\n\nThen, to compute the summed similarity for each trial i, we can use a for loop:\n\n\nCode\nevidence_mean &lt;- rep(0, length(probe_item))\nevidence_sd &lt;- rep(0, length(probe_item))\n\nfor (i in 1:length(probe_item)) {\n    summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n    p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n    \n    evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n    evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n}\n\n\nWe have now completed the second step of writing the ebrw_nll function, as summarized below.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\n\n\n9.3.3 Calculating the log-likelihood\nThis step is almost too easy. We are using the WienR package, which means we can use the WienerPDF function like we’ve seen already. There is only one thing we need to do: The WienerPDF function assumes that the standard deviation of the diffusion is always equal to one. As such, we need to standardize the drift rate and boundary separation before we send them to the WienerPDF function by dividing each by evidence_sd:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    )\n    \n    # 3. Return final result\n    return(-sum(result$logvalue))\n}\n\n\n\n\n9.3.4 Error-checking\nIt is important for us to do some error checking. Sometimes, a particular combination of parameters will make it impossible for the WienerPDF function to calculate the log-likelihood. When that happens, it gives an error. In essence, such a result tells us that the model cannot work with that combination of parameters. Thus, rather than an “error”, that is really telling us that we should assign zero likelihood to that set of parameters, which is equivalent to a log-likelihood of \\(-\\infty\\).\nWe can do that kind of check in R by putting the WienerPDF function call within try(). If the WienerPDF function gives an error, then the result that gets stored in trial_wiener is also an error. Otherwise, it just gives us the log-likelihoods that we want.\nLet’s set up an “if…else” structure to do this check:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- try(WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    ))\n    \n    # 3. Return final result\n    if (class(result) == \"try-error\") {\n        return(Inf)\n    } else {\n        return(-sum(result$logvalue))\n    }\n}",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#a-worked-example",
    "href": "ebrw.html#a-worked-example",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.4 A worked example",
    "text": "9.4 A worked example\nThis example uses a single participant’s data from Experiment 2 of Gillespie & Cox (2024). In this experiment, each participant made similarity ratings between all pairs of eight items. Each item was an “auditory texture” constructed via Fourier synthesis. We applied Multidimensional Scaling to the similarity ratings from each participant to assign, for each participant, a set of coordinates to each item. The coordinates are such that items that are farther from one another were associated with lower similarity ratings and those that were closer to one another were assigned higher similarity ratings. Be sure to check out the paper itself for additional detail on how this was done, and how we decided that the multidimensional space in which the stimuli are represented had 3 dimensions. These coordinates will be used for the stim_coords argument of the ebrw_nll function.\nIn addition to providing similarity ratings, each participant engaged in a recognition memory task. On each trial of this task, the participant heard two auditory textures, presented sequentially. They then heard a “probe” sound and had to decide whether or not it was one of the two sounds that had just been presented. It is these recognition data that we will model with the EBRW.\nYou can grab the data yourself by running the following chunk of code to download it and load it into your R workspace:\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/ebrw_example_data.rdata\", \"blast_data.rdata\")\nload(\"ebrw_example_data.rdata\")\n\n\n\n9.4.1 Check out the data\nThe stimulus coordinates are saved in a matrix called stim_coords:\n\n\nCode\nprint(stim_coords)\n\n\n           [,1]         [,2]        [,3]\n[1,] -0.4679162 -0.463219039 -0.08056499\n[2,] -0.5549266  0.499390636  0.07099460\n[3,] -0.4742833 -0.132020672  0.43312165\n[4,] -0.5062581  0.005578674 -0.40175331\n[5,]  0.5110397 -0.222844222 -0.30381582\n[6,]  0.4578305  0.336495895 -0.27302187\n[7,]  0.5669455 -0.288366241  0.24624698\n[8,]  0.4675684  0.264984969  0.30879277\n\n\nWe can visualize them using plot_ly:\n\n\nCode\nto_plot &lt;- as.data.frame(stim_coords)\ncolnames(to_plot) &lt;- paste(\"Dimension\", 1:ncol(stim_coords))\nrownames(to_plot) &lt;- paste(\"Item\", 1:nrow(stim_coords))\n\nplot_ly(\n    data = to_plot,\n    x = ~ `Dimension 1`,\n    y = ~ `Dimension 2`,\n    z = ~ `Dimension 3`,\n    type = \"scatter3d\",\n    text = rownames(to_plot),\n    mode = \"markers+text\"\n)\n\n\n\n\n\n\nIn addition for each trial of the recognition task, the study_items matrix tells us which of the two items had been presented as part of the set to be remembered and the probe_item vector tells us what the probe item was. These numbers refer to row in the stim_coords matrix.\n\n\nCode\nprint(study_items)\n\n\n      [,1] [,2]\n [1,]    3    5\n [2,]    3    6\n [3,]    8    1\n [4,]    1    7\n [5,]    2    4\n [6,]    7    2\n [7,]    6    7\n [8,]    8    3\n [9,]    3    4\n[10,]    5    6\n[11,]    6    8\n[12,]    1    4\n[13,]    4    8\n[14,]    7    4\n[15,]    6    1\n[16,]    1    3\n[17,]    1    2\n[18,]    3    2\n[19,]    6    4\n[20,]    8    2\n[21,]    3    7\n[22,]    4    5\n[23,]    5    2\n[24,]    1    5\n[25,]    7    8\n[26,]    2    6\n[27,]    7    5\n[28,]    5    8\n\n\nCode\nprint(probe_item)\n\n\n [1] 4 2 1 7 2 7 7 2 6 6 6 1 3 4 4 3 8 3 8 4 7 8 4 2 6 2 3 5\n\n\nFinally, the rt and response vectors record the response time (in seconds) and the response (where 2 is “yes” and 1 is “no”) produced by this participant on each trial.\n\n\n9.4.2 Finding optimal parameters\nThe version of the EBRW that we applied in our paper is a bit more complex than the one we will use here, which only has six free parameters. We will use R’s built-in nlminb function to find the best-fitting values of these parameters. To do this, we need to specify initial values for each parameter in a named vector, as shown below. These initial values don’t necessarily need to be anything in particular as long as they don’t cause the ebrw_nll function to return an error or a value of Inf.\n\n\nCode\ninit_par &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\nWe also need to specify the upper and lower values that each of these parameters could possibly take, as shown below:\n\n\nCode\nlower &lt;- c(\n    \"retrieval_rate\" = 0,     # This is the \"nu\" parameter\n    \"a\" = 0,                  # Response caution\n    \"w\" = 0,                  # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 0,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 0           # Criterion (the \"kappa\" parameter)\n)\n\nupper &lt;- c(\n    \"retrieval_rate\" = Inf,     # This is the \"nu\" parameter\n    \"a\" = Inf,                  # Response caution\n    \"w\" = 1,                    # Response bias\n    \"t0\" = min(rt),             # Residual time\n    \"specificity\" = Inf,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = Inf           # Criterion (the \"kappa\" parameter)\n)\n\n\nNote that these upper and lower values can be Infinite if necessary!\nFinally, let’s use the nlminb function, which we need to provide with each of the ingredients we prepared above. We will save the result as fit:\n\n\nCode\nfit &lt;- nlminb(\n    start = init_par,          # Need to provide initial guess of parameter values\n    objective = ebrw_nll,      # Tell R the name of the function to optimize\n    lower = lower,             # The lower bounds on each parameter\n    upper = upper,             # The upper bounds on each parameter\n    stim_coords = stim_coords, # The coordinates of each stimulus\n    rt = rt,                   # The vector of RT's on each trial\n    response = response,       # The vector of responses on each trial\n    study_items = study_items, # The study items on each trial\n    probe_item = probe_item    # The probe item on each trial\n)\n\n\nWarning in nlminb(start = init_par, objective = ebrw_nll, lower = lower, :\nNA/NaN function evaluation\n\n\nAnd the final result!\n\n\nCode\nfit\n\n\n$par\nretrieval_rate              a              w             t0    specificity \n     1.2474191      2.1459586      0.4488126      0.6884095      5.6470633 \n     criterion \n     0.1035233 \n\n$objective\n[1] 21.59716\n\n$convergence\n[1] 0\n\n$iterations\n[1] 35\n\n$evaluations\nfunction gradient \n      56      243 \n\n$message\n[1] \"relative convergence (4)\"\n\n\nIt may seem like a lot of work for such a simple result—six numbers! But it helps to take a step back and realize what we have just done. We had a participant provide similarity ratings for pairs of unusual auditory stimuli that they had never heard before. We found a way to represent how that participant perceives those stimuli in terms of coordinates in a multidimensional space. We could then infer, from their choices and response times in a recognition task, how well this participant could remember these stimuli and how they used perceived similarity to make their choices. We have explained why this participant did what they did not just in terms of accumulating evidence for a decision, but in terms of how they got that evidence from their memory for novel auditory stimuli.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#predictions-by-simulation-and-math",
    "href": "ebrw.html#predictions-by-simulation-and-math",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.5 Predictions by simulation and math",
    "text": "9.5 Predictions by simulation and math\nAs impressive as it is to have “reverse-engineered” the contents of a participant’s memory from their behavior, there are still some pieces we have left out of the puzzle. Specifically, although we developed a function to calculate the NLL for the purpose of estimating parameters, we haven’t yet built a function to simulate data using the EBRW. That is the purpose of this section. We will also see some explicit mathematical formulae for predicting average performance without the need to run many simulations. In the end, this will enable us to (a) verify the quality of our model fit by comparing its predictions to observations; and (b) make predictions for novel experimental conditions that we may not have observed.\nFinally, this section demonstrates a general technique that is often useful in programming a model: Having a single function that can return either the NLL or predictions. Since the model parameters have the same meaning regardless of whether we are calculating likelihoods or making predictions, we can just tell the function what we want it to do with those parameters. The value of this approach is that we won’t accidentally write simulation code that differs in some important way from our likelihood code. For example, if we change the parameters for our likelihood code, we want to make sure that our simulation code respects that change; the approach we take in this section forces us to do this and thereby keep our model consistent.\n\n9.5.1 Simulating individual trials\nFirst, we will see how we can modify our ebrw_nll function to return simulated behavior instead of just the negative log-likelihood of observed choices and RT’s. The chunk of code below gives an outline of our approach, which involves adding a new argument to the function called n_sims. By default, n_sims = 0, which indicates that the function should not do any simulation but should instead return the NLL, as it did above. As you might anticipate, we will need an if...else structure to check whether n_sims &gt; 0 or not.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\n# n_sims: this indicates whether or not simulations are meant to be returned instead of the NLL\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt, n_sims = 0) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    if (n_sims &gt; 0) {\n        # 2a. Simulate a response for each trial\n        \n        # SIMULATION CODE GOES HERE\n        \n        # 3a. Return final result\n        return(result)\n    } else {\n        # 2b. Calculate the log-likelihood of each observed response/RT on each trial\n        result &lt;- try(WienerPDF(\n            t = rt,\n            response = response,\n            a = par[\"a\"] / evidence_sd,\n            w = par[\"w\"],\n            v = evidence_mean / evidence_sd,\n            t0 = par[\"t0\"]\n        ))\n        \n        # 3b. Return final result\n        if (class(result) == \"try-error\") {\n            return(Inf)\n        } else {\n            return(-sum(result$logvalue))\n        }\n    }\n}\n\n\nIt is worth pointing out that, aside from the if...else structure, nothing else has changed about the function: Other than n_sims it takes exactly the same arguments, meaning it will still use the provided parameters to compute the drift rates for each trial of an experiment based on the similarity between the studied items and the probe.\nYou may wonder at this point why n_sims is a number—why didn’t we use a boolean like do_simulation which could be either TRUE or FALSE? This is because we may want to simulate multiple replications of a given trial. For example, we may want to simulate an experiment in which the same study/test items are repeated. Alternatively, we may want to use a large number of simulations so that we can estimate the entire distribution of possible responses and response times that a participant might produce on a given trial. In any case, by allowing n_sims to be a number rather than just TRUE or FALSE, we are making our function more flexible—something for which our future selves will thank our current selves.\nBack to the business at hand, we need to fill in the blank where it says SIMULATION CODE HERE. Recall that we are using the WienR package, which includes a sampWiener function for simulating choices and RT’s. We used this to build our diffusion simulation code and we can use it again here. The only challenge is that, unlike WienerPDF, sampWiener can only take a single value for the diffusion model parameters (e.g., a, v, w, etc.) at a time. So we will use a for loop to simulate behavior on each individual trial, as shown in the code below (as usual, there are alternative approaches that are more efficient than a for loop, but our aim at the moment is for transparency):\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\n# n_sims: this indicates whether or not simulations are meant to be returned instead of the NLL\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt, n_sims = 0) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    if (n_sims &gt; 0) {\n        # 2a. Simulate a response for each trial\n        result &lt;- c()\n        \n        # For each trial...\n        for (i in 1:length(probe_item)) {\n            # Simulate `n_sims` replications of this trial, using its corresponding parameters\n            trial_sim &lt;- sampWiener(\n                N = n_sims,\n                a = par[\"a\"] / evidence_sd[i],\n                w = par[\"w\"],\n                v = evidence_mean[i] / evidence_sd[i],\n                t0 = par[\"t0\"]\n            )\n            \n            # Append the new set of simulations to our `result`, including an indicator of which trial we are simulating and an index for each simulation\n            result &lt;- rbind(\n                result,\n                tibble(trial = i, sim_index = 1:n_sims, rt = trial_sim$q, response = trial_sim$response)\n            )\n        }\n        \n        # 3a. Return final result\n        return(result)\n    } else {\n        # 2b. Calculate the log-likelihood of each observed response/RT on each trial\n        result &lt;- try(WienerPDF(\n            t = rt,\n            response = response,\n            a = par[\"a\"] / evidence_sd,\n            w = par[\"w\"],\n            v = evidence_mean / evidence_sd,\n            t0 = par[\"t0\"]\n        ))\n        \n        # 3b. Return final result\n        if (class(result) == \"try-error\") {\n            return(Inf)\n        } else {\n            return(-sum(result$logvalue))\n        }\n    }\n}\n\n\nThe code above uses our old trick of creating an “empty” tibble (results &lt;- c()) and then appending each new set of simulations to the results tibble before returning it. Let’s take the new code out for a spin!\nFirst, let’s see how easy it is to simulate data that comes from exactly the same trials that our participant experienced:\n\n\nCode\nsim_trials &lt;- ebrw_nll(\n    par = fit$par,\n    stim_coords = stim_coords,\n    study_items = study_items,\n    probe_item = probe_item,\n    n_sims = 1\n)\n\nprint(sim_trials)\n\n\n# A tibble: 28 × 4\n   trial sim_index    rt response\n   &lt;int&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1     1         1 1.11  lower   \n 2     2         1 2.88  lower   \n 3     3         1 1.71  upper   \n 4     4         1 2.42  upper   \n 5     5         1 2.48  upper   \n 6     6         1 1.41  upper   \n 7     7         1 0.979 upper   \n 8     8         1 0.824 lower   \n 9     9         1 1.50  lower   \n10    10         1 1.26  upper   \n# ℹ 18 more rows\n\n\nNotice that for the par argument, we used the fitted parameter values we found earlier, which are in fit$par. We also used the exact same stim_coords, study_items, and probe_item arguments as we used when fitting this participant’s data. So essentially what we just did is simulate an imaginary but plausible dataset that this participant could have produced, assuming that the EBRW is a good model of their performance.\nWhile simulating a single dataset has its value—like with the parameter recovery exercises we did with diffusion models—we might be more interested in the distribution of responses and response times that this participant might produce. This is one reason why it is handy to be able to set n_sims to a large value, as in the chunk of code below. We can then estimate, for example, the probability of making a “yes” response in a particular trial, or the mean correct response time. That said, the next section will show us how we can obtain predictions for response probabilities and mean RT’s mathematically. However, mathematical formulae won’t always be available, so we will often fall back on simulations.\n\n\nCode\n# Simulate many trials\nsim_trials &lt;- ebrw_nll(\n    par = fit$par,\n    stim_coords = stim_coords,\n    study_items = study_items,\n    probe_item = probe_item,\n    n_sims = 1000\n)\n\n# Obtain mean predictions for each trial\nsim_means &lt;- sim_trials %&gt;%\n    group_by(trial) %&gt;%\n    summarize(\n        sim_p_upper = mean(response == \"upper\"),\n        sim_mean_rt_yes = mean(rt[response == \"upper\"]),\n        sim_mean_rt_no = mean(rt[response == \"lower\"])\n    )\n\nprint(sim_means)\n\n\n# A tibble: 28 × 4\n   trial sim_p_upper sim_mean_rt_yes sim_mean_rt_no\n   &lt;int&gt;       &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n 1     1       0.001            1.37           1.63\n 2     2       0.041            1.95           1.72\n 3     3       0.991            1.86           1.38\n 4     4       0.986            1.84           1.57\n 5     5       0.989            1.87           2.00\n 6     6       0.994            1.88           1.97\n 7     7       0.993            1.81           1.44\n 8     8       0.028            1.94           1.72\n 9     9       0              NaN              1.52\n10    10       0.988            1.81           1.77\n# ℹ 18 more rows\n\n\nYou may already notice one issue with using simulation to obtain average model predictions. According to the fitted model, there is almost no chance that this participant gives a “yes” response on trial 9. Even in 1000 simulations, the model never produced a “yes” response on that trial. As a result, we would need to simulate many trials before we got a stable estimate of the mean RT for a “yes” response on the trial (though, given how unlikely it is, maybe we wouldn’t be too interested in that prediction anyway).\nOut of curiousity, let’s see what the study items and probe were for trial 9:\n\n\nCode\nstudy_items[9,]\n\n\n[1] 3 4\n\n\nCode\nprobe_item[9]\n\n\n[1] 6\n\n\nIf you refer back to the MDS plot above, we see that items 3 and 4 (the studied items on trial 9) both fall on one end of “Dimension 1” whereas item 6 (the probe item) falls on the other side. In other words, the probe is pretty far from both studied items, so it makes sense that the EBRW would predict a very low probability that this participant incorrectly says “yes” on that trial.\n\n\n9.5.2 Mathematical expressions for response probability and mean RT’s\nMany cognitive models are sufficiently complex that there aren’t mathematical expressions for their predictions. However, the Wiener diffusion model (i.e., without any extra trial-by-trial variability) actually has mathematical expressions for the mean response probability and mean response times (for each response). These formulae aren’t exactly pretty, but they only involve elementary functions that are built into R, so we can translate them into code.\n\\[\\begin{align}\n\\hat{p}_i & = \\frac{1 - \\exp \\left( -\\frac{2 a v_i w}{s_i^2} \\right)}{1 - \\exp\\left(-\\frac{2 a v_i}{s_i^2} \\right)} \\\\\n\\widehat{RT}_{Y,i} & = t_0 + \\frac{a}{v_i} \\left[ \\frac{1}{\\tanh \\left( \\frac{a v_i}{s_i^2} \\right)} - \\frac{w}{\\tanh \\left( \\frac{a v_i w}{s_i^2} \\right)} \\right] \\\\\n\\widehat{RT}_{N,i} & = t_0 + \\frac{a}{v_i} \\left[ \\frac{1}{\\tanh \\left( \\frac{a v_i}{s_i^2} \\right)} - \\frac{1 - w}{\\tanh \\left( \\frac{a v_i \\left(1 - w \\right)}{s_i^2} \\right)} \\right]\n\\end{align}\\]\nIt may help to keep in mind the following “Rosetta stone” that relates the mathematical notation to things that we recognize from our code:\n\n\\(\\hat{p}_i\\): Probability of giving a “yes” response on trial \\(i\\).\n\\(\\widehat{RT}_{Y,i}\\): Mean RT for “yes” responses on trial \\(i\\).\n\\(\\widehat{RT}_{N,i}\\): Mean RT for “no” responses on trial \\(i\\).\n\\(a\\): Boundary separation, par[\"a\"].\n\\(w\\): Response bias, par[\"w\"].\n\\(t_0\\): Residual time, par[\"t0\"].\n\\(v_i\\): Mean drift rate on trial \\(i\\), evidence_mean[i].\n\\(s_i\\): Standard deviation of drift on trial \\(i\\), evidence_sd[i].\n\nFinally, \\(\\tanh\\) is the hyperbolic tangent function, which is built into R as tanh(). This function is defined by \\[\n\\tanh \\left(x \\right) = \\frac{\\exp \\left( x \\right) - \\exp \\left(-x \\right)}{\\exp \\left( x \\right) + \\exp \\left(-x \\right)}\n\\] and it looks like this:\n\n\nCode\ntibble(x = seq(-3, 3, length.out = 201)) %&gt;%\n    mutate(y = tanh(x)) %&gt;%\n    ggplot(aes(x = x, y = y)) +\n    geom_line() +\n    labs(x = \"x\", y = \"tanh(x)\")\n\n\n\n\n\n\n\n\n\nArmed with these mathematical expressions, we can readily translate them into R code. We’ll first do that and then see how we can insert that code into our ebrw_nll function. In the following, we are again using a for loop over each trial, using i as the index for the trial. Like we did with the simulations, we will first create an empty result and then append the predicted response probabilities and mean RT’s for each trial. Also, since the term \\(s_i^2\\) appears many times across all three formulae, we will want to compute it once and then refer back to it again later. The result is stored as the vector evidence_var.\n\n\nCode\nresult &lt;- c()\n\n# For convenience, we compute this first so we can refer to it each time we need it later\nevidence_var &lt;- evidence_sd^2\n\nfor (i in 1:length(probe_item)) {\n    trial_p_yes &lt;- (1 - exp(-2 * par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i])) / (1 - exp(-2 * par[\"a\"] * evidence_mean[i] / evidence_var[i]))\n    trial_mean_rt_yes &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - par[\"w\"] / tanh(par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i]))\n    trial_mean_rt_no &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - (1 - par[\"w\"]) / tanh(par[\"a\"] * evidence_mean[i] * (1 - par[\"w\"]) / evidence_var[i]))\n    \n    result &lt;- rbind(\n        result,\n        tibble(trial = i, p_yes = trial_p_yes, mean_rt_yes = trial_mean_rt_yes, mean_rt_no = trial_mean_rt_no)\n    )\n}\n\n\nNow we just need to figure out how to get the chunk of code above into our ebrw_nll function. There are a number of reasonable ways to do this. For example, we could add a new argument called something like return_math_pred which we could set to be TRUE or FALSE depending on whether we wanted the mathematically-computed mean predictions. However, since we already have the n_sims argument we added earlier, we can do something a bit clever. Since the mean predictions are based on what we would observe over an infinite number of simulations, we can allow a user to set n_sims = Inf, where Inf is R’s special shorthand for “infinity”. R uses the is.infinite function to check whether a number is infinite or not.\nAs such, in the code below, we “daisy-chain” the if...else construction we built in the previous section. We first check if (is.infinite(n_sims)) and, if so, run the chunk of code above. We then check for else if (n_sims &gt; 0) and, if so, run the specified but finite number of simulations per trial. Finally, the else statement computes the negative log-likelihoods.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\n# n_sims: this indicates whether or not simulations are meant to be returned instead of the NLL\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt, n_sims = 0) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    if (is.infinite(n_sims)) {\n        # 2a. Compute predicted response probabilities and mean RT's for each trial\n        result &lt;- c()\n        \n        evidence_var &lt;- evidence_sd^2\n        \n        for (i in 1:length(probe_item)) {\n            trial_p_yes &lt;- (1 - exp(-2 * par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i])) / (1 - exp(-2 * par[\"a\"] * evidence_mean[i] / evidence_var[i]))\n            trial_mean_rt_yes &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - par[\"w\"] / tanh(par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i]))\n            trial_mean_rt_no &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - (1 - par[\"w\"]) / tanh(par[\"a\"] * evidence_mean[i] * (1 - par[\"w\"]) / evidence_var[i]))\n            \n            result &lt;- rbind(\n                result,\n                tibble(trial = i, p_yes = trial_p_yes, mean_rt_yes = trial_mean_rt_yes, mean_rt_no = trial_mean_rt_no)\n            )\n        }\n        \n        # 3a. Return final result\n        return(result)\n    } else if (n_sims &gt; 0) {\n        # 2b. Simulate a response for each trial\n        result &lt;- c()\n        \n        # For each trial...\n        for (i in 1:length(probe_item)) {\n            # Simulate `n_sims` replications of this trial, using its corresponding parameters\n            trial_sim &lt;- sampWiener(\n                N = n_sims,\n                a = par[\"a\"] / evidence_sd[i],\n                w = par[\"w\"],\n                v = evidence_mean[i] / evidence_sd[i],\n                t0 = par[\"t0\"]\n            )\n            \n            # Append the new set of simulations to our `result`, including an indicator of which trial we are simulating and an index for each simulation\n            result &lt;- rbind(\n                result,\n                tibble(trial = i, sim_index = 1:n_sims, rt = trial_sim$q, response = trial_sim$response)\n            )\n        }\n        \n        # 3b. Return final result\n        return(result)\n    } else {\n        # 2c. Calculate the log-likelihood of each observed response/RT on each trial\n        result &lt;- try(WienerPDF(\n            t = rt,\n            response = response,\n            a = par[\"a\"] / evidence_sd,\n            w = par[\"w\"],\n            v = evidence_mean / evidence_sd,\n            t0 = par[\"t0\"]\n        ))\n        \n        # 3c. Return final result\n        if (class(result) == \"try-error\") {\n            return(Inf)\n        } else {\n            return(-sum(result$logvalue))\n        }\n    }\n}\n\n\nAgain, let’s see how this works. The code below computes the predicted mean response probabilities and RT’s for each trial:\n\n\nCode\nmath_pred &lt;- ebrw_nll(\n    par = fit$par,\n    stim_coords = stim_coords,\n    study_items = study_items,\n    probe_item = probe_item,\n    n_sims = Inf\n)\n\nmath_pred\n\n\n# A tibble: 28 × 4\n   trial       p_yes mean_rt_yes mean_rt_no\n   &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1     1 0.00420            1.84       1.64\n 2     2 0.0359             1.89       1.70\n 3     3 0.990              1.84       1.63\n 4     4 0.990              1.84       1.63\n 5     5 0.991              1.83       1.63\n 6     6 0.990              1.84       1.63\n 7     7 0.990              1.84       1.63\n 8     8 0.0364             1.89       1.70\n 9     9 0.000000120        1.71       1.52\n10    10 0.992              1.83       1.62\n# ℹ 18 more rows\n\n\nLet’s see how the mathematical predictions compare to those we derived from our 1000 simulations earlier, at least for the first few trials:\n\n\nCode\nknitr::kable(full_join(sim_means, math_pred, by = \"trial\")[1:12,], digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrial\nsim_p_upper\nsim_mean_rt_yes\nsim_mean_rt_no\np_yes\nmean_rt_yes\nmean_rt_no\n\n\n\n\n1\n0.001\n1.367\n1.629\n0.004\n1.842\n1.636\n\n\n2\n0.041\n1.948\n1.721\n0.036\n1.888\n1.695\n\n\n3\n0.991\n1.861\n1.384\n0.990\n1.836\n1.631\n\n\n4\n0.986\n1.839\n1.572\n0.990\n1.836\n1.630\n\n\n5\n0.989\n1.867\n2.003\n0.991\n1.833\n1.628\n\n\n6\n0.994\n1.875\n1.967\n0.990\n1.836\n1.631\n\n\n7\n0.993\n1.807\n1.444\n0.990\n1.835\n1.629\n\n\n8\n0.028\n1.938\n1.725\n0.036\n1.888\n1.695\n\n\n9\n0.000\nNaN\n1.521\n0.000\n1.710\n1.520\n\n\n10\n0.988\n1.807\n1.765\n0.992\n1.830\n1.625\n\n\n11\n0.989\n1.807\n1.597\n0.992\n1.831\n1.625\n\n\n12\n0.991\n1.809\n1.789\n0.992\n1.831\n1.625\n\n\n\n\n\nAs we can see, the simulated means tend to be close to the mathematical predictions, but can be off when it comes to predicting mean RT’s for rare responses, since those predictions are based on only a few simulated trials.\n\n\n9.5.3 Comparing predicted to observed\nAs noted above, being able to compute predictions from the EBRW is important to verify that it is doing a good job fitting the data. A common way to do this is to make a plot with observed values on the horizontal axis and predicted value on the vertical axis. To the extent that the points in the plot cluster around the diagonal, we have reason to believe that the model’s predictions are closely aligned with what was observed. Relatedly, we can report the \\(R^2\\) value, i.e., the proportion of variance explained by the model; this is just the square of the Pearson correlation coefficient.\nIn the present application, we have two observed values on each trial: the response and the RT. Thus, we’ll need to make two plots, one for each measure. But to do that, we’ll first need to get both the observed and predicted data into the same data structure. That’s what the chunk of code below does.\n\n\nCode\n# This tibble contains the observed data for each trial\nobs_data &lt;- tibble(\n    trial = 1:length(probe_item),\n    rt = rt,\n    response = response - 1 # The \"- 1\" is because \"response\" is coded as 2 (\"yes\") and 1 (\"no\"), but it'll be easier to instead code this as 1 (\"yes\") and 0 (\"no\").\n)\n\n# Since both the observed and predicted data contain a \"trial\" column, use that to join them together\nobs_pred &lt;- full_join(obs_data, math_pred, by = \"trial\")\n\n\nNow let’s try to naively plot the observed and predicted data against one another, as we just described. Note that this will not really work as intended!\n\n\nCode\nresp_plot &lt;- obs_pred %&gt;%\n    ggplot(aes(x = response, y = p_yes, color = factor(response))) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point() +\n    coord_equal() +\n    scale_color_manual(values = c(\"1\" = \"#377eb8\", \"0\" = \"#e41a1c\")) +\n    labs(x = \"Observed response\", y = \"Predicted P(\\\"Yes\\\")\", color = \"Response\")\n\nrt_plot &lt;- obs_pred %&gt;%\n    mutate(pred_rt = if_else(response == 1, mean_rt_yes, mean_rt_no)) %&gt;%\n    ggplot(aes(x = rt, y = pred_rt, color = factor(response))) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point() +\n    coord_equal() +\n    scale_color_manual(values = c(\"1\" = \"#377eb8\", \"0\" = \"#e41a1c\")) +\n    labs(x = \"Observed RT\", y = \"Predicted mean RT\", color = \"Response\")\n\nresp_plot + rt_plot + plot_layout(nrow = 1, guides = \"collect\")\n\n\n\n\n\n\n\n\n\nIn the plots above, each point represents a single trial. While we can see in the left plot (barely) that the model generally tends to predict a high probability of saying “yes” on trials where the participant actually said “yes”, it is much harder to see what is going on in the right plot that shows RT’s. The issue is that the model is making a prediction about the mean RT whereas each point represents a sample from the participant’s RT distribution.\nTherefore, a more informative way to judge whether the model is making sensible predictions is to compare its mean predictions against average observed performance. Since this is a recognition memory task, it makes the most sense to average performance depending on whether the probe item was a target (i.e., was one of the studied items) or a foil (i.e., was not one of the studied items). The code below first defines a new column in the obs_pred tibble that indicates the type of trial before aggregating both observed and predicted performance by probe type, then making plots similar to those above.\n\n\nCode\nobs_pred$probe_type &lt;- NA\n\nfor (i in 1:length(probe_item)) {\n    # Note the use of \"%in%\"\n    if (probe_item[i] %in% study_items[i,]) {\n        obs_pred$probe_type[i] &lt;- \"Target\"\n    } else {\n        obs_pred$probe_type[i] &lt;- \"Foil\"\n    }\n}\n\nobs_pred$probe_type &lt;- factor(obs_pred$probe_type, levels = c(\"Target\", \"Foil\"))\n\nresp_plot &lt;- obs_pred %&gt;%\n    group_by(probe_type) %&gt;%\n    summarize(mean_obs = mean(response), mean_pred = mean(p_yes)) %&gt;%\n    ggplot(aes(x = mean_obs, y = mean_pred, color = probe_type)) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point() +\n    coord_equal() +\n    scale_color_manual(values = c(\"Target\" = \"#377eb8\", \"Foil\" = \"#e41a1c\")) +\n    labs(x = \"Observed response proportion\", y = \"Predicted P(\\\"Yes\\\")\", color = NULL)\n\nrt_plot &lt;- obs_pred %&gt;%\n    mutate(pred_rt = if_else(response == 1, mean_rt_yes, mean_rt_no)) %&gt;%\n    group_by(probe_type) %&gt;%\n    summarize(mean_obs = mean(rt), mean_pred = mean(pred_rt)) %&gt;%\n    ggplot(aes(x = mean_obs, y = mean_pred, color = probe_type)) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n    geom_point() +\n    coord_equal() +\n    scale_color_manual(values = c(\"Target\" = \"#377eb8\", \"Foil\" = \"#e41a1c\")) +\n    labs(x = \"Observed mean RT\", y = \"Predicted mean RT\", color = NULL)\n\nresp_plot + rt_plot + plot_layout(nrow = 1, guides = \"collect\")\n\n\n\n\n\n\n\n\n\nThe above graphs are not only easier to see, they allow us to more fairly critique the model. The model does a great job predicting response probabilities as well as mean RT for targets. It looks like it predicts longer mean RT to foils than was observed, but that could also reflect sampling variability. In general, the plots above suggest that the model is generally good at fitting this participant’s data, though it may be missing something about the RT’s. That misfit in part justifies the more complex version of the EBRW that Gillespie & Cox (2024) fit to these data.\n\n\n9.5.4 Making novel predictions\nNow that we have the ability to quickly extract predictions from the EBRW, it is worth pointing out that we can now make predictions about how this participant would respond in a trial they did not experience, perhaps with a different set of study items or a different probe item.\nTo go even broader, we could imagine a new experiment in which the auditory stimuli were degraded by noise. In that case, we might expect the participant’s sensitivity parameter to be lower in that condition. We could simulate how this would affect their recognition performance with this stimuli (though it is likely that, in such an experiment, the participant would also adjust their response caution and response bias to compensate).\nThe point is that the EBRW permits us to make predictions regarding particular experimental manipulations, which can then help us design future experiments. This is because the EBRW’s predictions depend upon the specifics of how a participant represents the items in the experiment and contains parameters with meanings that are clearly linked to cognitive constructs like “sensitivity”. This was not necessarily the case with the “generic” decision models we explored earlier in the course.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#putting-it-all-together",
    "href": "ebrw.html#putting-it-all-together",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.6 Putting it all together",
    "text": "9.6 Putting it all together\nThe chunk of code below puts all our EBRW work in one place. There are blanks left in certain areas that could either be filled by observed results or by your own imagination. In addition, a complete script that simulates data using the EBRW, fits the EBRW to the simulated data, and compares the simulated to the fitted data is provided here.\n\n\nCode\n# This could be derived using MDS\nstim_coords &lt;- ...\n\n# These could be actual trials in an experiment or used to construct imaginary trials for simulation\nstudy_items &lt;- ...\nprobe_item &lt;- ...\n\n# These could be observed or simulated; they may not even be needed if you are just doing simulation\nresponse &lt;- ...\nrt &lt;- ...\n\n# This could be from a model fit or specified manually to do simulations\npar &lt;- ...\n\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\n# n_sims: this indicates whether or not simulations are meant to be returned instead of the NLL\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt, n_sims = 0) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    if (is.infinite(n_sims)) {\n        # 2a. Compute predicted response probabilities and mean RT's for each trial\n        result &lt;- c()\n        \n        evidence_var &lt;- evidence_sd^2\n        \n        for (i in 1:length(probe_item)) {\n            trial_p_yes &lt;- (1 - exp(-2 * par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i])) / (1 - exp(-2 * par[\"a\"] * evidence_mean[i] / evidence_var[i]))\n            trial_mean_rt_yes &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - par[\"w\"] / tanh(par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i]))\n            trial_mean_rt_no &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - (1 - par[\"w\"]) / tanh(par[\"a\"] * evidence_mean[i] * (1 - par[\"w\"]) / evidence_var[i]))\n            \n            result &lt;- rbind(\n                result,\n                tibble(trial = i, p_yes = trial_p_yes, mean_rt_yes = trial_mean_rt_yes, mean_rt_no = trial_mean_rt_no)\n            )\n        }\n        \n        # 3a. Return final result\n        return(result)\n    } else if (n_sims &gt; 0) {\n        # 2b. Simulate a response for each trial\n        result &lt;- c()\n        \n        # For each trial...\n        for (i in 1:length(probe_item)) {\n            # Simulate `n_sims` replications of this trial, using its corresponding parameters\n            trial_sim &lt;- sampWiener(\n                N = n_sims,\n                a = par[\"a\"] / evidence_sd[i],\n                w = par[\"w\"],\n                v = evidence_mean[i] / evidence_sd[i],\n                t0 = par[\"t0\"]\n            )\n            \n            # Append the new set of simulations to our `result`, including an indicator of which trial we are simulating and an index for each simulation\n            result &lt;- rbind(\n                result,\n                tibble(trial = i, sim_index = 1:n_sims, rt = trial_sim$q, response = trial_sim$response)\n            )\n        }\n        \n        # 3b. Return final result\n        return(result)\n    } else {\n        # 2c. Calculate the log-likelihood of each observed response/RT on each trial\n        result &lt;- try(WienerPDF(\n            t = rt,\n            response = response,\n            a = par[\"a\"] / evidence_sd,\n            w = par[\"w\"],\n            v = evidence_mean / evidence_sd,\n            t0 = par[\"t0\"]\n        ))\n        \n        # 3c. Return final result\n        if (class(result) == \"try-error\") {\n            return(Inf)\n        } else {\n            return(-sum(result$logvalue))\n        }\n    }\n}",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#exercises",
    "href": "ebrw.html#exercises",
    "title": "9  Exemplar of the Exemplar Based Random Walk",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises\n\nThis exercise makes use of the EBRW example script mentioned in the main text. It replicates the recognition memory task described in the chapter, assuming two items per study list followed by a single probe item. With this script, you can specify stim_coords and, by default, it will simulate one trial for each possible combination of study items and probe item (i.e., all possible 2-item lists, followed by all possible probe items). The script then fits the EBRW to the simulated data using exactly the same code as in the chapter. Finally, the script also produces plots of predicted vs. observed performance just like in the chapter.\n\nReplace the stim_coords matrix in the example file with one of your own devising. As a reminder, each row should correspond to a different item with each column giving its coordinate along the corresponding dimension. You might define your stim_coords based on pre-existing knowledge of psychologically-relevant stimulus dimensions (like with the color example at the beginning of the chapter). You could also find a matrix of coordinates obtained from a published scaling study, or one you carry out yourself. Finally, you could come up with stim_coords that represent a meaningful hypothesis about how some set of items is represented psychologically. In any case, provide your matrix and explain what the items are and what each dimension is.\nModify the simulation parameters in sim_par until the model’s simulated performance resembles what you would expect to see in a real experiment using your stimuli.\nDescribe an experimental manipulation that you expect would influence the EBRW’s sensitivity parameter. Simulate performance using a lower value of the sensitivity parameter than you used in part (b) and comment on how the model’s predicted performance is affected.\nFind values for the other parameters in the model (e.g., boundary separation, drift bias) that allow it to achieve the same speed and accuracy with lower sensitivity (part c) as it achieved with higher sensitivity (part d).\n\nYou may have noticed that our implementation of the EBRW assumes that each list of studied items is the same length. Describe how to modify our ebrw_nll function so that study_items can include NA values, thus allowing for lists to vary in length, similar to how we allowed our race model to be robust to sets of different size. Hint: All this involves is putting a na.rm = TRUE somewhere in our code!\nThis is a follow-up to the previous exercise. In applications of the EBRW to experiments that vary the number of items, it is typical to assume that the “criterion” varies linearly with list length (Nosofsky et al., 2011, 2014). Modify our ebrw_nll function to accommodate this version of the model. The chunk of code below gives a suggestion about how this might be done in such a way that preserves the functionality of the code we used throughout this chapter by keeping the “criterion” parameter and adding a “criterion_slope” parameter.\n\n\n\nCode\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt, n_sims = 0) {\n    ...\n    \n    if (is.na(par[\"criterion_slope\"])) {\n        criterion_slope &lt;- 0\n    } else {\n        criterion_slope &lt;- par[\"criterion_slope\"]\n    }\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        \n        # HINT: You will need to find the value of `list_length` on each trial---how will you do this?  (You might think about the fact that we are using `NA` values to indicate when `study_items[i,]` has fewer items than the number of columns in `study_items`).\n        this_criterion &lt;- par[\"criterion\"] + criterion_slope * list_length\n        \n        p &lt;- summed_sim / (summed_sim + this_criterion)\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    ...\n}\n\n\n\n\n\n\nGarner, W. R., & Felfoldy, G. L. (1970). Integrality of stimulus dimensions in various types of information processing. Cognitive Psychology, 1, 225–241.\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for novel auditory stimuli: Similarity, serial position, and list homogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models. Annual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An exemplar-familiarity model predicts short-term and long-term probe recognition across diverse forms of memory search. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011). Short-term memory scanning viewed as exemplar-based categorization. Psychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random walk model of speeded classification. Psychological Review, 104(2), 266–300.\n\n\nShepard, R. N. (1962a). The analysis of proximities: Multidimensional scaling with an unknown distance function. I. Psychometrika, 27(2), 125–140. https://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities: Multidimensional scaling with an unknown distance function. II. Psychometrika, 27(3), 219–246. https://doi.org/https://doi.org/10.1007/BF02289621",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "vector_reps.html",
    "href": "vector_reps.html",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "",
    "text": "10.1 Representations\nWhile it is beyond the scope of our course to delve into the philosophy behind the idea of “representation”, it is worth spending some time to think about what a “representation” is in the context of a cognitive model, so that we can at least arrive at a reasonable operational definition of the term. For additional discussion, see [].\nFor our purposes, we can define a representation as a formal entity posited by a cognitive model that enables certain kinds of processes that, when applied to that representation, enable the model to make predictions about performance in a particular task context. You may notice that this definition of a representation is tied to both the processes posited by a model as well as the kinds of predictions the model is expected to make. This is because a representation only has meaning in the context of these other aspects of the model.\nWe can think of a representation as a kind of “code” that conveys information that can be “read” by a suitable process. To take a concrete, if not exactly cognitive, example, consider the task of sorting mail. Imagine that we are working in a distribution center that receives packages that are intended to go to different parts of the country. Our job is to route those packages to the post office nearest their final destinations. We can accomplish this task by reading (processing) the ZIP codes on each package. The ZIP code is a numerical representation of the geographical area for which a package is destined, which when processed by an appropriate reader enables them to route the package to the correct office. This example illustrates the essential characteristics of a representation:\nWe can see how these principles manifested in the random walk/diffusion/race models we explored earlier. As we discussed, these models represent a decision-maker’s current state of mind in terms of one or more numbers that represent the degree to which the decision-maker favors each option they are choosing between. Representing evidence as a number enables an evidence accumulation process that can be modeled via the mathematical operation of addition. These models do not necessarily claim that the numbers that represent accumulated evidence are “implemented” in any particular way. That said, as we will see later in this course, it is possible to relate representations of accumulated evidence to scalp (Philiastides et al., 2006) and single-neuron (Purcell et al., 2010; Purcell et al., 2012; Shadlen & Newsome, 2001) electrophysiology as well as fMRI BOLD signals (Turner et al., 2013).",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "vector_reps.html#representations",
    "href": "vector_reps.html#representations",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "",
    "text": "A ZIP code only serves as a representation of geographical area when processed appropriately. If you don’t have sensory organs to see the numbers or you do not know how to interpret the numbers, the ZIP code is meaningless. As noted above, a representation only has meaning in the context of the processes applied to it to accomplish a task.\nThere isn’t necessarily just one way to represent something. We could write ZIP codes with Roman numerals instead of Arabic numerals—while this would entail changing the kind of process applied to the ZIP code (because the two formats must be read in different ways), both are legitimate ways of representing geographical regions in the context of the mail-sorting task. We could even use a graphical representation, like a map with a dot indicating the destination. Again, such a representation would need to be processed appropriately.\nThe structure of a representation may or may not enable multiple kinds of processes to be applied to it, potentially to serve different tasks. For example, ZIP codes do not just serve as labels for different regions—nearby regions have similar ZIP codes. This is because the earlier digits indicate broad geographic regions while later digits represent narrower subdivisions of those larger regions. Therefore, one could apply a comparison process to these ZIP codes to determine not just whether two packages were going to the same region, but whether they were going to nearby regions. This would enable sorting to be robust to certain kinds of contingencies. For example, if the post office in one region were closed, the comparison process could allow you to determine the nearest open office to send the package to. A graphical representation of the postal destination would allow for even finer gradations of similarity.\nPositing a representation does not necessarily commit to any particular way that such a representation may be implemented. Here, I use the term “implementation” in the same way as in the three levels of description posited by Marr (1982). A ZIP code can be “implemented” as ink on a page, as pixels on a screen, as an etching on a tablet, as a sound wave (if spoken aloud), etc. While these different implementations of a ZIP code would entail different implementations of how they were processed, they do not alter the form or content of the ZIP code. The broader point is that the kinds of representations posited by cognitive models are defined not by their physical forms, but rather by their abstract structure and the kinds of processes they support.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "vector_reps.html#types-of-vector-representations",
    "href": "vector_reps.html#types-of-vector-representations",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "10.2 Types of vector representations",
    "text": "10.2 Types of vector representations\nMany cognitive models make use of representations that take the form of vectors, that is, as ordered collections of numbers. We saw one kind of vector representation in the EBRW. In the EBRW, each item was represented as a vector of coordinates that specified that item’s position within a multidimensional space. That representation enabled the EBRW to operationalize similarity as a function of distance between vector representations of items. We now consider other broad classes of vector representations and, in the next section, we see how different kinds of representations enable other operationalizations of similarity. Finally, we see how similarity can be used to model performance in different kinds of tasks.\nIn the examples below, to keep things concrete, let’s imagine a participant is engaged in a task that involves making judgments about different concepts. There are eight concepts, each of which is a living thing from a particular category (these concepts are the same ones used in the examples from Rogers & McClelland (2004)):\n\nPine\nOak\nRose\nDaisy\nRobin\nCanary\nSunfish\nSalmon\n\nYou may notice that these concepts can be grouped together in different ways. For example, we could divide them up into plants and animals; into trees, flowers, birds, and fish; into things that are red, green, or yellow; etc. The kinds of vector representations we consider below will illustrate how these relations can be encoded in the vectors.\n\n10.2.1 Localist representations\nPerhaps the simplest and most direct way to represent each of the eight concepts above is to use a localist representation. The term “localist” refers to the idea that there is a one-to-one mapping between each concept and its “location” within a vector. Specifically, with a localist representation, each vector has as many entries as there are things to be represented. So if we have eight concepts, each of them will be represented with an eight-dimensional vector. Each of those vectors will contain zeros except for a “1” in exactly one entry in the vector. The “location” of the 1 is what determines which concept the vector represents.\nThe matrix below gives an example of a set of localist representations of each of the eight concepts above. Each row is the representation of a different concept.\n\n\nCode\nconcept_names &lt;- c(\"Pine\", \"Oak\", \"Rose\", \"Daisy\", \"Robin\", \"Canary\", \"Sunfish\", \"Salmon\")\ncategory_names &lt;- rep(c(\"Tree\", \"Flower\", \"Bird\", \"Fish\"), each = 2)\n\nrep_localist &lt;- diag(length(concept_names))\nrownames(rep_localist) &lt;- concept_names\n\nprint(rep_localist)\n\n\n        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\nPine       1    0    0    0    0    0    0    0\nOak        0    1    0    0    0    0    0    0\nRose       0    0    1    0    0    0    0    0\nDaisy      0    0    0    1    0    0    0    0\nRobin      0    0    0    0    1    0    0    0\nCanary     0    0    0    0    0    1    0    0\nSunfish    0    0    0    0    0    0    1    0\nSalmon     0    0    0    0    0    0    0    1\n\n\nNote that there is nothing special about having the 1’s on the diagonal—or even about using 1’s in the first place! For example, the matrix below is another example of localist representations of the same set of concepts:\n\n\nCode\nalt_rep_localist &lt;- rep_localist %*% diag(rpois(n = nrow(rep_localist), lambda = 5) + 1)\nalt_rep_localist &lt;- alt_rep_localist[sample(nrow(alt_rep_localist)),]\nrownames(alt_rep_localist) &lt;- concept_names\n\nprint(alt_rep_localist)\n\n\n        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\nPine       0   12    0    0    0    0    0    0\nOak        0    0    0    0    0    0    0    7\nRose       0    0    0    0    0    0    4    0\nDaisy      0    0    0    5    0    0    0    0\nRobin      0    0    0    0    0    5    0    0\nCanary     0    0    5    0    0    0    0    0\nSunfish    0    0    0    0    2    0    0    0\nSalmon     4    0    0    0    0    0    0    0\n\n\nWe could even replace all the 0’s with NAs or -99 or any other value that we agree to interpret as a kind of “background”. Ultimately, what matters about a localist representation is that what a vector represents is indicated by which entry in the vector is “not background”.\n\n\n10.2.2 Separable distributed representations\nAnother defining characteristic of a localist representation is that it does not allow for gradations of similarity. Either two representations refer to the same thing or they refer to different things. Distributed vector representations, like those used in the EBRW, allow for representations to be partially similar to one another.\nAlthough it is not necessarily standard terminology in the field, I think it is important to distinguish between separable and integral distributed representations. The difference between them is that, with a separable distributed representation, it is possible to identify the elements of the vector with particular attributes/features/dimensions of the items being represented. With an integral distributed representation, the individual elements of the vector have no interpretation on their own—instead, different items are represented by different patterns of values across all the elements of a vector. This distinction probably seems pretty abstract, so let’s dig into some concrete examples.\nReturning to the set of concepts above, one way to construct a set of separable distributed representations is to consider different attributes that each concept may or may not have. Each element of the vectors corresponds to a different attribute. For each concept, its representation will have a value of 1 in the entries corresponding to attributes that the concept possesses and a value of 0 in the entries corresponding to attributes that the concept lacks. This is illustrated below:\n\n\nCode\nattribute_names &lt;- c(\"can_grow\", \"is_living\", \"has_roots\", \"has_bark\", \"is_big\", \"has_branches\", \"is_green\", \"has_leaves\", \"has_petals\", \"is_pretty\", \"is_red\", \"is_yellow\", \"can_move\", \"has_feathers\", \"can_fly\", \"has_wings\", \"can_sing\", \"can_swim\", \"has_gills\", \"has_scales\")\n\nrep_distrib_sep1 &lt;- matrix(c(\n    1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1\n), nrow = 8, ncol = length(attribute_names), byrow = TRUE, dimnames = list(concept_names, attribute_names))\n\nknitr::kable(rep_distrib_sep1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncan_grow\nis_living\nhas_roots\nhas_bark\nis_big\nhas_branches\nis_green\nhas_leaves\nhas_petals\nis_pretty\nis_red\nis_yellow\ncan_move\nhas_feathers\ncan_fly\nhas_wings\ncan_sing\ncan_swim\nhas_gills\nhas_scales\n\n\n\n\nPine\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nOak\n1\n1\n1\n1\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nRose\n1\n1\n1\n0\n0\n0\n0\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nDaisy\n1\n1\n1\n0\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nRobin\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n1\n1\n1\n0\n0\n0\n0\n\n\nCanary\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n0\n0\n0\n\n\nSunfish\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n1\n\n\nSalmon\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n1\n1\n\n\n\n\n\nAlthough we will consider similarity more deeply in the next section, note that the distributed representations above make it possible to judge similarity based on the extent to which two concepts’ representations do or do not share attributes. Indeed, the different categories (plants/animals) and subcategories (trees/flowers/birds/fish) to which the concepts belong are implicit in which attributes are shared between concepts.\nIn the example above, each entry in the vector corresponded to a distinct attribute. It is also possible to construct separable distributed representations where attributes are encoded with sectors of a vector. For example, rather than treating is_red, is_yellow, and is_green as different attributes, we might assign a “sector” consisting of several entries to represent the color associated with a concept. Maybe that sector consists of three entries, for hue, chroma, and lightness, as in the example at the beginning of the EBRW chapter.\nRelatedly, distributed representations can use continuous values—they are not restricted to binary indicators of the presence/absence of an attribute. For example, instead of an attribute called is_big, we could have a size attribute which corresponds to the size of the concept being represented.\nFor example, here is how one might represent color and size for each of the concepts in our running example:\n\n\nCode\nalt_attribute_names &lt;- c(\"size\", \"hue\", \"chroma\", \"lightness\")\n\nrep_distrib_sep2 &lt;- matrix(c(\n    50, 131, 36, 27,\n    40, 20, 60, 16,\n    0.1, 3, 58, 79,\n    0.2, 52, 100, 50,\n    0.3, 9, 63, 38,\n    0.1, 60, 100, 63,\n    0.5, 32, 100, 59,\n    1, 5, 99, 71\n), nrow = 8, ncol = length(alt_attribute_names), byrow = TRUE, dimnames = list(concept_names, alt_attribute_names))\n\nknitr::kable(rep_distrib_sep2)\n\n\n\n\n\n\nsize\nhue\nchroma\nlightness\n\n\n\n\nPine\n50.0\n131\n36\n27\n\n\nOak\n40.0\n20\n60\n16\n\n\nRose\n0.1\n3\n58\n79\n\n\nDaisy\n0.2\n52\n100\n50\n\n\nRobin\n0.3\n9\n63\n38\n\n\nCanary\n0.1\n60\n100\n63\n\n\nSunfish\n0.5\n32\n100\n59\n\n\nSalmon\n1.0\n5\n99\n71\n\n\n\n\n\nWith a separable distributed representation, we can increase the dimensionality of the vectors as much as we want. For example, a separable distributed representation might consist of hundreds of dimensions. However, it is unlikely that all of these dimensions would be relevant to any particular task. There may also be capacity limits on the number of dimensions that someone could make use of at any particular time. This highlights one final, but important, aspects of a separable distributed representation: Because different kinds of information about an item are represented in different elements of the vector, separable distributed representations enable us to model attention to particular kinds of information. Specifically, as we shall see below, we can assign weights to each dimension that represent the degree to which someone attends to that dimension within a given task context. A separable distributed representation can thus support performance in many different tasks by assuming that some tasks entail attention to different elements of that representation.\n\n\n10.2.3 Integral distributed representations\nThe final kind of vector representation we will consider are integral distributed representations. The difference between integral and separable distributed representations is that the vector elements of an integral representation cannot be identified with distinct features/attributes of the items. Rather, an item’s representation consists of the complete pattern of elements across the vector. An integral representation can thus be thought of as a “holistic” or “configural” representation, because its individual elements can only be understood as part of the complete pattern of entries in the vector.\nAn analogy may help clarify this admittedly abstract issue: Consider baking a cake. Before you bake the cake, its ingredients are separable: You have a pile of flour, a carton of eggs, a jug of milk, etc. One could imagine constructing a separable distributed representation of the pre-baked cake in which each element corresponded to a particular ingredient and the entries specified the quantities of each ingredient. However, once the ingredients are mixed and the cake is baked, it is no longer reducible to its component ingredients. Those same ingredients, in those same quantities, would not necessarily result in the same cake—it is the particular way in which the ingredients are combined and prepared that results in the final product. The way any individual ingredient contributes to the baked cake depends on its relationship to all the other ingredients in the cake. In that sense, the baked cake is best represented using an integral as opposed to separable representation.\nUnlike separable representations, then, integral representations make it impossible to model giving different amounts of weight/attention to different attributes of an item. This is an important distinction, and is why I adopted the terms “integral” and “separable” to distinguish between these kinds of representations. Garner & Felfoldy (1970) used those terms to distinguish between cases in which a participant could selectively attend to one feature while ignoring others (separable) and cases in which a participant could not ignore other features (integral).\nIt is still possible to conceive of similarity between integral representations. It is just that similarity depends not on sharing specific elements of a vector, but instead on having similar patterns of values across elements. To visualize this, we can graph a vector representation with the index of the elements along the horizontal axis and the value on the vertical axis. Integral representations are similar to the extent that the resulting graphs have similar shapes. This is illustrated below.\n\n\nCode\nx &lt;- rnorm(n = 10)\nx &lt;- (x - mean(x)) / sd(x)\n\ns_vals &lt;- round(seq(0, 1, length.out = 6), 2)\n\ntoPlot &lt;- c()\n\nfor (s in s_vals) {\n    if (s &lt; 1) {\n        while (TRUE) {\n            y &lt;- rnorm(n = 10)\n            y &lt;- (y - mean(y)) / sd(y)\n            \n            if (round(cor(x, y), 2) == s) break\n        }\n    } else {\n        y &lt;- x\n    }\n    \n    toPlot &lt;- rbind(\n        toPlot,\n        tibble(sim_factor = paste(\"Similarity =\", s), rep = \"A\", i = 1:length(x), val = x),\n        tibble(sim_factor = paste(\"Similarity =\", s), rep = \"B\", i = 1:length(y), val = y)\n    )\n}\n\ntoPlot %&gt;%\n    ggplot(aes(x = i, y = val, color = rep, linetype = rep)) +\n    geom_line() +\n    facet_wrap(\"sim_factor\") +\n    labs(x = \"Vector index\", y = \"Value\", color = \"Representation\", linetype = \"Representation\", title = \"Similarity between integral representations\")\n\n\n\n\n\n\n\n\n\nIt will not have escaped your notice (especially if you look at the code for the above chunk) that similarity between integral representations can be modeled in terms of their correlation. We will explore this more below.\nFor now, we can return to our running example to see what integral distributed representations of our eight concepts might look like. In fact, the example representations below are based on ones derived from a statistical model of word co-occurrence called Latent Semantic Analysis (Landauer & Dumais, 1997). As noted below, many machine learning models make use of integral distributed representations, and some of these are even plausible cognitive models of learning, which we will explore in the next chapter.\n\n\nCode\nload(\"lsa_reps_examples.rdata\")\nrownames(lsa_reps_examples) &lt;- concept_names\n\nknitr::kable(lsa_reps_examples)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\nV162\nV163\nV164\nV165\nV166\nV167\nV168\nV169\nV170\nV171\nV172\nV173\nV174\nV175\nV176\nV177\nV178\nV179\nV180\nV181\nV182\nV183\nV184\nV185\nV186\nV187\nV188\nV189\nV190\nV191\nV192\nV193\nV194\nV195\nV196\nV197\nV198\nV199\nV200\nV201\nV202\nV203\nV204\nV205\nV206\nV207\nV208\nV209\nV210\nV211\nV212\nV213\nV214\nV215\nV216\nV217\nV218\nV219\nV220\nV221\nV222\nV223\nV224\nV225\nV226\nV227\nV228\nV229\nV230\nV231\nV232\nV233\nV234\nV235\nV236\nV237\nV238\nV239\nV240\nV241\nV242\nV243\nV244\nV245\nV246\nV247\nV248\nV249\nV250\nV251\nV252\nV253\nV254\nV255\nV256\nV257\nV258\nV259\nV260\nV261\nV262\nV263\nV264\nV265\nV266\nV267\nV268\nV269\nV270\nV271\nV272\nV273\nV274\nV275\nV276\nV277\nV278\nV279\nV280\nV281\nV282\nV283\nV284\nV285\nV286\nV287\nV288\nV289\nV290\nV291\nV292\nV293\nV294\nV295\nV296\nV297\nV298\nV299\nV300\nV301\n\n\n\n\nPine\n57.307893\n-33.412359\n16.2100709\n44.705718\n5.4170146\n-77.312664\n-14.9572611\n-27.9986255\n-32.299533\n-14.5052352\n-4.5012929\n-14.7266570\n-16.1968384\n-2.7994879\n22.4571901\n15.729012\n11.851067\n24.6211851\n-9.1846293\n2.2328819\n-50.0163069\n-3.0823218\n33.7986198\n3.119457\n-17.114383\n13.4889538\n4.2553778\n-1.5470188\n-0.0345441\n-18.7060762\n-5.5927648\n-3.3022175\n-8.9941651\n-1.8332407\n22.5889364\n13.926796\n-9.5462912\n0.7528040\n20.7099540\n8.977873\n-18.0528367\n13.0251756\n5.1726928\n12.223609\n1.9835759\n16.4832762\n14.7923809\n-2.818340\n9.3103527\n-0.0929313\n-2.4702942\n-25.6337961\n14.202371\n-11.0013780\n-15.1385398\n20.0835240\n-0.0384213\n-17.011600\n14.5557277\n-3.6187865\n-8.1690392\n9.0190558\n6.2733016\n-6.4742631\n-21.835881\n7.759060\n9.4504609\n-9.293384\n2.3812821\n13.5068984\n2.3493417\n6.492563\n11.2623955\n-7.2021843\n4.4342641\n4.404997\n-3.6185602\n4.560521\n-5.6883207\n0.3942039\n-3.103478\n-0.2551315\n-7.4488074\n1.048294\n-1.7003834\n-14.8334574\n-7.3806372\n21.785405\n-6.706319\n-14.7996623\n-14.8057805\n4.2287031\n-6.268469\n-9.6626014\n3.6745613\n-25.201119\n5.2614205\n-0.3076832\n13.4564618\n-0.2724789\n-0.7343194\n3.7806412\n-4.0303417\n6.906578\n-16.8387944\n-13.0173042\n2.5265882\n-2.1689518\n3.9887857\n-7.5873560\n13.2403690\n-6.8157585\n-5.555756\n-9.843402\n6.9697738\n1.149107\n-0.7261884\n13.9617517\n-1.0806520\n-0.7193217\n-4.611446\n0.6665858\n-6.824130\n-10.490425\n-0.4190986\n6.6339878\n7.8565984\n0.0106521\n2.7727858\n0.2248497\n-3.6600560\n-0.4946363\n-13.6349074\n-11.496180\n-10.7151125\n-9.0431384\n8.1208173\n-2.457928\n-6.4496081\n-3.1466380\n0.1797440\n-10.4487262\n-3.0656779\n1.3713914\n7.7817654\n2.2848116\n3.4939900\n-4.0449003\n-0.4560466\n4.2031594\n-6.6603234\n-6.8989429\n0.6610100\n-2.7081900\n1.3808937\n-8.3187305\n4.1863844\n-8.4271535\n9.202663\n13.9739600\n-5.6569982\n8.1442349\n-0.4116793\n-2.4405695\n14.0171390\n1.2796313\n-4.2112780\n-5.6927812\n-1.065173\n-14.3548774\n-0.6837453\n-8.4956908\n4.7990248\n-13.9831855\n6.1447592\n-6.668499\n-1.9669608\n8.8483279\n-9.9708037\n-1.5526994\n-2.3869305\n2.7068987\n-5.8647411\n3.9524734\n4.062503\n-3.9309064\n-7.8845501\n7.1579054\n0.1585556\n-5.5554894\n9.0703253\n-4.0248275\n-6.9605902\n-9.8685993\n-0.3081633\n0.4980695\n3.7748428\n1.9719101\n5.0909790\n0.1292172\n-3.226018\n9.6870012\n-1.3666593\n2.211289\n-0.8944688\n-0.8549064\n3.0816563\n4.9719423\n4.114711\n-14.281108\n-7.9345617\n-1.6437555\n-7.9618872\n-8.0368606\n3.4011152\n-2.7222087\n2.8836967\n0.2547526\n-2.3780604\n-1.1224880\n-11.5821939\n4.0609673\n-8.6903496\n-2.8427766\n-2.4340404\n4.2274566\n-8.3796828\n5.6594842\n2.7963812\n0.2636938\n-9.7927961\n9.5555720\n9.4439495\n1.522367\n-6.7097545\n-0.3524096\n-0.8597147\n6.5798253\n2.2472588\n8.0601951\n-5.9025702\n-2.5059219\n2.0198455\n-12.8518396\n2.291976\n1.1620025\n6.2732416\n2.8002452\n-1.6263764\n2.6704350\n-10.1605403\n-2.7630097\n12.7147504\n5.715203\n1.8822445\n7.2482598\n2.3230484\n-5.3064914\n8.0907059\n3.4526805\n-8.4392930\n4.3845380\n-2.7214840\n13.0781151\n4.9657986\n4.3581377\n-7.6347574\n4.2915669\n1.3878334\n3.9236583\n2.0851763\n-9.9306471\n-2.457062\n11.5000748\n6.9552347\n-0.2530878\n10.3370600\n-5.9768839\n-8.2311500\n-3.3333605\n7.1425790\n2.4735721\n0.0097459\n2.8663022\n-3.1668199\n1.2567023\n-0.6361538\n-6.8877328\n11.1474688\n-3.9729353\n-1.8673939\n-1.0748327\n6.478546\n12.9997228\n10.3136090\n-5.5700471\n-9.9853885\n9.1411329\n0.2742870\n-1.6717776\n\n\nOak\n80.828697\n-43.005475\n26.7473579\n33.209697\n10.2143428\n-88.688440\n-26.7698885\n-36.4809668\n-32.689389\n-28.1914601\n5.8729877\n-20.1327581\n-26.6134246\n16.4039523\n15.2154146\n13.858923\n-16.996326\n-0.0919365\n10.3958523\n19.4280717\n-48.1713132\n-10.4005373\n16.1410747\n-2.868989\n-28.312146\n2.4767914\n-8.9061867\n-5.9204197\n4.4135992\n-17.6132436\n-24.8680966\n11.0406067\n-22.7716040\n-1.1670161\n12.7757840\n5.076753\n4.1300678\n-5.0944729\n47.6587007\n6.015303\n-19.0976943\n1.9509617\n-4.9462611\n4.171989\n3.3572475\n20.1556112\n10.8333810\n-7.790407\n2.5772871\n-20.7119218\n5.0779574\n-19.1404229\n22.226832\n-22.0977128\n-8.9922374\n18.7208032\n-4.4950088\n-15.808647\n22.7718473\n-7.4013208\n10.9007914\n13.8910809\n24.5008176\n0.2974784\n-6.888492\n-4.040368\n17.0215756\n-21.543589\n6.4547801\n1.7278160\n6.0658790\n11.427325\n13.5814514\n-7.5986843\n-0.4017347\n12.109434\n-11.1031793\n3.234420\n11.4574224\n-10.0867276\n-10.302973\n-18.1461301\n-5.2251757\n18.880036\n-8.3391278\n-6.6289327\n-0.6804034\n10.682985\n-9.124614\n-9.7054687\n-4.9089148\n-16.4950604\n1.187639\n-4.1632332\n-2.1032415\n-18.275406\n2.3416492\n-7.5896618\n24.0136987\n-3.2429851\n6.9687686\n14.4519253\n-0.2791838\n7.115823\n-11.9696475\n-1.5205516\n-8.2146305\n7.9105197\n14.0550096\n-2.9324309\n22.6483777\n10.3098669\n-2.724509\n2.098667\n4.5523924\n-10.880036\n0.5708622\n9.9182861\n-9.6121785\n-8.8592534\n0.124189\n16.0831198\n-7.280793\n-7.470394\n15.9237948\n7.6834953\n12.3278255\n-3.5486672\n-11.9662029\n-4.9252451\n-2.1536257\n1.8985313\n-7.5979244\n-7.383110\n-19.0073754\n1.9448647\n2.0579126\n-17.412922\n-11.1693916\n-14.6267846\n-4.1773881\n-12.7152303\n8.6602983\n8.8907915\n3.0503019\n-0.0037553\n-9.8574560\n4.4583720\n-3.1306854\n-9.1026034\n-6.1067185\n-10.6015973\n-5.7251255\n-10.5043480\n0.8605427\n-12.5711306\n3.9891822\n-14.5223856\n2.131734\n8.6427481\n-4.4826514\n3.5473972\n-1.4149334\n-9.7085635\n16.2090817\n-0.1036665\n-10.3853703\n-6.5985241\n-5.582096\n-5.1657445\n-8.3063971\n-18.5980656\n12.2062214\n-6.8818838\n5.1119193\n7.313527\n-6.2993178\n9.0798866\n-13.2630747\n4.6537671\n3.7365609\n-1.4956865\n-12.0706154\n0.9103531\n-1.686001\n-2.8324344\n-6.7086971\n12.9250006\n11.1620524\n-9.8040349\n12.2273438\n6.4498272\n-6.0560375\n-8.9560154\n11.3814081\n17.0410777\n-0.3908397\n12.1629579\n10.2282912\n13.1237576\n8.497552\n7.8198934\n-11.0312620\n-1.332901\n-13.9372947\n6.5161129\n1.5215513\n-5.0862092\n-5.332131\n-8.985470\n-3.0928814\n-11.8218450\n-8.3140759\n-9.1598165\n0.7849052\n-1.6985827\n4.3136719\n-1.6546882\n1.9974886\n-9.4080705\n-19.5365685\n-0.6712322\n-17.2954168\n0.4360413\n1.9430895\n16.7224478\n-12.1301834\n13.3619001\n-9.1417729\n-4.3495371\n-20.9839851\n3.0265527\n21.3448865\n20.042162\n-3.9763363\n-7.7227427\n-4.3354595\n1.5552491\n3.5565718\n7.3571507\n4.9196287\n-6.7190032\n15.4551298\n-18.3392176\n-7.329798\n19.9773636\n3.9836644\n-9.9018899\n-2.4813813\n0.8674818\n-10.0296373\n5.1682120\n14.7502598\n-2.908291\n3.3245893\n-1.7032331\n13.9013417\n3.4384251\n7.8857765\n-8.5167114\n-18.8396904\n5.5098333\n-2.5232538\n12.7119670\n-2.0198069\n11.5662823\n-8.4465002\n12.6920782\n8.5115727\n5.0622426\n1.0143331\n-10.7399950\n-5.023741\n13.8779947\n7.6182755\n-14.4531521\n5.6044493\n-2.8049467\n-11.8018653\n4.2484054\n-3.9074604\n-7.9172866\n-3.5020140\n8.1817810\n3.6104357\n0.2792197\n2.6597445\n-10.6930430\n19.5662373\n-11.0043755\n6.7610438\n1.8715504\n5.841162\n12.3294527\n-0.5637173\n1.4770438\n-13.3556489\n5.2794818\n3.9390143\n-5.9196026\n\n\nRose\n169.793825\n-98.482982\n7.9087297\n-33.526768\n-15.3870192\n-12.804220\n-14.4783884\n-15.5809105\n-25.410565\n-19.4996026\n-27.4623533\n-5.6971808\n-8.5937710\n28.3714423\n29.5112569\n-7.504715\n-12.272873\n-14.9184604\n48.8658440\n1.8716615\n-14.6257486\n-29.9462025\n-2.6105517\n-18.737203\n5.911870\n24.5004368\n3.5533200\n27.8024060\n-2.2104456\n-27.5325946\n5.3811664\n14.3092581\n-4.2505634\n6.2236096\n30.3394288\n8.797142\n4.6484107\n4.6574179\n10.1908145\n-5.267450\n-19.6150691\n-23.6457392\n29.0449034\n-28.486535\n7.6362859\n-0.1406000\n-5.7477637\n-2.528637\n23.5909689\n-14.3507716\n18.2506426\n-9.4865387\n12.052128\n-15.1619448\n14.9628981\n9.3703101\n-11.4976291\n3.435361\n7.0759125\n-1.4774759\n-0.0685737\n-16.2138107\n-11.4504387\n-11.0340333\n-8.777626\n10.978064\n31.6275187\n-17.394848\n1.5170053\n-12.4252284\n3.1297145\n9.534743\n25.7245968\n1.5104692\n-12.8455362\n21.783901\n-33.4809698\n22.691487\n15.3734504\n7.3714504\n1.814490\n-0.1285942\n8.4247191\n19.642460\n-4.7169768\n-0.1141606\n7.3560021\n14.891125\n6.643697\n-12.9119349\n3.8057530\n11.4236129\n-7.610132\n22.4005712\n-11.1136624\n-14.408629\n-3.2702556\n10.5295792\n4.7816807\n13.0524770\n0.2997899\n6.3874410\n10.2777419\n14.919367\n15.9114001\n2.6025231\n11.2475550\n10.1245306\n-4.3021472\n-14.1799770\n29.2487634\n15.3426564\n7.777509\n5.093669\n-26.2353297\n7.290247\n-1.3080207\n14.7794721\n-7.3412600\n1.5924531\n10.437176\n-7.2708055\n3.825308\n-4.408311\n22.2402751\n-9.7766258\n12.9946723\n5.5923931\n-6.1653314\n-14.2313198\n19.3671305\n19.4241150\n4.6512561\n-5.752324\n-3.0811970\n0.7296660\n-11.6086048\n3.939982\n-9.5809516\n-1.1101148\n11.4602614\n7.3187249\n-0.9660889\n-11.2094730\n5.8177400\n-1.7164509\n12.0703200\n2.6721368\n-13.8695715\n-8.8573739\n-2.0379172\n-0.0437098\n-6.8562632\n-10.4266609\n1.9711819\n-17.1435723\n-21.0114836\n-3.0988737\n-16.277689\n5.6989771\n17.1905151\n7.3003084\n-13.0027768\n-6.8507316\n13.4156697\n2.5991769\n6.6928880\n0.9784581\n-15.818938\n5.1605969\n-7.9594016\n8.7603460\n-9.5441003\n6.5391132\n3.2680039\n7.200926\n8.5513808\n-12.7086585\n7.3750603\n-14.1497674\n6.1342401\n-0.4422350\n2.8880373\n-13.0100570\n-14.632730\n15.6580307\n-19.2117003\n-6.3291255\n-9.8000420\n1.1788047\n2.0219291\n-6.1350549\n-7.5339776\n4.4261359\n12.7294918\n14.7959570\n14.2741003\n1.3313340\n-3.6815732\n13.1639548\n6.393202\n3.3457355\n-0.3390432\n2.370055\n-26.2276702\n1.8357318\n0.4190367\n2.3285473\n1.788032\n-1.154643\n10.6305695\n-6.9046237\n-2.4252594\n8.7147069\n-10.0202057\n12.2915791\n-4.8637219\n-8.3308660\n14.7143327\n-5.9119868\n-3.5836339\n-5.9821050\n3.3685229\n-0.5273490\n7.4853536\n0.8879983\n-1.6465533\n6.7061540\n2.4660995\n-17.8014362\n3.0484707\n-8.8926470\n-5.8612257\n-10.381385\n1.3308735\n-1.7600527\n-6.8335712\n2.2206121\n-5.4044090\n-0.9646472\n-13.1956251\n-0.5255635\n6.2242313\n-5.5270536\n-3.950202\n10.8664688\n-13.9663561\n0.0951356\n-1.8206412\n-8.7879439\n-22.3673848\n1.2170017\n-14.5392483\n5.334749\n-0.3670962\n-1.2099986\n-6.3474973\n22.8696146\n2.1016206\n-12.2466947\n-3.1836825\n-13.9297601\n-19.3750175\n-5.5130141\n7.4440775\n4.6176661\n9.0544032\n17.0450127\n1.3686618\n3.7586278\n-7.5690573\n-13.8882015\n-2.576893\n11.9090520\n11.9572000\n-1.8513407\n-1.2740561\n2.4682909\n3.4724126\n-7.5428997\n-9.2694222\n-6.5640788\n-9.9982253\n0.4708680\n-2.7110109\n2.2204115\n-10.2996062\n-1.0598588\n11.1593595\n11.8381842\n5.0702978\n13.6659472\n-13.532357\n12.3769665\n-3.2224983\n-4.2846200\n7.7764724\n-5.4564864\n-1.6851974\n-1.2794527\n\n\nDaisy\n24.100221\n-16.222531\n-9.3980192\n3.055284\n4.6509376\n-2.064403\n3.9375922\n-7.1785296\n-3.427622\n-2.5476127\n-3.1881560\n-3.0890079\n2.8138486\n8.4137179\n8.8892470\n3.930178\n4.484171\n-5.4619650\n3.4778137\n-0.6353814\n-15.1974376\n-1.0285566\n-1.0310829\n-5.313575\n6.470959\n1.2715653\n-2.6302464\n-0.2207977\n1.3919182\n-2.1731995\n-0.9797795\n-0.1544892\n1.0353388\n4.5132537\n-0.5794254\n-3.784247\n7.4763496\n1.1541796\n1.8444969\n4.896767\n0.4737606\n0.9662965\n-0.8882757\n2.829369\n2.2048359\n5.3551305\n1.7500490\n-2.990434\n7.6930077\n-3.2830856\n1.9311926\n-1.5081203\n6.648616\n-8.3339914\n2.1998600\n9.1336778\n2.9894294\n-2.443459\n2.7925253\n1.1114895\n3.0950249\n-6.0302616\n-1.7250197\n2.7722301\n-2.009590\n-2.873179\n5.3776300\n-3.190599\n-1.2582892\n-1.1636990\n-0.5336351\n4.735501\n3.0734966\n1.4201545\n-7.2246440\n1.439099\n-4.7856932\n2.419344\n4.3053005\n-0.6889198\n2.566885\n0.1682647\n1.8888079\n3.535584\n-2.7770019\n0.7089246\n4.0487488\n2.837982\n2.183721\n-0.2072544\n-2.7926343\n1.6429740\n-4.428295\n7.5298984\n0.7520422\n-3.652488\n2.1818781\n4.1139360\n2.6437537\n2.8562345\n1.6740233\n-5.6797268\n1.4680887\n5.022289\n0.0013254\n0.9708033\n-0.0881402\n-0.3067673\n-1.4011147\n-0.0301427\n1.7268919\n0.2298842\n1.751551\n2.619544\n0.1792596\n2.262902\n0.5520544\n2.2583938\n-3.4603345\n-1.4617958\n1.765299\n-3.4695657\n-1.789427\n-1.291499\n-0.9980570\n-0.8156097\n2.2177832\n-1.2410956\n0.1199769\n1.2092455\n0.5854205\n0.6172075\n1.0071439\n-1.830293\n0.6156090\n-1.5444117\n0.3443324\n2.931205\n-0.5220600\n-0.3023792\n-2.6408510\n0.9592554\n-0.6381676\n-2.1317337\n1.6269074\n0.7034337\n0.7778252\n-0.6087897\n1.0196182\n-0.5708336\n0.3365156\n-0.4899099\n0.1691228\n-2.2193951\n0.6475840\n-1.3154586\n-1.5273491\n1.9772685\n-1.502573\n0.5563318\n-0.9540241\n-0.9424389\n-0.1309414\n0.5641224\n4.9536121\n-1.6481216\n0.0152478\n0.0713423\n-2.476908\n-1.2880931\n-2.2792060\n-1.5237614\n1.8059194\n-1.0313243\n-1.8179311\n1.719301\n1.4999382\n-0.8877665\n-1.1326820\n-2.6514381\n-2.1634048\n0.2419982\n4.1322335\n-1.7894117\n-1.879960\n-0.9275659\n-2.8482647\n0.0662491\n-1.2305098\n2.5804608\n0.1833774\n0.1125451\n-2.4019557\n1.3005379\n-1.7227692\n0.2017959\n2.4216225\n2.5192043\n-0.0032864\n-0.4333918\n0.878485\n-0.1422516\n1.5043564\n1.427500\n-1.4644374\n1.8093708\n-1.3059904\n1.9247803\n2.011994\n-0.836282\n-0.0305426\n2.6002665\n-0.4163487\n-1.1505782\n0.5197413\n-0.3288488\n2.0073724\n-3.3995149\n0.3591165\n-0.8033242\n2.3073012\n-2.4522559\n1.0381770\n0.5889167\n-1.2192055\n-2.2046264\n-0.0626758\n-2.2200307\n1.7759482\n-1.4519378\n1.4079847\n4.1210806\n-1.1196130\n-1.105506\n1.3710091\n-0.5470366\n-0.4197090\n-1.8541823\n0.8415489\n-3.7318444\n2.5166220\n3.6061232\n4.2544035\n1.8787912\n2.367761\n-0.3487660\n0.2295378\n-0.2703449\n-0.4056041\n-0.8336008\n-0.9515302\n-0.8328531\n-0.2374453\n2.148024\n-1.5675426\n1.2949289\n1.6991554\n2.7862258\n-0.6770487\n0.0717748\n2.0054809\n-1.4472863\n0.4194559\n-1.0473439\n1.0471419\n-0.8462998\n-0.7288768\n2.1141282\n0.2206433\n0.9258962\n-3.9254093\n-1.4988314\n1.123979\n-0.3680056\n2.0287794\n-4.2838177\n0.5503843\n-0.7195955\n1.3857401\n-0.7845520\n-1.6141708\n0.4472853\n-0.7486416\n0.7764512\n-0.1349593\n1.3673770\n-1.5620602\n-1.1320222\n-1.6498093\n2.6569546\n-0.3293581\n-0.7622562\n1.200270\n-0.4821121\n-1.1639723\n-0.9182759\n-0.4077662\n-1.6968441\n-2.0445169\n0.4338182\n\n\nRobin\n87.209927\n-39.421553\n-13.2598933\n-19.255405\n12.6966848\n13.649532\n1.5221174\n-14.5741633\n-12.210516\n-0.5938838\n-18.5349484\n2.2500446\n-21.2421595\n24.6352050\n13.8045869\n32.620392\n17.944238\n-36.4383255\n7.9661383\n-5.6953062\n-11.4241949\n11.2369978\n0.6669709\n-8.619645\n13.561825\n6.9819243\n18.0589694\n2.5570000\n-0.6621710\n6.6970804\n-8.7458538\n-0.9545062\n0.0350254\n10.0853483\n-12.8431858\n-1.320653\n2.0786364\n-1.4873606\n8.4382774\n14.977747\n-12.4116775\n10.7415860\n-4.5315644\n13.927279\n-0.7128135\n9.6521416\n-15.8944102\n-10.277005\n1.9953862\n-4.9111056\n13.1432152\n5.2965675\n6.968865\n-10.1453840\n6.4075715\n23.5236111\n8.0962490\n1.989658\n11.7967562\n7.6318221\n-3.2844709\n4.1211137\n-14.3982188\n-10.9720064\n-6.372903\n4.284889\n-2.0337362\n-1.238032\n-2.4289796\n-5.6503061\n-5.9904350\n5.792373\n6.6458773\n1.3018887\n10.0427329\n5.481997\n2.8851058\n-5.935497\n-7.9150823\n3.4489882\n9.693554\n-10.6514120\n3.4651870\n-16.072585\n-4.8761024\n0.4401328\n2.3540835\n2.018782\n-2.763589\n-11.4212434\n-2.3363155\n-7.5630419\n-8.602159\n-4.2029689\n7.3109632\n-11.829872\n-0.2461956\n-2.6658087\n3.1757153\n-5.1620742\n14.5710273\n-10.9124843\n-1.3028343\n1.692319\n-0.7856966\n-18.7663053\n1.2938884\n7.7773864\n-7.3547104\n-3.8452535\n3.5982890\n-2.2197566\n-2.964379\n-1.904294\n-2.5573230\n3.325042\n6.1901865\n2.2946508\n-8.6880534\n-12.0032768\n10.386573\n-12.8842522\n-6.411623\n-7.892069\n-2.3083960\n-5.8206563\n-0.6115528\n-4.2427814\n2.2741640\n6.5603657\n1.4889978\n-7.4718740\n-4.2095390\n1.977323\n8.5250592\n-3.7560782\n1.0639200\n7.170260\n-0.5884419\n-4.8995161\n-0.3838779\n5.7217020\n2.7197784\n-0.1464315\n4.8567756\n-3.7900789\n-12.7395744\n-6.5280637\n4.6569942\n-5.3193175\n3.3383670\n-6.3656664\n6.2351808\n-7.2392041\n2.8795302\n-13.1776304\n-3.7389721\n3.4776007\n4.965016\n-0.1876198\n-4.3859840\n4.6497057\n-2.7225727\n0.0782279\n5.5174978\n-1.8113893\n-3.6797836\n2.8278217\n3.474013\n6.2143381\n4.6871694\n-3.9044960\n-3.4702816\n1.1007603\n-6.5268288\n2.856452\n-1.4037336\n-4.9919524\n-3.4320218\n-1.6192452\n-5.3155054\n-3.1168445\n-2.8154924\n-4.2488728\n1.439867\n3.6809335\n-3.6949757\n3.2758540\n0.3023899\n2.8939321\n5.8187221\n-0.6670275\n3.0347652\n-0.0887428\n-1.5831982\n2.3446869\n2.5552661\n7.5736351\n-0.7490191\n4.2969524\n-1.069244\n8.1020301\n1.3164267\n-4.474278\n-0.9060467\n3.3468269\n-5.6638199\n7.6678717\n2.111567\n-5.039989\n0.6724506\n5.3588127\n-2.4365683\n3.9894087\n1.8377403\n-1.5928317\n0.2032277\n-0.2400587\n-7.0711414\n-3.5950192\n0.8553665\n5.4162505\n-1.4317203\n3.0724923\n-1.0762675\n2.2648095\n2.4612144\n-1.0634334\n-0.5904171\n5.8193823\n0.7524095\n3.8338898\n6.2357706\n-2.316103\n-1.3868023\n-4.9612493\n-0.7907146\n2.9447086\n-0.2930757\n-0.4749651\n2.5210642\n6.3847007\n11.3807706\n10.8388429\n-4.556101\n-0.2353506\n1.0616370\n1.8722904\n4.2907091\n-2.4827531\n-5.7486118\n3.2385323\n3.4846426\n1.298343\n2.8100805\n4.2519181\n-1.8560000\n4.9559298\n3.5121412\n-3.1172622\n-4.8691203\n-7.0946331\n-7.5602092\n-3.0801421\n-5.8546164\n-2.2928990\n-1.4201750\n-2.1490260\n-2.0374218\n5.2978722\n4.1143296\n2.4964750\n-1.707420\n1.1130026\n-1.4592996\n-3.5824727\n-5.0246880\n-1.5280913\n5.3745849\n-3.4539094\n-4.4424357\n-7.0144081\n2.4888395\n-3.4601753\n5.7682678\n-0.5639159\n1.7719846\n1.8693498\n0.3915249\n4.3354162\n0.6329579\n-4.7893166\n2.355965\n-2.9944984\n0.9746733\n2.1831488\n1.8503339\n5.7226143\n-3.5455370\n-8.8605653\n\n\nCanary\n28.017936\n-9.711131\n1.8152580\n4.152567\n4.6799648\n-18.097735\n-9.7935685\n-5.7242762\n-9.117048\n-6.4045831\n-7.1737961\n3.7290718\n-4.2616369\n-1.8423486\n9.0168055\n2.552417\n10.890162\n2.2268742\n3.5813905\n-10.7686105\n0.9729619\n3.9552726\n9.7763952\n4.992721\n9.647722\n3.4270408\n4.9922738\n-3.0303735\n0.5653330\n4.8307165\n2.0812984\n-1.3337595\n5.0110176\n3.8795221\n1.9729774\n3.114877\n5.6659330\n-0.3845149\n-6.0508167\n-2.505897\n3.2621366\n-8.5092034\n0.2695424\n8.999274\n6.0097419\n-8.0452811\n-6.2318201\n-2.956672\n-8.0912288\n10.2832121\n-8.5757066\n2.0593362\n5.641815\n-1.6180890\n8.4030088\n7.7012418\n12.3991068\n1.103800\n-2.8683962\n0.4302879\n-1.0158241\n-3.5594815\n-4.2587670\n-6.4801574\n5.638990\n6.314367\n-0.0669196\n-1.348402\n7.5563033\n-10.8832919\n3.7249564\n5.189974\n-11.1306659\n8.7928820\n2.8876223\n4.541898\n-2.3243570\n-3.231420\n-0.4968872\n3.5529275\n2.423911\n-3.5899662\n-3.6125600\n-8.406667\n1.0438244\n-3.3558637\n-2.0500128\n-3.263322\n-1.852730\n9.0978358\n8.7565410\n-1.1946464\n4.118265\n1.7952097\n-4.1285179\n-1.918781\n0.3452547\n-0.7890635\n0.3350979\n1.2202142\n4.4832191\n-6.2956360\n1.7460564\n6.924928\n4.3928950\n-1.8558423\n4.9384971\n-3.5288743\n3.8039616\n-8.2919066\n3.7334474\n2.7497758\n3.204420\n2.333834\n-0.1390349\n5.446273\n-0.7796235\n1.3121761\n2.4666003\n1.0968973\n-1.472856\n-0.4516848\n-1.731479\n1.297061\n7.8931945\n-7.8552598\n-0.9213307\n-5.1829622\n1.4432436\n-3.8580089\n4.6614600\n-0.4314485\n2.3888149\n-6.777383\n-0.9086408\n-0.2654383\n0.5617019\n4.655535\n0.0676956\n5.3238419\n-1.3010668\n-1.0045344\n2.7937679\n-1.5368508\n-0.3815586\n-0.8088542\n-2.0564964\n-0.5237565\n3.4549695\n4.1438910\n2.4115136\n3.6730358\n2.9372325\n0.8475813\n-0.5392527\n-5.5385215\n-0.2500064\n7.1198768\n3.138690\n5.7205305\n-3.2763185\n-1.6993905\n0.0370527\n4.1311516\n5.1184535\n-2.2756837\n0.6948147\n0.1812992\n6.260929\n1.2352646\n2.8668889\n2.6751753\n1.6192647\n2.6606578\n0.5162005\n3.506697\n-0.3387404\n4.1307986\n-3.5253067\n2.5762092\n0.8551627\n2.6942940\n0.2475203\n-3.6053549\n3.826843\n-1.4177310\n1.6054711\n-1.7910695\n-6.5983420\n-0.3165268\n-2.0444003\n3.5619750\n4.1132019\n-1.5378804\n-6.9456183\n7.5385905\n8.1937005\n4.2524765\n-1.7145109\n-1.0758415\n-1.455281\n6.5756390\n5.8934214\n-5.505482\n1.5139850\n4.7889436\n1.2251997\n3.1443918\n1.363844\n5.646660\n-4.3012001\n8.7334368\n-1.7210364\n-0.5361291\n1.1349723\n-5.3463749\n-4.1545847\n-4.0710196\n1.3033721\n-0.4549559\n2.4057862\n4.3525330\n0.9562371\n1.3003306\n-0.9387649\n-1.5592181\n1.0699544\n-0.3185847\n2.1227863\n2.1451704\n1.2627861\n-1.8852066\n-0.8324722\n4.130666\n0.0788831\n-2.3861298\n3.3290750\n2.4536828\n-0.7881028\n6.8388531\n2.8891909\n2.3766424\n3.7569247\n-2.4993799\n1.846241\n-1.8720644\n3.6760059\n-0.0793287\n0.9553124\n3.5302088\n2.8229766\n1.9054433\n2.0903841\n2.126011\n-1.8324137\n-2.5411060\n2.2986315\n4.5185081\n2.6298880\n-1.7034878\n0.1103810\n2.1441119\n-2.3426218\n-1.4942959\n6.0660064\n0.2770576\n-4.2644216\n4.4382470\n-4.1272113\n1.4978426\n-4.3379426\n-2.3860744\n-2.743482\n8.6801296\n0.4912353\n-3.4577271\n-4.6427416\n-6.0232588\n-1.2000095\n1.2915031\n1.7547299\n0.5286464\n-3.7662894\n4.7920103\n1.9458703\n0.2371975\n-1.0947628\n-0.3974943\n-2.5085937\n-0.5398389\n0.2735771\n1.5247094\n-3.624901\n2.3300559\n-2.0270701\n1.2641799\n-0.9181785\n9.4161516\n4.1023113\n-1.0459135\n\n\nSunfish\n2.671976\n-1.634745\n1.0092547\n1.971743\n-0.0659806\n-4.485483\n-0.6157394\n-0.4446398\n-2.135539\n-0.1855337\n-0.3653675\n-0.9757169\n0.9833536\n-0.4373506\n-0.6857746\n1.395239\n3.526766\n0.5293000\n0.4209848\n-3.4104846\n-3.9299972\n-0.4856075\n1.1505664\n2.247154\n1.291273\n0.4333016\n0.5757962\n0.7421109\n1.3637568\n0.4675282\n-1.1996607\n-1.1199203\n-0.5715238\n0.7483034\n-0.2462562\n1.295735\n-2.1481787\n2.2357764\n-0.1000319\n-1.334179\n-0.4678468\n0.6883993\n0.7824726\n1.986898\n0.1823848\n0.5900189\n-0.6196374\n-1.197890\n-0.6397997\n1.8739895\n-0.6986206\n0.3264926\n-1.106825\n-0.7986667\n-0.7942869\n0.3534946\n1.5704717\n1.099842\n-0.4712961\n-1.9296982\n-1.2794992\n-0.6377849\n-0.4841883\n-0.7619484\n-1.848736\n1.861377\n-3.0369215\n1.040914\n-0.8948211\n0.5964522\n-2.1729557\n-2.847560\n0.3661112\n0.7198424\n-0.2592527\n-1.005021\n0.9121147\n-1.991298\n-4.0090396\n0.9573294\n0.837238\n1.5041342\n0.5979597\n-1.329158\n0.1356189\n0.1137635\n0.5712501\n1.144023\n-2.901016\n1.7090371\n0.1723399\n0.7930372\n-1.302795\n-0.1576198\n0.6288434\n1.809818\n0.9966588\n0.1851948\n-0.9818111\n-0.5018535\n0.6628568\n0.2434079\n0.3056738\n-1.179871\n1.0023197\n1.9586813\n-0.2391551\n-0.5478282\n0.4052252\n0.1050347\n0.0608304\n0.6921589\n0.090562\n1.737157\n-0.1224932\n1.382547\n-0.0669635\n0.6275334\n1.1357830\n0.7212117\n1.332176\n-0.1708254\n1.631695\n1.046881\n2.6477299\n-0.7323800\n0.2450768\n1.0407605\n-0.0638638\n0.0362075\n-0.7602249\n-0.4514443\n1.0970385\n-2.058717\n-0.4772066\n0.6891971\n-0.5252515\n1.320807\n2.0855522\n-0.5308727\n-0.5414442\n0.8132779\n0.8060741\n-0.7820840\n-0.0974855\n-1.1516975\n-0.4544318\n-0.1437671\n1.0149376\n-0.7442971\n0.2365992\n0.5018176\n-0.0623840\n0.7175603\n-1.4370608\n2.1816251\n-1.1740033\n-0.1587521\n-1.308936\n1.0963224\n0.9416279\n0.6446517\n-0.7079844\n-1.3376836\n0.8534419\n-0.1928021\n-0.4729082\n-0.6972626\n-0.595974\n0.9460619\n-1.1913831\n0.1201412\n0.0858613\n-0.0684709\n0.8437920\n-0.956026\n0.9757848\n-0.0287358\n0.2485583\n0.2431551\n-1.2416189\n0.0169046\n-0.5596322\n0.2480171\n-0.637270\n-0.4266425\n-0.8717179\n2.0318199\n0.2985858\n-0.8279377\n0.2846029\n0.8176092\n0.2886955\n-1.0247478\n1.3453494\n-1.0061067\n-0.0779308\n-0.2040882\n-0.9363782\n0.6747263\n1.141463\n-1.2624069\n-0.8103713\n1.212891\n0.0998399\n0.9855938\n0.7333348\n-0.8901834\n1.282947\n-2.092871\n-0.3857082\n-0.4879458\n0.3354572\n0.5785333\n-0.8967905\n1.6569907\n-0.3487997\n-0.9604216\n0.8301921\n0.1801073\n-2.2939194\n-1.8618764\n-0.5685490\n-1.1015050\n0.8148482\n0.4927997\n-1.7475145\n2.6695286\n-1.1713861\n-1.5447938\n-1.7871431\n0.0911204\n-0.0722668\n-1.870259\n-0.3034667\n0.4476403\n-2.0470996\n0.2271746\n-1.2681026\n-0.3287547\n-0.2580326\n-0.7302849\n-0.7232476\n-0.1447716\n1.142121\n0.0259262\n0.9386625\n0.0660591\n2.2029548\n0.5374430\n0.2409948\n0.9285480\n-0.3375535\n-1.890040\n0.5197283\n0.5158098\n0.5181227\n0.6476375\n1.0858086\n0.2762813\n-0.1479446\n0.2331174\n-0.1243531\n0.7791777\n-0.6929186\n0.3517946\n1.4635512\n0.2301916\n1.3337702\n0.2979985\n-0.4120448\n-0.3105052\n1.233750\n-1.7594159\n0.6044447\n0.8377204\n-1.4883090\n-1.3467319\n0.2149829\n0.6559219\n-0.8600177\n0.6556712\n-0.1650155\n1.9970446\n-0.4196055\n0.4368345\n-1.2926978\n-0.8387044\n-0.4728054\n0.0600773\n-0.8078840\n-0.8101973\n1.032789\n0.0913317\n-0.2479691\n1.2400970\n-0.2620524\n-0.4653997\n-0.6517328\n0.2916859\n\n\nSalmon\n45.366639\n-14.246932\n0.1114514\n19.613487\n2.7339021\n-37.359271\n-15.1653864\n-15.6177393\n-28.997250\n-3.1877566\n-6.6190532\n-15.9110693\n-0.7991651\n-1.2207791\n25.7337867\n18.073711\n18.250084\n10.8358750\n23.4028315\n-6.8574182\n-28.0333926\n-6.6615900\n11.7924924\n-2.439194\n15.361486\n2.6333636\n-18.3236103\n20.7517419\n-38.2821673\n-21.7261770\n-8.9726795\n-3.8014499\n23.8414364\n-10.6582933\n-32.0685345\n10.280295\n0.1439898\n-5.1115406\n7.0460971\n-12.619112\n-15.9090216\n5.6932943\n0.0775648\n6.647813\n-15.5498536\n-11.8216543\n-9.0334169\n-1.171663\n3.2620234\n11.2080167\n-0.9551670\n2.5643337\n-17.841022\n-7.5145103\n-21.0402972\n0.2247946\n-2.1811709\n6.188044\n2.9438778\n-5.0685389\n-15.7523157\n16.3098186\n11.8173905\n-9.4073700\n-6.414177\n10.251040\n-12.0886915\n3.541542\n-10.0117884\n1.7279323\n-13.3995545\n-24.430764\n14.0453707\n-10.6955862\n8.0365074\n-1.883903\n12.6877520\n-6.894571\n-22.7189243\n4.7472505\n4.395364\n-2.1284084\n5.7227501\n-2.650241\n9.1897555\n2.1506669\n9.4490531\n2.812082\n-20.816413\n8.5460037\n0.2949648\n0.7946690\n-10.656108\n9.9514356\n-12.6217186\n16.278604\n0.8662642\n2.8323808\n5.5195939\n0.5749495\n-13.1863747\n2.6751923\n-13.9624171\n-11.584639\n-15.9321708\n12.5074162\n-3.9394292\n-3.4320179\n3.9509412\n8.7203613\n-0.9916812\n4.4278251\n-5.484492\n5.542930\n5.9595888\n-1.846622\n-2.2214505\n-9.5353523\n0.6262246\n-2.1146753\n6.978190\n2.4015731\n-2.978400\n23.274266\n10.1745679\n-12.6547850\n8.5752611\n20.8520893\n-4.7983872\n3.8165092\n1.6916782\n-4.5252281\n0.3917101\n-9.628118\n-10.0832436\n16.4615853\n-2.9438570\n4.273337\n9.3487661\n-9.0246737\n-8.1324818\n9.3575397\n-5.6498191\n3.4268754\n-7.4079411\n-5.2582906\n-3.8441174\n5.5187426\n2.6453734\n-6.7113518\n6.7072824\n-7.0429745\n3.1472481\n-0.6532618\n-5.3207453\n0.4442541\n-4.4238417\n-8.6722421\n-20.286674\n16.6801413\n6.2967667\n12.9163128\n2.5236117\n-16.1339405\n3.9601234\n7.9584559\n-3.5261174\n-4.7358231\n-6.021531\n1.3814217\n-9.8024166\n5.5291360\n5.4079389\n-6.4259406\n7.3904302\n-6.307354\n1.5624471\n9.8609787\n-3.2719547\n-3.8165110\n-6.0230060\n2.2525619\n-9.1581446\n0.5150933\n-3.109665\n-12.3073288\n0.1718954\n8.2760865\n1.0782718\n-4.5277518\n3.5575192\n8.7853295\n-7.3308001\n-10.3578341\n3.8029453\n-0.7960860\n-4.5135825\n2.4909701\n-5.2377565\n2.8056909\n4.187349\n2.1199821\n-14.5778237\n-5.288184\n0.7636763\n1.0684937\n11.4446640\n-3.8809239\n-1.471044\n-5.762816\n9.2540044\n-3.1231925\n3.6703762\n-2.7950426\n-7.2013671\n4.9203092\n-2.9570233\n-5.5224954\n5.8207086\n1.3965562\n-22.8025385\n-9.1081463\n-7.9102714\n-4.8906529\n-4.1812692\n12.2521930\n-21.5515863\n11.7752264\n-6.4152903\n-4.5245436\n-15.0166304\n4.7185851\n-2.0311982\n-15.313263\n1.9812127\n3.7187549\n-19.9333908\n-2.4657861\n-10.5151205\n5.2766498\n-0.7492269\n-4.5585811\n5.6919522\n3.2917922\n14.842447\n1.6301066\n2.8435282\n1.9368151\n10.4675541\n-1.6156167\n3.1438421\n3.1220410\n-7.2900231\n-11.184279\n7.0010860\n6.1452208\n1.4225875\n9.5060338\n7.1725843\n10.3827746\n-4.0648451\n1.0313897\n-2.1608972\n5.0647489\n4.5756690\n7.6646325\n14.0237157\n5.6951812\n9.2584501\n4.4598100\n-15.8358166\n-3.1563305\n1.917434\n-17.5611094\n17.6697035\n1.3399241\n-2.5608145\n-11.7418063\n3.3866112\n4.1455907\n-7.2857001\n12.7853620\n-0.8977347\n9.5451436\n-5.8540317\n-1.8019472\n-7.1901684\n-7.3223563\n10.1887605\n-1.8333372\n2.3858847\n6.8776140\n13.609219\n3.4711277\n2.3469568\n12.4018618\n-3.9063538\n-5.5250340\n-0.2188451\n0.2033760\n\n\n\n\n\nOf course, the raw numbers alone are not especially easy to interpret. The graph below may make it a bit easier to see how items in the same category have vector representations with similar “shapes” whereas items from different categories have different “shapes”. That said, since these vectors have 300 dimensions, I only plot the first 30 entries!\n\n\nCode\ntoPlot &lt;- c()\nfor (i in 1:nrow(lsa_reps_examples)) {\n    toPlot &lt;- rbind(\n        toPlot,\n        tibble(item = rownames(lsa_reps_examples)[i], index = 1:30, val = lsa_reps_examples[i,1:30])\n    )\n}\n\ntoPlot %&gt;%\n    mutate(item = factor(item, levels = concept_names)) %&gt;%\n    mutate(category = factor(item, levels = concept_names, labels = category_names)) %&gt;%\n    mutate(exemplar = factor(item, levels = concept_names, labels = rep(c(\"A\", \"B\"), length(concept_names) / 2))) %&gt;%\n    ggplot(aes(x = index, y = val, color = item)) +\n    geom_line() +\n    facet_wrap(\"category\")\n\n\n\n\n\n\n\n\n\nOf course, this is all just based on our visual impressions—we will now explore different ways of operationalizing similarity between representations. We will then see how to incorporate similarity into models of behavior.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "vector_reps.html#similarity-between-distributed-representations",
    "href": "vector_reps.html#similarity-between-distributed-representations",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "10.3 Similarity between distributed representations",
    "text": "10.3 Similarity between distributed representations\nAs noted earlier, different kinds of representations enable different ways of operationalizing the similarity between those representations. This is important because similarity is a core construct in many cognitive models, like we saw with the EBRW. Indeed, the EBRW’s approach to similarity is the first we will consider.\n\n10.3.1 Transformed distance\nRecall that the EBRW operationalized similarity as an exponential function of distance between items. Specifically, the similarity \\(s_{ij}\\) between representations of items \\(i\\) and \\(j\\) was defined as \\[\ns_{ij} = \\exp \\left(-c d_{ij} \\right)\n\\] where \\(c\\) was a sensitivity parameter and \\(d_{ij}\\) is the distance between \\(\\mathbf{x_i}\\), the vector representing item \\(i\\), and \\(\\mathbf{x_j}\\), the vector representing item \\(j\\): \\[\nd_{ij} = \\left( \\sum_{k = 1}^D w_k \\left| x_{ik} - x_{jk} \\right|^p \\right)^{\\frac{1}{p}}\n\\] where \\(D\\) is the number of dimensions in each representation, \\(w_k\\) is the weight given to dimension \\(k\\), and \\(p\\) is a new parameter that we just added for this chapter. The new parameter \\(p\\) makes the distance formula more general. When \\(p = 2\\), we get the Euclidean distance we used in the last chapter. But \\(p\\) can, in principle, be any nonnegative number; this more general distance formula is known as a (Minkowski distance)[https://en.wikipedia.org/wiki/Minkowski_distance].\nThe choice of \\(p\\) reflects how differences in different dimensions contribute to the overall distance. When \\(p = 2\\), corresponding to Euclidean distance, the distance (and therefore similarity) between representations only depends on how far apart their vector representations are, not their orientation relative to the dimensions of the space. Another common choice of \\(p\\) in cognitive models is \\(p = 1\\), corresponding to the “city block” or “taxicab” distance. When \\(p = 1\\), the distance is the sum of the absolute differences between vector representations. As a result, distance (and therefore similarity) depends on how the two items are oriented with respect to the dimensions of the space.\nWe can visualize the effect of different choices of \\(p\\) by drawing contours of equal distance. We can imagine assigning item \\(i\\) to have a vector representation of \\((0, 0)\\) and then consider the all the possible positions of item \\(j\\) that would result in a distance \\(d_{ij} = 1\\). That’s what is shown in the graph below:\n\n\nCode\nexpand_grid(p = c(0.25, 0.5, 1, 2, 4, 8), theta = seq(0, 2*pi, length.out = 501)) %&gt;%\n    mutate(x = cos(theta)) %&gt;%\n    mutate(y = sign(sin(theta)) * (1 - abs(x)^p)^(1 / p)) %&gt;%\n    ggplot(aes(x = x, y = y, color = factor(p), group = p, linewidth = factor(p))) +\n    geom_path() +\n    coord_equal() +\n    scale_linewidth_manual(values = c(\"0.25\" = 0.5, \"0.5\" = 0.5, \"1\" = 1.5, \"2\" = 1.5, \"4\" = 0.5, \"8\" = 0.5)) +\n    labs(x = expression(x[j1]), y = expression(x[j2]), color = \"p\", linewidth = \"p\")\n\n\n\n\n\n\n\n\n\nWhen \\(p = 2\\), the contour of equal distance is a circle—distance is irrespective of the orientation relative to the two dimensions of the space. When \\(p = 1\\), the contour of equal distance is a diamond—distance is the sum of the differences on each dimension. As noted above, most cognitive models adopt either \\(p = 1\\) or \\(p = 2\\), but other values of \\(p\\) are entirely possible. When \\(p\\) gets really big, the contour of equal distance approaches a square—distance depends on the maximum difference. When \\(p\\) gets really small, the contour of equal distance approaches a “star”—distance depends on the minimum difference.\nA major conceptual point to take from the preceding discussion about the Minkowski distance parameter \\(p\\) is that, whenever \\(p \\neq 2\\), we need to take the dimensions of the space seriously. When \\(p \\neq 2\\), distance depends on which dimensions exhibit which differences. The resulting distance is only interpretable if those dimensions are interpretable, in turn. As a result, this approach to similarity is best suited to separable distributed representations.\nFor similar reasons, attention weights \\(w_k\\) only make sense to apply to separable distributed representations. If the elements of a distributed representation cannot be interpreted as referring to different attributes/features, as with an integral distributed representation, it makes little sense to assign those elements different attention weights. Of course, there is nothing stopping you from building such a model—it just will not have a very clear cognitive interpretation.\nTo give a concrete example of how the transformed distance approach to similarity can be implemented in R, we can adapt some of the code we wrote for the EBRW. This example uses the size and color representations for the eight concepts used in the examples in the previous section.\n\n\nCode\n# List names of items and attributes\nconcept_names &lt;- c(\"Pine\", \"Oak\", \"Rose\", \"Daisy\", \"Robin\", \"Canary\", \"Sunfish\", \"Salmon\")\nsep_attribute_names &lt;- c(\"size\", \"hue\", \"chroma\", \"lightness\")\n\n# Define matrix of representations\nseparable_distributed_reps &lt;- matrix(c(\n    50, 131, 36, 27,\n    40, 20, 60, 16,\n    0.1, 3, 58, 79,\n    0.2, 52, 100, 50,\n    0.3, 9, 63, 38,\n    0.1, 60, 100, 63,\n    0.5, 32, 100, 59,\n    1, 5, 99, 71\n), nrow = 8, ncol = length(alt_attribute_names), byrow = TRUE, dimnames = list(concept_names, alt_attribute_names))\n\n# The \"c\" parameter representing sensitivity\nsensitivity &lt;- 0.01\n\n# The \"p\" parameter representing the Minkowski parameter\nminkowski_p &lt;- 1\n\n# These are the weights given to each of the four dimensions.\nattention_weight &lt;- c(1, 1, 1, 1)\n# By convention, these weights are constrained to sum to 1.\nattention_weight &lt;- attention_weight / sum(attention_weight)\n\n# First, define an empty distance matrix\ndistance &lt;- matrix(0, nrow = nrow(separable_distributed_reps), ncol = nrow(separable_distributed_reps), dimnames = list(concept_names, concept_names))\n\n# Fill in each entry in the distance matrix \nfor (i in 1:nrow(separable_distributed_reps)) {\n    for (j in 1:nrow(separable_distributed_reps)) {\n        distance[i, j] &lt;- sum(attention_weight * abs(separable_distributed_reps[i,] - separable_distributed_reps[j,])^minkowski_p)^(1 / minkowski_p)\n    }\n}\n\nsimilarity &lt;- exp(-sensitivity * distance)\n\nprint(round(similarity, 2))\n\n\n        Pine  Oak Rose Daisy Robin Canary Sunfish Salmon\nPine    1.00 0.68 0.53  0.58  0.59   0.58    0.54   0.49\nOak     0.68 1.00 0.74  0.69  0.83   0.66    0.71   0.69\nRose    0.53 0.74 1.00  0.74  0.88   0.75    0.80   0.88\nDaisy   0.58 0.69 0.74  1.00  0.79   0.95    0.93   0.84\nRobin   0.59 0.83 0.88  0.79  1.00   0.75    0.82   0.83\nCanary  0.58 0.66 0.75  0.95  0.75   1.00    0.92   0.85\nSunfish 0.54 0.71 0.80  0.93  0.82   0.92    1.00   0.90\nSalmon  0.49 0.69 0.88  0.84  0.83   0.85    0.90   1.00\n\n\nGo ahead, try it out yourself! You may notice that the sensitivity parameter is pretty small, see what happens if you increase it. In fact, that will be an exercise for us later!\n\n\n10.3.2 Dot product\nThe dot product or inner product is a way of directly computing the similarity between two vectors, without first computing a distance between them. While transformed distance is the most common approach to modeling similarity in the GCM/EBRW, dot products have been used a lot in other models of memory, notably the Theory Of Distributed Associative Memory (TODAM; Murdock (1982)).\nThe dot product between two vectors is sum of the products of their elements. To get formal about it, the dot product between vector representations \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\) is often written as \\(\\mathbf{x_i} \\cdot \\mathbf{x_j}\\) (can you guess why this is called a dot product?). The dot product is defined as: \\[\n\\mathbf{x_i} \\cdot \\mathbf{x_j} = \\sum_{k = 1}^D x_{ik} x_{jk}\n\\]\nIntuitively, the dot product quantifies the amount of overlap between two representations. Any time the two vectors have elements that are both large and both of the same sign, their dot product will be larger. That’s why the dot product is a useful way to operationalize similarity.\nTo make this concrete, let’s consider a pair of two-dimensional vector representations (so \\(D = 2\\) in this example). We will assume that \\(x_{11} = x_{21} = 1\\), i.e., that the first element of each vector representation equals 1. The second elements of each representation (\\(x_{12}\\) and \\(x_{22}\\)) will vary between -2 and 2. The colors in the graph below indicates the value of the dot product for each combination of values of $x_{21}The chunk of code below varies the elements of these vectors so you can see how their dot product is influenced by those changes.\n\n\nCode\nexpand_grid(x11 = 1, x12 = seq(-2, 2, length.out = 11), x21 = 1, x22 = seq(-2, 2, length.out = 11)) %&gt;%\n    mutate(dot_product = x11 * x21 + x12 * x22) %&gt;%\n    ggplot(aes(x = x12, y = x22, fill = dot_product)) +\n    geom_raster() +\n    scale_fill_gradient2() +\n    coord_equal() +\n    labs(x = expression(x[12]), y = expression(x[22]), fill = expression(bold(x[1]) %.% bold(x[2])))\n\n\n\n\n\n\n\n\n\nNotice that the dot product is large and positive (i.e., very blue) whenever \\(x_{12}\\) and \\(x_{22}\\) are large and of the same sign, which happens in the upper right and lower left quadrants of the graph above. To the extent that \\(x_{12}\\) and \\(x_{22}\\) are large but of different signs, the dot product becomes negative (the red regions in the upper left and lower right quadrants). The dot product thus quantifies the degree to which the elements of each representation have the same sign, weighted by the magnitude of the elements of each representation.\nWhile dot products can be computed with continuous values, they can also be computed for binary values just as well. For any element that contains a zero in the vectors being compared, that element will contribute zero to the dot product. Therefore, the dot product between representations that consist of ones and zeros is the number of elements for which both representations contain a one.\nFor example, using the concept features from earlier, the following is a matrix where each entry gives the dot product between the representations of the items in the corresponding rows/columns.\n\n\nCode\nconcept_names &lt;- c(\"Pine\", \"Oak\", \"Rose\", \"Daisy\", \"Robin\", \"Canary\", \"Sunfish\", \"Salmon\")\n\nattribute_names &lt;- c(\"can_grow\", \"is_living\", \"has_roots\", \"has_bark\", \"is_big\", \"has_branches\", \"is_green\", \"has_leaves\", \"has_petals\", \"is_pretty\", \"is_red\", \"is_yellow\", \"can_move\", \"has_feathers\", \"can_fly\", \"has_wings\", \"can_sing\", \"can_swim\", \"has_gills\", \"has_scales\")\n\nconcept_attributes &lt;- matrix(c(\n    1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1\n), nrow = 8, ncol = length(attribute_names), byrow = TRUE, dimnames = list(concept_names, attribute_names))\n\ntcrossprod(concept_attributes)\n\n\n        Pine Oak Rose Daisy Robin Canary Sunfish Salmon\nPine       7   6    3     3     2      2       2      2\nOak        6   7    4     4     2      2       2      2\nRose       3   4    7     6     3      2       2      3\nDaisy      3   4    6     7     2      3       3      2\nRobin      2   2    3     2     7      6       3      4\nCanary     2   2    2     3     6      8       4      3\nSunfish    2   2    2     3     3      4       7      6\nSalmon     2   2    3     2     4      3       6      7\n\n\nIt is worth taking a look at the code for this one, since R makes it easy to compute the dot products between many vectors simultaneously using the tcrossprod function, as illustrated in the final line of the code chunk above. R has two functions that implement particular forms of (matrix multiplication)[https://en.wikipedia.org/wiki/Matrix_multiplication], crossprod and tcrossprod. Specifically, tcrossprod returns the cross-product of an \\(N \\times M\\) matrix \\(A\\) with the transpose of a \\(K \\times M\\) matrix \\(B\\). The “transpose” of a matrix is what you get when you swap its rows and columns. So the transpose of matrix \\(B\\) has dimension \\(M \\times K\\). The result is an \\(N \\times K\\) matrix where the entry in the \\(i\\)th row and \\(j\\)th column is the dot product of the \\(i\\)th row of \\(A\\) and the \\(j\\)th row of \\(B\\). This is illustrated below.\n\n\nCode\nA &lt;- matrix(rnorm(n = 15), nrow = 3, ncol = 5)\nB &lt;- matrix(rnorm(n = 20), nrow = 4, ncol = 5)\n\nprint(A)\n\n\n          [,1]       [,2]       [,3]       [,4]       [,5]\n[1,] -1.042958 -0.4140553  1.3762569 -1.2603923  0.1210855\n[2,] -1.070853 -0.3916844 -0.9313825  0.7158927 -2.6305672\n[3,]  0.379089  1.5611897  1.9640299  0.7494422 -0.8950186\n\n\nCode\nprint(B)\n\n\n           [,1]       [,2]       [,3]      [,4]       [,5]\n[1,] -1.1570559 -0.1226359  0.7488086 -2.455725 0.80124750\n[2,]  0.5232695  1.7441242 -0.8286818 -1.545715 0.05190826\n[3,]  0.1259115 -1.7034857  1.8937240 -0.436462 0.24459708\n[4,] -1.0263656 -1.2446303  1.0119758  1.201336 0.54842031\n\n\nCode\ntcrossprod(A, B)\n\n\n          [,1]        [,2]       [,3]       [,4]\n[1,]  5.480287 -0.45389825  3.7599981 1.53079186\n[2,] -3.276126 -1.71478563 -2.1872745 0.06142366\n[3,] -1.716958  0.08883569  0.5615761 0.06484820\n\n\nWhen you call tcrossprod with just a single matrix, R uses that same matrix for both \\(A\\) and \\(B\\). For example:\n\n\nCode\ntcrossprod(A)\n\n\n           [,1]       [,2]      [,3]\n[1,]  4.7565358 -1.2236171 0.6082522\n[2,] -1.2236171  9.6000030 0.0442214\n[3,]  0.6082522  0.0442214 7.8011570\n\n\nCode\ntcrossprod(B)\n\n\n           [,1]      [,2]      [,3]       [,4]\n[1,]  8.5871127  2.397573  2.749072 -0.4127539\n[2,]  2.3975730  6.394423 -3.787157 -5.3749163\n[3,]  2.7490719 -3.787157  6.754235  3.5171862\n[4,] -0.4127539 -5.374916  3.517186  5.3705980\n\n\nSo to get back to talking about dot products between vector representations, tcrossprod(concept_attributes) returns a matrix where the entry in the \\(i\\)th row and \\(j\\)th column is the dot product between the \\(i\\)th row of concept_attributes and the \\(j\\)th row of concept_attributes. Convenient!\nAs we saw, the dot product can be used to quantify similarity between separable distributed vector representations. It can also be used to quantify similarity between integral distributed vector representations. For example, this is the matrix of dot-product similarities between the integral representations of the concepts in our running example:\n\n\nCode\nknitr::kable(tcrossprod(lsa_reps_examples))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPine\nOak\nRose\nDaisy\nRobin\nCanary\nSunfish\nSalmon\n\n\n\n\nPine\n38573.968\n37331.6943\n18080.1644\n3954.26442\n8252.5993\n4161.7246\n1012.64213\n12580.369\n\n\nOak\n37331.694\n59365.5215\n31061.6833\n5111.06152\n11119.6447\n3805.2614\n703.56230\n14579.626\n\n\nRose\n18080.164\n31061.6833\n83666.0058\n9616.77767\n22586.7398\n6677.3640\n544.37714\n12069.413\n\n\nDaisy\n3954.264\n5111.0615\n9616.7777\n3147.26980\n5174.1907\n1266.2499\n92.93532\n1729.109\n\n\nRobin\n8252.599\n11119.6447\n22586.7398\n5174.19071\n25216.0414\n4542.8128\n307.62160\n4887.937\n\n\nCanary\n4161.725\n3805.2614\n6677.3640\n1266.24994\n4542.8128\n6624.3994\n277.54518\n1760.961\n\n\nSunfish\n1012.642\n703.5623\n544.3771\n92.93532\n307.6216\n277.5452\n405.72158\n2192.350\n\n\nSalmon\n12580.369\n14579.6264\n12069.4125\n1729.10943\n4887.9368\n1760.9615\n2192.34977\n33261.839\n\n\n\n\n\n\n\n10.3.3 Cosine similarity\nAs noted above, the dot product is sensitive to the magnitude of the values in the vector representations. This could be important if magnitude represents something important in the context of our model. For example, just like the EBRW allows for a “strength” parameter that can multiplicatively scale the similarity between two representations, we could imagine that the magnitude of the entries in a vector represents the “strength” or “salience” of the item that vector represents.\nIn some models, though, the magnitudes are irrelevant—instead an item is represented by the pattern of relative values in the vector. We can still use the dot product to quantify similarity, but we will first need to normalize each vector representation. Specifically, we will normalize the vectors such that their dot products with themselves are equal to 1. Referring back to the definition of the dot product above, the dot product of a vector with itself is the sum of the squares of the entries in the vector. So if we divide each entry in a vector by the square root of the sum of the squared entries, we obtain our normalized vector representation.\nWe can see how this works by imagining that we have two integral distributed vector representations, which the code below randomly generates and then shows.\n\n\nCode\nx_1 &lt;- rnorm(n = 10, mean = 0, sd = 1)\nx_2 &lt;- rnorm(n = 10, mean = 0, sd = 1)\n\nknitr::kable(rbind(x_1, x_2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_1\n1.4623004\n-0.4582554\n-1.3126406\n-0.7356256\n0.6091427\n0.1927802\n-0.0306855\n0.5532889\n0.7257781\n1.088871\n\n\nx_2\n-0.9597082\n0.6364972\n0.4518392\n-0.3443309\n-0.1859800\n-1.0846488\n0.3763883\n-1.6267809\n0.6824552\n-1.126632\n\n\n\n\n\nTo create normalized versions of these representations, we divide them by the square root of the sum of their squared entries:\n\n\nCode\nx_1_norm &lt;- x_1 / sqrt(sum(x_1^2))\nx_2_norm &lt;- x_2 / sqrt(sum(x_2^2))\n\nknitr::kable(rbind(x_1_norm, x_2_norm))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_1_norm\n0.5511184\n-0.1727094\n-0.4947139\n-0.2772459\n0.2295764\n0.0726559\n-0.0115649\n0.2085260\n0.2735345\n0.4103787\n\n\nx_2_norm\n-0.3532000\n0.2342491\n0.1662897\n-0.1267236\n-0.0684459\n-0.3991817\n0.1385216\n-0.5987017\n0.2511630\n-0.4146329\n\n\n\n\n\nTo see the effect of this normalization on the dot products, let’s compute the dot products between the unnormalized vectors and for the normalized ones:\n\n\nCode\n# Dot product between unnormalized x_1 and itself\nsum(x_1 * x_1)\n\n\n[1] 7.040174\n\n\nCode\n# Dot product between unnormalized x_2 and itself\nsum(x_2 * x_2)\n\n\n[1] 7.383073\n\n\nCode\n# Dot product between unnormalized x_1 and x_2\nsum(x_1 * x_2)\n\n\n[1] -4.000327\n\n\nCode\n# Dot product between normalized x_1 and itself\nsum(x_1_norm * x_1_norm)\n\n\n[1] 1\n\n\nCode\n# Dot product between normalized x_2 and itself\nsum(x_2_norm * x_2_norm)\n\n\n[1] 1\n\n\nCode\n# Dot product between normalized x_1 and x_2\nsum(x_1_norm * x_2_norm)\n\n\n[1] -0.5548623\n\n\nBy normalizing the vectors so that the dot product with themselves is 1, we can treat the result as a measure of relative similarity between vector representations. Since similarity is greatest between a representation and itself, the dot product between normalized vector representations has an upper bound of 1. The dot product also has a lower bound of -1, which is achieved when the two vectors have exactly opposite entries:\n\n\nCode\nsum(x_1_norm * (-x_1_norm))\n\n\n[1] -1\n\n\nJust for completeness, let’s see how we can use the tcrossprod trick in this example:\n\n\nCode\n# Matrix of dot products for unnormalized representations\ntcrossprod(rbind(x_1, x_2))\n\n\n          x_1       x_2\nx_1  7.040174 -4.000327\nx_2 -4.000327  7.383073\n\n\nCode\n# Matrix of dot products for normalized representations\ntcrossprod(rbind(x_1_norm, x_2_norm))\n\n\n           x_1_norm   x_2_norm\nx_1_norm  1.0000000 -0.5548623\nx_2_norm -0.5548623  1.0000000\n\n\nThis might remind you of something—the Pearson correlation coefficient, which also ranges between 1 and -1 and measures the degree of correspondence between two set of numbers. Indeed, the normalized dot product can be interpreted in exactly the same way as the correlation coefficient! They are not strictly identical, however, as the correlation coefficient involves subtracting out the mean of each set of numbers, which we do not do to get the normalized dot product.\nThe normalized dot product has another, potentially even more evocative interpretation: It is the cosine of the angle between two vector representations. Specifically, we can treat a vector representation as specifying the end point of a line segment that starts at the origin (i.e., the point where all vector elements are equal to zero). The line segment thus goes in a particular direction from the origin. The normalized dot product between two vectors is the cosine of the angle between the directions specified by each vector. For that reason, the normalized dot product is often called cosine similarity.\nThe basic idea of cosine similarity is illustrated in the graph below. The graph shows different vector representations \\(\\mathbf{x_j}\\) that are at different angles \\(\\theta_{ij}\\) relative to another vector representation \\(\\mathbf{x_i}\\). When the two vectors point generally in the same direction (to the left), the cosine similarity \\(s_{ij} = \\cos \\left( \\theta_{ij} \\right)\\) is greater than zero. When the two vectors point generally in the opposite direction (i.e., when \\(\\mathbf{x_j}\\) points more to the right than the left), cosine similarity is less than zero. Finally, when the two vectors are orthogonal, cosine similarity is zero.\n\n\nCode\nplot_angles &lt;- seq(0, 2 * pi - pi / 6, by = pi / 6)\nangle_ticks &lt;- seq(0, pi, by = pi / 4)\nangle_labels &lt;- c(expression(0), expression(pi / 4), expression(pi / 2), expression(3 * pi / 4), expression(pi))\n\ncircPlotDF &lt;- tibble(x = 0, y = 0, xend = -cos(plot_angles), yend = sin(plot_angles), theta = acos(cos(plot_angles)))\n\ncircPlot &lt;- circPlotDF %&gt;%\n    ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = theta)) +\n    geom_segment(arrow = arrow(length = unit(0.04, \"npc\"))) +\n    annotate(geom = \"segment\", x = 0, y = 0, xend = -1, yend = 0, arrow = arrow(length = unit(0.04, \"npc\"), type = \"closed\"), color = \"black\", linewidth = 1) +\n    annotate(geom = \"curve\", x = -0.7, y = 0, xend = -0.7 * cos(plot_angles[2]), yend = 0.7 * sin(plot_angles[2]), linetype = \"dashed\", color = \"black\", curvature = -1/6) +\n    annotate(geom = \"text\", x = -1.05, y = 0, label = \"bold(x[i])\", parse = TRUE, hjust = 1, vjust = 0.5, color = \"black\") +\n    annotate(geom = \"text\", x = -1.05 * cos(plot_angles[2]), y = 1.05 * sin(plot_angles[2]), label = \"bold(x[j])\", parse = TRUE, hjust = 1, vjust = 0.5, color = color(\"sunset\")(length(plot_angles))[2]) +\n    annotate(geom = \"text\", x = -0.75 * cos(plot_angles[2] / 2), y = 0.75 * sin(plot_angles[2] / 2), label = \"theta[ij]\", parse = TRUE, hjust = 1, vjust = 0.5) +\n    scale_color_sunset(range = c(0, 1), midpoint = pi / 2, guide = \"none\") +\n    coord_equal(xlim = c(-1.1, 1.1), ylim = c(-1.1, 1.1)) +\n    theme_void()\n\ncosPlotDF &lt;- tibble(theta = seq(0, pi, length.out = 101), s = cos(theta))\n\ncosPlot &lt;- cosPlotDF %&gt;%\n    ggplot(aes(x = theta, y = s, color = theta)) +\n    geom_line() +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n    scale_color_sunset(range = c(0, 1), midpoint = pi / 2, guide = \"none\") +\n    labs(x = expression(theta[ij]), y = expression(s[ij] == plain(cos)*(theta[ij]))) +\n    scale_x_continuous(breaks = angle_ticks, labels = angle_labels)\n\nprint(circPlot + cosPlot + plot_layout(ncol = 1))\n\n\n\n\n\n\n\n\n\nCosine similarity between vector representations \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\) can be formally specified in terms of the entries in each vector, without needing to explicitly specify the angle \\(\\theta_{ij}\\): \\[\ns_{ij} = \\cos \\left( \\theta_{ij} \\right) = \\frac{\\sum_{k = 1}^D x_{ik} x_{jk}}{\\left( \\sqrt{\\sum_{k = 1}^D x_{ik}^2} \\right) \\left( \\sqrt{\\sum_{k = 1}^D x_{jk}^2} \\right)}\n\\] where the numerator is the dot product and the denominator is the result of normalizing each vector.\nAbove, we saw how to use the tcrossprod trick to quickly compute the dot products between a set of vector representations that are stored in a matrix, with one row per item. We can use the same trick to compute the cosine similarities between those vectors if we first normalize them. One way to do that is to use a for loop to create a new matrix of normalized representations, like we did with x_1 and x_2 above. The code below does this with lsa_reps_examples, the integral distributed representations for our eight living things. It then uses tcrossprod with the normalized representations (reps_normalized) to get the cosine similarities for each pair of items.\n\n\nCode\nreps_normalized &lt;- lsa_reps_examples\n\nfor (i in 1:nrow(reps_normalized)) {\n    reps_normalized[i,] &lt;- lsa_reps_examples[i,] / sqrt(sum(lsa_reps_examples[i,]^2))\n}\n\nknitr::kable(tcrossprod(reps_normalized))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPine\nOak\nRose\nDaisy\nRobin\nCanary\nSunfish\nSalmon\n\n\n\n\nPine\n1.0000000\n0.7801236\n0.3182590\n0.3588819\n0.2646093\n0.2603472\n0.2559734\n0.3512150\n\n\nOak\n0.7801236\n1.0000000\n0.4407409\n0.3739185\n0.2873990\n0.1918864\n0.1433578\n0.3280999\n\n\nRose\n0.3182590\n0.4407409\n1.0000000\n0.5926361\n0.4917457\n0.2836333\n0.0934354\n0.2287908\n\n\nDaisy\n0.3588819\n0.3739185\n0.5926361\n1.0000000\n0.5808139\n0.2773187\n0.0822431\n0.1689983\n\n\nRobin\n0.2646093\n0.2873990\n0.4917457\n0.5808139\n1.0000000\n0.3514901\n0.0961755\n0.1687773\n\n\nCanary\n0.2603472\n0.1918864\n0.2836333\n0.2773187\n0.3514901\n1.0000000\n0.1692959\n0.1186324\n\n\nSunfish\n0.2559734\n0.1433578\n0.0934354\n0.0822431\n0.0961755\n0.1692959\n1.0000000\n0.5967915\n\n\nSalmon\n0.3512150\n0.3280999\n0.2287908\n0.1689983\n0.1687773\n0.1186324\n0.5967915\n1.0000000\n\n\n\n\n\nWe can also get a bit fancy and use some more matrix algebra to do the normalization without using a for loop. Admittedly, unless you are used to linear algebra, this may not be too intuitive. However, the main idea is to multiply the matrix of representations by a diagonal matrix that normalizes each row:\n\n\nCode\nreps_normalized &lt;- diag(1 / sqrt(rowSums(lsa_reps_examples^2))) %*% lsa_reps_examples\n\nknitr::kable(tcrossprod(reps_normalized))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.0000000\n0.7801236\n0.3182590\n0.3588819\n0.2646093\n0.2603472\n0.2559734\n0.3512150\n\n\n0.7801236\n1.0000000\n0.4407409\n0.3739185\n0.2873990\n0.1918864\n0.1433578\n0.3280999\n\n\n0.3182590\n0.4407409\n1.0000000\n0.5926361\n0.4917457\n0.2836333\n0.0934354\n0.2287908\n\n\n0.3588819\n0.3739185\n0.5926361\n1.0000000\n0.5808139\n0.2773187\n0.0822431\n0.1689983\n\n\n0.2646093\n0.2873990\n0.4917457\n0.5808139\n1.0000000\n0.3514901\n0.0961755\n0.1687773\n\n\n0.2603472\n0.1918864\n0.2836333\n0.2773187\n0.3514901\n1.0000000\n0.1692959\n0.1186324\n\n\n0.2559734\n0.1433578\n0.0934354\n0.0822431\n0.0961755\n0.1692959\n1.0000000\n0.5967915\n\n\n0.3512150\n0.3280999\n0.2287908\n0.1689983\n0.1687773\n0.1186324\n0.5967915\n1.0000000\n\n\n\n\n\nAs you can see, the result is the same set of cosine similarities. The linear algebra approach can be more efficient than the for loop if we have a large number of representations to deal with, but for the purposes of this class I recommend whichever approach you are most comfortable with.\nFinally, while cosine similarity can be computed using either separable or integral distributed representations, it makes a bit more sense to apply with integral distributed representations. That’s because the cosine similarity is a measure of the extent to which the entries in two vector representations exhibit the same patterns. This is a “holistic” measure of overall similarity which does not depend on the entries in each vector having any particular interpretation.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "vector_reps.html#modeling-choice-and-response-time-with-similarity",
    "href": "vector_reps.html#modeling-choice-and-response-time-with-similarity",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "10.4 Modeling choice and response time with similarity",
    "text": "10.4 Modeling choice and response time with similarity\nIn the last chapter, we saw how the EBRW used similarity between representations of items to explain choice and response time in recognition tasks. The previous application did not include attention weights and only allowed for transformed distance as a measure of similarity. The chunk of code below shows can we can modify our EBRW code to accommodate different types of similarity and to allow for attention weights on transformed distances. This function is embedded in a simplified working example in this script. The changes are explained in comments.\n\n\nCode\n# To be more general, the function now asks for \"stim_reps\", which is a matrix of vector representations of each stimulus.  These could be any kind of vector representation (localist, separable, integral).\n# The type of similarity to use is specified by the `sim_type` argument.  This can be \"transformed_distance\", \"cosine\", or \"dot_product\".\nextended_ebrw_nll &lt;- function(par, stim_reps, study_items, probe_item, response, rt, n_sims = 0, sim_type = \"transformed_distance\") {\n    if (sim_type == \"transformed_distance\") {\n        # If transformed distance similarity is specified, the parameter vector can also optionally specify parameters for *attention weights*.\n        # If there are D columns in stim_reps, there are D - 1 free attention weights, since they must sum to one.\n        # The attention weight parameters need only be nonnegative numbers, since they will be normalized anyway.\n        if (is.na(par[\"attention_weight[1]\"])) {\n            attention_weight &lt;- rep(1, ncol(stim_reps))\n        } else {\n            attention_weight &lt;- c(par[paste0(\"attention_weight[\", 1:(ncol(stim_reps) - 1), \"]\")], 1)\n        }\n        attention_weight &lt;- attention_weight / sum(attention_weight)\n        \n        # You can also optionally specify a Minkowski parameter, but it will be assumed to be 2 if you don't\n        if (is.na(par[\"minkowski_p\"])) {\n            minkowski_p &lt;- 2\n        } else {\n            minkowski_p &lt;- par[\"minkowski_p\"]\n        }\n        \n        # Finally, compute the matrix of stimulus similarities\n        stim_sims &lt;- diag(nrow(stim_reps))\n        \n        for (i in 2:nrow(stim_reps)) {\n            for (j in 1:(i - 1)) {\n                stim_sims[i, j] &lt;- stim_sims[j, i] &lt;- exp(-par[\"specificity\"] * sum(attention_weight * abs(stim_reps[i,] - stim_reps[j,])^minkowski_p)^(1 / minkowski_p))\n            }\n        }\n    } else {\n        # If similarity is *not* transformed distance, then dot product is assumed.\n        if (sim_type == \"cosine\") {\n            # If cosine similarity is specified, then first normalize the representations.\n            stim_reps &lt;- diag(1 / sqrt(rowSums(stim_reps^2))) %*% stim_reps\n        }\n        \n        # Finally, compute the matrix of stimulus similarities\n        stim_sims &lt;- tcrossprod(stim_reps)^par[\"specificity\"]\n    }\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(stim_sims[probe_item[i], study_items[i,]], na.rm = TRUE)\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    if (is.infinite(n_sims)) {\n        # 2a. Compute predicted response probabilities and mean RT's for each trial\n        result &lt;- c()\n        \n        evidence_var &lt;- evidence_sd^2\n        \n        for (i in 1:length(probe_item)) {\n            trial_p_yes &lt;- (1 - exp(-2 * par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i])) / (1 - exp(-2 * par[\"a\"] * evidence_mean[i] / evidence_var[i]))\n            trial_mean_rt_yes &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - par[\"w\"] / tanh(par[\"a\"] * evidence_mean[i] * par[\"w\"] / evidence_var[i]))\n            trial_mean_rt_no &lt;- par[\"t0\"] + (par[\"a\"] / evidence_mean[i]) * (1 / tanh(par[\"a\"] * evidence_mean[i] / evidence_var[i]) - (1 - par[\"w\"]) / tanh(par[\"a\"] * evidence_mean[i] * (1 - par[\"w\"]) / evidence_var[i]))\n            \n            result &lt;- rbind(\n                result,\n                tibble(trial = i, p_yes = trial_p_yes, mean_rt_yes = trial_mean_rt_yes, mean_rt_no = trial_mean_rt_no)\n            )\n        }\n        \n        # 3a. Return final result\n        return(result)\n    } else if (n_sims &gt; 0) {\n        # 2b. Simulate a response for each trial\n        result &lt;- c()\n        \n        # For each trial...\n        for (i in 1:length(probe_item)) {\n            # Simulate `n_sims` replications of this trial, using its corresponding parameters\n            trial_sim &lt;- sampWiener(\n                N = n_sims,\n                a = par[\"a\"] / evidence_sd[i],\n                w = par[\"w\"],\n                v = evidence_mean[i] / evidence_sd[i],\n                t0 = par[\"t0\"]\n            )\n            \n            # Append the new set of simulations to our `result`, including an indicator of which trial we are simulating and an index for each simulation\n            result &lt;- rbind(\n                result,\n                tibble(trial = i, sim_index = 1:n_sims, rt = trial_sim$q, response = trial_sim$response)\n            )\n        }\n        \n        # 3b. Return final result\n        return(result)\n    } else {\n        # 2c. Calculate the log-likelihood of each observed response/RT on each trial\n        result &lt;- try(WienerPDF(\n            t = rt,\n            response = response,\n            a = par[\"a\"] / evidence_sd,\n            w = par[\"w\"],\n            v = evidence_mean / evidence_sd,\n            t0 = par[\"t0\"]\n        ))\n        \n        # 3c. Return final result\n        if (class(result) == \"try-error\") {\n            return(Inf)\n        } else {\n            return(-sum(result$logvalue))\n        }\n    }\n}",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "vector_reps.html#exercises",
    "href": "vector_reps.html#exercises",
    "title": "10  Distributed representations, similarity, and recognition",
    "section": "10.5 Exercises",
    "text": "10.5 Exercises\n\nWhat kinds of items do you think are best modeled using separable representations and what kinds of items do you think are best modeled using integral representations? Are there particular characteristics of items that make separable or integral representations more appropriate?\n\n\n\n\n\nGarner, W. R., & Felfoldy, G. L. (1970). Integrality of stimulus dimensions in various types of information processing. Cognitive Psychology, 1, 225–241.\n\n\nLandauer, T. K., & Dumais, S. T. (1997). A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2), 211–240.\n\n\nMarr, D. (1982). Vision: A computational investigation into the human representation and processing of visual information. W.H. Freeman.\n\n\nMurdock, B. B. (1982). A theory for the storage and retrieval of item and associative information. Psychological Review, 89(3), 609–626.\n\n\nPhiliastides, M. G., Ratcliff, R., & Sajda, P. (2006). Neural representation of task difficulty and decision making during perceptual categorization: A timing diagram. Journal of Neuroscience, 26(35), 8965–8975. https://doi.org/10.1523/JNEUROSCI.1655-06.2006\n\n\nPurcell, B. A., Heitz, R. P., Cohen, J. Y., Schall, J. D., Logan, G. D., & Palmeri, T. J. (2010). Neurally constrained modeling of perceptual decision making. Psychological Review, 117(4), 1113–1143. https://doi.org/10.1037/a0020311\n\n\nPurcell, B. A., Schall, J. D., Logan, G. D., & Palmeri, T. J. (2012). From salience to saccades: Multiple-alternative gated stochastic accumulator model of visual search. Journal of Neuroscience, 32(10), 3433–3446. https://doi.org/10.1523/JNEUROSCI.4622-11.2012\n\n\nRogers, T. T., & McClelland, J. L. (2004). Semantic cognition: A parallel distributed processing approach. MIT Press.\n\n\nShadlen, M. N., & Newsome, W. T. (2001). Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey. Journal of Neurophysiology, 86(4), 1916–1936. https://doi.org/10.1152/jn.2001.86.4.1916\n\n\nTurner, B. M., Forstmann, B. U., Wagenmakers, E.-J., Brown, S. D., Sederberg, P. B., & Steyvers, M. (2013). A bayesian framework for simultaneously modeling neural and behavioral data. NeuroImage, 72, 193–206. https://doi.org/10.1016/j.neuroimage.2013.01.048",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distributed representations, similarity, and recognition</span>"
    ]
  },
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "11  Associative Learning",
    "section": "",
    "text": "11.1 Hebbian learning\nAlthough this form of learning takes its name from Hebb (1949), the basic idea has been around since at least the ancient Greeks. The idea is that things that are experienced at the same time become associated with one another. Eventually, experiencing one thing “activates” or “evokes” or “retrieves” other things that were frequently encountered alongside it. In more recent times, the principle has been applied to neurons, giving rise to the dictum that “neurons that fire together wire together”.\nTo model Hebbian learning, we assume that the learner experiences discrete learning “events”. These “events” are analogous to the kinds of memory traces we used in the EBRW: each event is represented as a vector with \\(D\\) dimensions. These representations can be localist or either separable or integral distributed. Learning is modeled by making adjustments in a \\(D \\times D\\) matrix, where the entry in the \\(i\\)th row and \\(j\\)th column is the associative weight between element \\(i\\) and element \\(j\\) of the event representations. These weights get updated each time an event occurs. As a result, the weights eventually come to represent the ways that different event element co-vary with one another.",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Associative Learning</span>"
    ]
  },
  {
    "objectID": "learning.html#hebbian-learning",
    "href": "learning.html#hebbian-learning",
    "title": "11  Associative Learning",
    "section": "",
    "text": "11.1.1 Representing learning events\nLet’s make this concrete by thinking back to the Blast cell example. Recall that those data involved participants with varying degrees of expertise in identifying whether a cell was a potentially cancerous “blast” cell or not, just by looking at a picture of the cell. Let’s imagine a related but somewhat simpler scenario, based on those used by Medin et al. (1982), that puts us in the position of being a novice gradually learning to become an expert.\nImagine that we are new doctors reading case reports that describe the presence or absence of four symptoms in each patient. For the moment, we are only interested in how these different symptoms may or may not co-vary with one another. The four symptoms are swollen eyelids, splotchy ears, discolored gums, and nosebleed. We have eight patient reports, and we can represent each report using a separable distributed vector with \\(D = 4\\) dimensions. As shown below, we can represent the presence of a symptom with a 1 and its absence with a 0.\n\n\nCode\nevent &lt;- matrix(c(\n    0, 0, 1, 1,\n    1, 1, 1, 1,\n    0, 1, 0, 0,\n    1, 1, 1, 1,\n    1, 0, 1, 1,\n    1, 1, 0, 0,\n    0, 1, 1, 1,\n    1, 0, 0, 0\n), nrow = 8, ncol = 4, byrow = TRUE,\ndimnames = list(\n    c(\"EM\", \"RM\", \"JJ\", \"LF\", \"AM\", \"JS\", \"ST\", \"SE\"),\n    c(\"swollen_eyelids\", \"splotchy_ears\", \"discolored_gums\", \"nosebleed\")\n))\n\nknitr::kable(event)\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nEM\n0\n0\n1\n1\n\n\nRM\n1\n1\n1\n1\n\n\nJJ\n0\n1\n0\n0\n\n\nLF\n1\n1\n1\n1\n\n\nAM\n1\n0\n1\n1\n\n\nJS\n1\n1\n0\n0\n\n\nST\n0\n1\n1\n1\n\n\nSE\n1\n0\n0\n0\n\n\n\n\n\n\n\n11.1.2 Updating associative weights\nBefore reading any of the patient reports, we are a tabula rasa, a “blank slate”. That means we don’t know anything about how any of the symptoms go together. This state of initial ignorance is represented by an associative weight matrix that is filled with zeros. This is illustrated below.\n\n\nCode\nassc_weights &lt;- matrix(0, nrow = ncol(event), ncol = ncol(event), dimnames = list(colnames(event), colnames(event)))\n\nknitr::kable(assc_weights)\n\n\n\n\n\n\n\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nswollen_eyelids\n0\n0\n0\n0\n\n\nsplotchy_ears\n0\n0\n0\n0\n\n\ndiscolored_gums\n0\n0\n0\n0\n\n\nnosebleed\n0\n0\n0\n0\n\n\n\n\n\nNow we read the first patient report:\n\n\nCode\nprint(event[1,])\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n              0               0               1               1 \n\n\nHow should we update our matrix of associative weights on the basis of this report? Since discolored gums and nosebleed were both present, we should increment the cells of the matrix corresponding to the combination of those symptoms. Moreover, since discolored gums and nosebleed are both present with themselves, we might as well update those cells of the matrix too. The result is that our new matrix might look something like this:\n\n\nCode\nknitr::kable(assc_weights + outer(event[1,], event[1,]))\n\n\n\n\n\n\n\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nswollen_eyelids\n0\n0\n0\n0\n\n\nsplotchy_ears\n0\n0\n0\n0\n\n\ndiscolored_gums\n0\n0\n1\n1\n\n\nnosebleed\n0\n0\n1\n1\n\n\n\n\n\nTo formalize what we just did, we will draw on one concept we have already seen and another concept we’ve sort of seen, if through a glass darkly. For the concept we have seen, recall that our models of choice and response time involved accumulating samples of evidence, where we added the new sample to a “running total”. That’s exactly how we will be updating our matrix of associative weights, and we can write it formally like this: \\[\nW(t + 1) = W(t) + \\Delta W(t)\n\\] where \\(W(t)\\) is our matrix of associative weights at the current time (\\(t\\)), \\(W(t + 1)\\) is our updated matrix after experiencing the learning event that occurs at time \\(t\\), and \\(\\Delta W(t)\\) is how we change our weights on the basis of the learning event experienced at time \\(t\\). This is just like accumulating samples of evidence, but instead we are accumulating changes in associative weights over time.\nNow for the thing we haven’t exactly seen, at least not in this form: Where do we get \\(\\Delta W(t)\\)? Since we are talking about adding something to a \\(D \\times D\\) matrix, we already know that \\(\\Delta W(t)\\) must also be a \\(D \\times D\\) matrix. We also know conceptually what \\(\\Delta W(t)\\) needs to do: It needs to represent the combinations of features that were present in the learning event at time \\(t\\). Recall from last chapter that, when dealing with binary 0/1 vectors, the dot product between two such vectors gave us a count of the number of features that were present (i.e., coded as 1) in each representation. This is because when \\(x_{ik} = 1\\) and \\(x_{jk} = 1\\), \\(x_{ik} x_{jk} = 1\\), otherwise \\(x_{ik} x_{jk} = 0\\). This is the idea behind what we are about to do.\nWe can get \\(\\Delta W(t)\\) by taking the outer product of the learning event representation \\(\\mathbf{x}(t)\\) with itself. The outer product between two vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) is sometimes written \\(\\mathbf{a} \\otimes \\mathbf{b}\\). If \\(\\mathbf{a}\\) has length \\(N\\) and \\(\\mathbf{b}\\) has length \\(M\\), then \\(\\mathbf{a} \\otimes \\mathbf{b}\\) is an \\(N \\times M\\) matrix where the entry in the \\(i\\)th row and \\(j\\)th column is the product between the \\(i\\)th element of \\(\\mathbf{a}\\) and the \\(j\\)th element of \\(\\mathbf{b}\\). This is illustrated in the example below, showing that the outer function in R gives us the outer product.\n\n\nCode\na &lt;- c(1, 0, 0, 1)\nb &lt;- c(1, 0, 1)\n\n# Outer product of a and b\nouter(a, b)\n\n\n     [,1] [,2] [,3]\n[1,]    1    0    1\n[2,]    0    0    0\n[3,]    0    0    0\n[4,]    1    0    1\n\n\nCode\n# Outer product of a with itself\nouter(a, a)\n\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    0    0    1\n[2,]    0    0    0    0\n[3,]    0    0    0    0\n[4,]    1    0    0    1\n\n\nCode\n# Outer product of b with itself\nouter(b, b)\n\n\n     [,1] [,2] [,3]\n[1,]    1    0    1\n[2,]    0    0    0\n[3,]    1    0    1\n\n\nSo if the vector \\(\\mathbf{x}(t)\\) represents the learning event experienced at time \\(t\\), then \\[\n\\Delta W(t) = \\lambda \\left[ \\mathbf{x}(t) \\otimes \\mathbf{x}(t) \\right]\n\\] where \\(\\lambda\\) is a parameter that represents the \\(learning rate\\). In the present example, we will keep things simple and assume \\(\\lambda = 1\\), but we will make use of this parameter later.\nGetting back to our symptom example, we can write the update procedure in R like this:\n\n\nCode\nlearning_rate &lt;- 1\ni &lt;- 1\n\nassc_weights &lt;- assc_weights + learning_rate * outer(event[i,], event[i,])\n\n\nYou might already anticipate where we are going: We can use a for loop to update the matrix of associative weights for each learning “event”, i.e., for each patient record we read.\n\n\nCode\n# Initialize weights to zero\nassc_weights &lt;- matrix(0, nrow = ncol(event), ncol = ncol(event))\n\n# Specify learning rate\nlearning_rate &lt;- 1\n\n# Update weights for each event\nfor (i in 1:nrow(event)) {\n    assc_weights &lt;- assc_weights + learning_rate * outer(event[i,], event[i,])\n}\n\nknitr::kable(assc_weights)\n\n\n\n\n\n\n\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nswollen_eyelids\n5\n3\n3\n3\n\n\nsplotchy_ears\n3\n5\n3\n3\n\n\ndiscolored_gums\n3\n3\n5\n5\n\n\nnosebleed\n3\n3\n5\n5\n\n\n\n\n\n\n\n11.1.3 Using what you’ve learned\nVia Hebbian learning, we have accumulated information about the co-occurrence patterns of different features (symptoms) across a series of learning events (patient records). We can use the resulting matrix of associative weights to do something that has been labeled in a few ways, such as cued recall, pattern completion, inference, and fill-in-the-blanks. The idea is that if we know that a patient has some symptoms, we can use the matrix of associative weights to make a reasonable guess about whether they have other symptoms, based on the degree to which those other symptoms co-occurred with the ones we know about. As the various names listed above imply, this is the same kind of process that goes on when we, say, correctly infer that penguins have wings by knowing that they have beaks and webbed feet (we might also incorrectly infer that penguins can fly for the same reason!).\nSay, for example, that we know a patient has discolored gums. By looking at the corresponding row in our matrix of associative weights, we can see that this symptom co-occurs with nosebleed more often than it does with either swollen eyelids or splotchy ears, as shown below.\n\n\nCode\nassc_weights[\"discolored_gums\",]\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n              3               3               5               5 \n\n\nOf course, the entries in our associative weight matrix are just numbers, they are not behavior. We need an additional process that enables us to predict behavior on the basis of the knowledge represented by the associative weight matrix. The relevant behavior here is whether or not you would be willing to say that a patient had symptom \\(k\\)—this is a choice. We could also model the response time associated with that choice (see the Exercises), but for now we only focus on choice behavior.\nSpecifically, we will transform the numbers extracted from the associative weight matrix into probabilities using the logistic function. This function will be familiar if you’ve done logistic regression, since it transforms unrestricted real numbers into the range between zero and one. The formula for the logistic function is \\[\nf(x) = \\frac{1}{1 + \\exp \\left(-x \\right)}\n\\] and it looks like this:\n\n\nCode\ntibble(x = seq(-6, 6, length.out = 501)) %&gt;%\n    mutate(y = 1 / (1 + exp(-x))) %&gt;%\n    ggplot(aes(x = x, y = y)) +\n    geom_line() +\n    labs(x = \"x\", y = expression(f(x)), title = \"Logistic function\")\n\n\n\n\n\n\n\n\n\nAs shown above, the logistic function returns values greater than 0.5 whenever its argument \\(x\\) is a positive number. When \\(x\\) is negative, the logistic function returns values less than 0.5. And if \\(x = 0\\), the logistic function is exactly 0.5.\nWe can apply the logistic function to the row of the associative weight matrix above:\n\n\nCode\n1 / (1 + exp(-assc_weights[\"discolored_gums\",]))\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n      0.9525741       0.9525741       0.9933071       0.9933071 \n\n\nOf course, we can probably ignore the entry for discolored_gums because we already know the patient has those! Looking at the other probabilities, they are pretty big, reflecting the fact that the associative weights are also pretty large. The magnitude of the weights depends on the learning rate parameter. The chunk of code below shows what happens if we reduce the learning rate.\n\n\nCode\n# Initialize weights to zero\nassc_weights &lt;- matrix(0, nrow = ncol(event), ncol = ncol(event))\n\n# Specify learning rate\nlearning_rate &lt;- 0.2\n\n# Update weights for each event\nfor (i in 1:nrow(event)) {\n    assc_weights &lt;- assc_weights + learning_rate * outer(event[i,], event[i,])\n}\n\nknitr::kable(assc_weights)\n\n\n\n\n\n\n\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nswollen_eyelids\n1.0\n0.6\n0.6\n0.6\n\n\nsplotchy_ears\n0.6\n1.0\n0.6\n0.6\n\n\ndiscolored_gums\n0.6\n0.6\n1.0\n1.0\n\n\nnosebleed\n0.6\n0.6\n1.0\n1.0\n\n\n\n\n\nCode\n1 / (1 + exp(-assc_weights[\"discolored_gums\",]))\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n      0.6456563       0.6456563       0.7310586       0.7310586 \n\n\nWith a smaller learning rate, the probabilities are not so extreme, and there is a bigger difference between the larger probabilities and smaller probabilities. Even so, we can anticipate that more learning will cause these weights to keep increasing and the probabilities to increase along with them. How can we address this counterintuitive behavior?\n\n\n11.1.4 Discriminative learning\nThe fault, as it turns out, is not in our stars but in our representations. Recall that we coded the presence/absence of symptoms as 1 or 0. As a result, associative weights can only ever increase with learning. To avoid this, we can instead code the absence of a symptom as -1. By using negative values, we can represent the absence of a feature more explicitly, thereby allowing us to learn to discriminate between the presence or absence of different features.\nFirst, let’s see what our learning event representations look like now:\n\n\nCode\nevent &lt;- matrix(c(\n    -1, -1,  1,  1,\n     1,  1,  1,  1,\n    -1,  1, -1, -1,\n     1,  1,  1,  1,\n     1, -1,  1,  1,\n     1,  1, -1, -1,\n    -1,  1,  1,  1,\n     1, -1, -1, -1\n), nrow = 8, ncol = 4, byrow = TRUE,\ndimnames = list(\n    c(\"EM\", \"RM\", \"JJ\", \"LF\", \"AM\", \"JS\", \"ST\", \"SE\"),\n    c(\"swollen_eyelids\", \"splotchy_ears\", \"discolored_gums\", \"nosebleed\")\n))\n\nknitr::kable(event)\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nEM\n-1\n-1\n1\n1\n\n\nRM\n1\n1\n1\n1\n\n\nJJ\n-1\n1\n-1\n-1\n\n\nLF\n1\n1\n1\n1\n\n\nAM\n1\n-1\n1\n1\n\n\nJS\n1\n1\n-1\n-1\n\n\nST\n-1\n1\n1\n1\n\n\nSE\n1\n-1\n-1\n-1\n\n\n\n\n\nNow let’s see what happens when we take the outer product of the first learning event with itself:\n\n\nCode\nouter(event[1,], event[1,])\n\n\n                swollen_eyelids splotchy_ears discolored_gums nosebleed\nswollen_eyelids               1             1              -1        -1\nsplotchy_ears                 1             1              -1        -1\ndiscolored_gums              -1            -1               1         1\nnosebleed                    -1            -1               1         1\n\n\nWe can see that the fact that discolored gums and nosebleed were both present while swollen eyelids and splotchy ears were not will result in a lowering of the associative weight between those two sets of symptoms.\nNow let’s see what the final set of associative weights looks like:\n\n\nCode\n# Initialize weights to zero\nassc_weights &lt;- matrix(0, nrow = ncol(event), ncol = ncol(event))\n\n# Specify learning rate\nlearning_rate &lt;- 1\n\n# Update weights for each event\nfor (i in 1:nrow(event)) {\n    assc_weights &lt;- assc_weights + learning_rate * outer(event[i,], event[i,])\n}\n\nknitr::kable(assc_weights)\n\n\n\n\n\n\n\n\n\n\n\n\n\nswollen_eyelids\nsplotchy_ears\ndiscolored_gums\nnosebleed\n\n\n\n\nswollen_eyelids\n8\n0\n0\n0\n\n\nsplotchy_ears\n0\n8\n0\n0\n\n\ndiscolored_gums\n0\n0\n8\n8\n\n\nnosebleed\n0\n0\n8\n8\n\n\n\n\n\nNow if we know a patient has discolored gums, we are very sure that they also have nosebleed and are equivocal about whether or not they have swollen eyelids or splotchy ears, as shown below:\n\n\nCode\n1 / (1 + exp(-assc_weights[\"discolored_gums\",]))\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n      0.5000000       0.5000000       0.9996646       0.9996646 \n\n\nOn the other hand, if we know a patient has swollen eyelids, we don’t have any strong opinions about whether or not they have any other symptoms (though we think it is more likely than not). Note that this is a consequence of the fact that discolored gums and nosebleed did tend to co-occur in our training events, whereas swollen eyelids did not systematically covary with any other symptoms.\n\n\nCode\n1 / (1 + exp(-assc_weights[\"swollen_eyelids\",]))\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n      0.9996646       0.5000000       0.5000000       0.5000000 \n\n\n\n\n11.1.5 Using multiple cues\nSo far, we have only thought about situations in which a single symptom was given for a new patient. What if we know that a patient has 2 symptoms or 3? Or what if we know they do not have a particular symptom? To address these situations, we need to go beyond just looking at a single row at a time.\nTo appreciate what we are about to do, imagine that we knew a patient had discolored gums and that they did not have swollen eyelids. In that case, the strength of support for each feature would be the row corresponding to discolored_gums minus the row corresponding to swollen_eyelids, as shown below:\n\n\nCode\nassc_weights[\"discolored_gums\",] - assc_weights[\"swollen_eyelids\",]\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n             -8               0               8               8 \n\n\nWhen we apply the logistic function to the vector above, we are still equivocal about splotchy ears but we are actually more sure that they have nosebleed:\n\n\nCode\n1 / (1 + exp(-(assc_weights[\"discolored_gums\",] - assc_weights[\"swollen_eyelids\",])))\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n   0.0003353501    0.5000000000    0.9996646499    0.9996646499 \n\n\nWe can make the logic of what we just did to obtain that prediction more general. We will again make use of some linear algebra. Specifically, we will obtain the “strength of support” for each symptom by multiplying the matrix of associative weights with a vector that encodes the presence/absence/missingness of each known symptom. This vector is called a “probe” or a “cue”, and the result will be another vector that gives the total degree of support for each symptom. In math, we can write the operation like this: \\[\n\\mathbf{o} = \\mathbf{c} W\n\\] where \\(\\mathbf{c}\\) is the cue (or probe) vector and \\(\\mathbf{o}\\) is the “output” vector.\nThe example above corresponds to the following cue vector:\n\n\nCode\ncue &lt;- c(-1, 0, 1, 0)\nnames(cue) &lt;- rownames(assc_weights)\n\nprint(cue)\n\n\nswollen_eyelids   splotchy_ears discolored_gums       nosebleed \n             -1               0               1               0 \n\n\nNotice that we use -1 to code for the known absence of a feature, 1 to code for the known presence of a feature, and 0 to code for “missing knowledge” about a feature.\nWe can use the cue vector to “probe” the associative weight matrix. In R, matrix multiplication uses the %*% operator (think of it as a “fancy multiplication”). So the code below directly implements the equation listed above:\n\n\nCode\ncue %*% assc_weights\n\n\n     swollen_eyelids splotchy_ears discolored_gums nosebleed\n[1,]              -8             0               8         8\n\n\nAnd as we hoped, we get the same result from our fancy linear algebra as we did when we did it by hand earlier. The point of introducing this linear algebra now is that it will generalize more readily to situations in which we have more complex event representations (e.g., integral representations).\n\n\n11.1.6 Associating events with actions\nIn the preceding examples, the learner associated features of events with one another, but now we consider how to model learning the relations between features of events and outcomes or actions. In the context of our ongoing medical example, imagine that a new doctor is learning to diagnose whether or not someone has a particular disease based on the pattern of symptoms they display. Now, instead of associating symptoms with symptoms, the doctor needs to associate symptoms with the presence/absence of the disease. Modeling this form of learning will require making two changes to the Hebbian learning model we have been building so far.\nFirst, we need to redefine the associative weight matrix \\(W\\). Before, it was \\(D \\times D\\), where \\(D\\) is the number of dimensions in our learning event representations. Now, it will be \\(D \\times O\\), where \\(O\\) is the number of dimensions used to represent the available actions. Sometimes, as in some of the examples below, \\(O\\) will equal 1 if the learner just needs to decide whether to take an action or not (e.g., whether or not someone has a disease). But in general, \\(O\\) could have many dimensions if the learner can take many actions or if the actions are sufficiently complex that they require a distributed representation. The entry in the \\(i\\)th row and \\(j\\)th column of our new associative weight matrix will represent the strength of association between event dimension \\(i\\) and action/outcome dimension \\(j\\).\nThe other thing we need to do is define, for each learning event, the “label” or “correct answer” that is associated with it. In the model implementation below, we do this by having two matrices: an event matrix that stores the features of each learning event, with one row per event and one column per feature; and a target matrix that stores the “correct answer” for each event, with one row per event and one column per outcome dimension.\nThe example below uses the same set of symptoms as our running example. The first four patients were diagnosed with a disease while the second four were not.\n\n\nCode\nevent &lt;- matrix(c(\n     1,  1,  1,  1,\n    -1,  1, -1, -1,\n     1, -1, -1,  1,\n     1, -1, -1, -1,\n     1, -1,  1,  1,\n    -1, -1,  1, -1,\n    -1,  1, -1,  1,\n    -1, -1, -1, -1\n), nrow = 8, ncol = 4, byrow = TRUE, dimnames = list(\n    c(paste0(\"T\", 1:4), paste0(\"F\", 1:4)),\n    c(\"swollen_eyelids\", \"splotchy_ears\", \"discolored_gums\", \"nosebleed\")\n))\n\ntarget &lt;- matrix(c(\n     1,\n     1,\n     1,\n     1,\n    -1,\n    -1,\n    -1,\n    -1\n), nrow = 8, ncol = 1, byrow = TRUE, dimnames = list(\n    c(paste0(\"T\", 1:4), paste0(\"F\", 1:4)),\n    c(\"Diagnosis\")\n))\n\nassc_weights &lt;- matrix(0, nrow = ncol(event), ncol = ncol(target))\n\nlearning_rate &lt;- 1\n\nfor (i in 1:nrow(event)) {\n    assc_weights &lt;- assc_weights + learning_rate * outer(event[i,], target[i,])\n}\n\nknitr::kable(assc_weights)\n\n\n\n\n\nswollen_eyelids\n4\n\n\nsplotchy_ears\n2\n\n\ndiscolored_gums\n-2\n\n\nnosebleed\n0\n\n\n\n\n\nIn the end, the new doctor has learned that swollen eyelids are strongly diagnostic of the disease, splotchy ears are weakly diagnostic, discolored gums are weakly counter-indicative of the disease, and nosebleed is uninformative.\nNotice that all we needed to do to model this form of associative learning was to swap out event for target. Formally, we can specify the learning procedure like this: \\[\n\\Delta W(t) = \\lambda \\left[ \\mathbf{x}(t) \\otimes \\mathbf{t}(t) \\right]\n\\] where \\(\\lambda\\) and \\(\\mathbf{x}(t)\\) are as defined above and \\(\\mathbf{t}(t)\\) is the vector representation of the target (“correct answer”) for the learning event experienced at time \\(t\\).",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Associative Learning</span>"
    ]
  },
  {
    "objectID": "learning.html#error-driven-learning",
    "href": "learning.html#error-driven-learning",
    "title": "11  Associative Learning",
    "section": "11.2 Error-driven learning",
    "text": "11.2 Error-driven learning\nAs noted above, Hebbian learning—whether of associations between event features or associations between events and actions—was a form of unsupervised learning, since the learner had no explicit goal other than to learn. In supervised learning, a learner again associates features of events with different actions or outcomes. The difference between supervised and unsupervised learning is that, in supervised learning, the adjustments the learner makes to their matrix of associations depends on the error between the target action/outcome and the learner’s guess or prediction about the action/outcome. Each time a learning event occurs, the learner uses the features of that event to form a representation of the action/outcome they select. The learner then receives feedback telling them the correct action/outcome they should have chosen. The goal of the learner is to adjust their associative weights in such a way that they reduce the discrepancy between the action/outcome they pick and the one they are told is correct.\nTo return to our running example, in supervised learning, the new doctor examines the symptoms of a patient report (this is the “learning event”), makes a diagnosis (this is the chosen action/outcome), and then gets told what the correct diagnosis would have been for that patient (this is the feedback). The new doctor then has to adjust the pattern of associations between symptoms (learning event features) and diagnoses (actions/outcomes).\nWe can imagine the same kind of learning occurring in many situations: When you are learning language, you might choose which word to use to describe an object based on its visible features (e.g., calling a black and white creature with four legs a “zebra”) and then someone nearby would either confirm your choice or provide the correct name (e.g., “no, that’s a dalmatian”). When you are learning a skill like using a tool or playing an instrument, you take an action (e.g., pressing a key on a keyboard) and then get feedback about whether it was correct or not (e.g., you hear the correct note you should have played).\nFormally, error-driven learning then happens in two steps: \\[\\begin{align*}\n\\mathbf{y}(t) & = f \\left[ \\mathbf{x}(t) W(t) \\right] & \\text{Make a prediction/guess} \\\\\n\\Delta W(t) & = \\lambda \\left\\lbrace \\mathbf{x}(t) \\otimes \\overbrace{\\left[\\mathbf{t}(t) - \\mathbf{y}(t) \\right]}^{\\text{Error}} \\right\\rbrace & \\text{Adjust weights in proportion to error}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHebb, D. O. (1949). The organization of behavior: A neuropsychological theory. Wiley.\n\n\nMedin, D. L., Altom, M. W., Edelson, S. M., & Freko, D. (1982). Correlated symptoms and simulated medical classification. Journal of Experimental Psychology: Learning, Memory, and Cognition, 8(1), 37–50. https://www.proquest.com/scholarly-journals/correlated-symptoms-simulated-medical/docview/614362118/se-2",
    "crumbs": [
      "Coupling behavior to structured representations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Associative Learning</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Akaike, H. (1974). A new look at the\nstatistical model identification. IEEE Transactions on Automatic\nControl, 19(6), 716–723.\n\n\nArlot, S., & Celisse, A. (2010). A survey of cross-validation\nprocedures for model selection. Statistics Surveys, 4,\n40–79. https://doi.org/10.1214/09-SS054\n\n\nBlurton, S. P., Kesselmeier, M., & Gondan, M. (2012). Fast and\naccurate calculations for cumulative first-passage time distributions in\nwiener diffusion models. Journal of Mathematical Psychology,\n56(6), 470–475. https://doi.org/https://doi.org/10.1016/j.jmp.2012.09.002\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and\nimmediate memory. Psychological Review, 64(3),\n205–215.\n\n\nBrown, S., & Heathcote, A. (2008). The simplest complete model of\nchoice response time: Linear ballistic accumulation. Cognitive\nPsychology, 57, 153–178.\n\n\nBrowne, M. W. (2000). Cross-validation methods. Journal of\nMathematical Psychology, 44(1), 108–132. https://doi.org/10.1006/jmps.1999.1279\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A\ndynamic–cognitive approach to decision making in an uncertain\nenvironment. Psychological Review, 100(3), 432–459.\n\n\nBusemeyer, J. R., & Wang, Y.-M. (2000). Model comparisons and model\nselections based on generalization criterion methodology. Journal of\nMathematical Psychology, 44(1), 171–189. https://doi.org/10.1006/jmps.1999.1282\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event\nmemory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of\nhuman memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and\nBrain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nDiederich, A. (1997). Dynamic stochastic models for decision making\nunder time constraints. Journal of Mathematical Psychology,\n41(3), 260–274. https://doi.org/10.1006/jmps.1997.1167\n\n\nDonkin, C., Brown, S., Heathcote, A., & Wagenmakers, E.-J. (2011).\nDiffusion versus linear ballistic accumulation: Different models but the\nsame conclusions about psychological processes? Psychonomic Bulletin\n& Review, 55, 140–151.\n\n\nGarner, W. R., & Felfoldy, G. L. (1970). Integrality of stimulus\ndimensions in various types of information processing. Cognitive\nPsychology, 1, 225–241.\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding\npredictive information criteria for bayesian models. Statistics and\nComputing, 24(6), 997–1016. https://doi.org/10.1007/s11222-013-9416-2\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for\nnovel auditory stimuli: Similarity, serial position, and list\nhomogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nGondan, M., Blurton, S. P., & Kesselmeier, M. (2014). Even faster\nand even more accurate first-passage time densities and distributions\nfor the wiener diffusion model. Journal of Mathematical\nPsychology, 60, 20–22. https://doi.org/https://doi.org/10.1016/j.jmp.2014.05.002\n\n\nHarding, B., Goulet, M.-A., Jolin, S., Tremblay, C., Villeneuve, S.-P.,\n& Durand, G. (2016). Systems factorial technology explained to\nhumans. The Quantitative Methods for Psychology,\n12(1), 39–56.\n\n\nHartmann, R., & Klauer, K. C. (2021). Partial derivatives for the\nfirst-passage time distribution in wiener diffusion models. Journal\nof Mathematical Psychology, 103, 102550.\nhttps://doi.org/https://doi.org/10.1016/j.jmp.2021.102550\n\n\nHartmann, R., & Klauer, K. C. (2023). WienR: Derivatives of the\nfirst-passage time density and cumulative distribution function, and\nrandom sampling from the (truncated) first-passage time\ndistribution. https://CRAN.R-project.org/package=WienR\n\n\nHebb, D. O. (1949). The organization of behavior: A\nneuropsychological theory. Wiley.\n\n\nHoupt, J. W., Blaha, L. M., McIntire, J. P., Havig, P. R., &\nTownsend, J. T. (2014). Systems factorial technology with\nR. Behavior Research Methods, 46,\n307–330.\n\n\nLandauer, T. K., & Dumais, S. T. (1997). A solution to Plato’s problem: The latent semantic analysis\ntheory of acquisition, induction, and representation of knowledge.\nPsychological Review, 104(2), 211–240.\n\n\nMarr, D. (1982). Vision: A computational investigation into the\nhuman representation and processing of visual information. W.H.\nFreeman.\n\n\nMedin, D. L., Altom, M. W., Edelson, S. M., & Freko, D. (1982).\nCorrelated symptoms and simulated medical classification. Journal of\nExperimental Psychology: Learning, Memory, and Cognition,\n8(1), 37–50. https://www.proquest.com/scholarly-journals/correlated-symptoms-simulated-medical/docview/614362118/se-2\n\n\nMurdock, B. B. (1982). A theory for the storage and retrieval of item\nand associative information. Psychological Review,\n89(3), 609–626.\n\n\nNavarro, D. J. (2018). Between the devil and the deep blue sea: Tensions\nbetween scientific judgement and statistical model selection.\nComputational Brain & Behavior. https://doi.org/10.1007/s42113-018-0019-z\n\n\nNavarro, D. J., & Fuss, I. G. (2009). Fast and accurate calculations\nfor first-passage times in wiener diffusion models. Journal of\nMathematical Psychology, 53(4), 222–230.\nhttps://doi.org/https://doi.org/10.1016/j.jmp.2009.02.003\n\n\nNeisser, U. (1967). Cognitive psychology.\nAppleton-Century-Crofts.\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the\nidentification-categorization relationship. Journal of Experimental\nPsychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models.\nAnnual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An\nexemplar-familiarity model predicts short-term and long-term probe\nrecognition across diverse forms of memory search. Journal of\nExperimental Psychology: Learning, Memory, and Cognition,\n40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011).\nShort-term memory scanning viewed as exemplar-based categorization.\nPsychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random\nwalk model of speeded classification. Psychological Review,\n104(2), 266–300.\n\n\nPhiliastides, M. G., Ratcliff, R., & Sajda, P. (2006). Neural\nrepresentation of task difficulty and decision making during perceptual\ncategorization: A timing diagram. Journal of Neuroscience,\n26(35), 8965–8975. https://doi.org/10.1523/JNEUROSCI.1655-06.2006\n\n\nPiironen, J., & Vehtari, A. (2017). Comparison of bayesian\npredictive methods for model selection. Statistics and\nComputing, 27(3), 711–735. https://doi.org/10.1007/s11222-016-9649-y\n\n\nPurcell, B. A., Heitz, R. P., Cohen, J. Y., Schall, J. D., Logan, G. D.,\n& Palmeri, T. J. (2010). Neurally constrained modeling of perceptual\ndecision making. Psychological Review, 117(4),\n1113–1143. https://doi.org/10.1037/a0020311\n\n\nPurcell, B. A., Schall, J. D., Logan, G. D., & Palmeri, T. J.\n(2012). From salience to saccades: Multiple-alternative gated stochastic\naccumulator model of visual search. Journal of Neuroscience,\n32(10), 3433–3446. https://doi.org/10.1523/JNEUROSCI.4622-11.2012\n\n\nRaab, D. H. (1962). Statistical facilitation of simple reaction times.\nTransactions of the New York Academy of Sciences, 24(5\nSeries II), 574–590.\n\n\nRae, B., Heathcote, A., Donkin, C., Averell, L., & Brown, S. (2014).\nThe hare and the tortoise: Emphasizing speed can change the evidence\nused to make decisions. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 40(5), 1226–1243.\n\n\nRaftery, A. E. (1995). Bayesian model selection in social research.\nSociological Methodology, 25, 111–163. https://doi.org/10.2307/271063\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological\nReview, 85(2), 59–108.\n\n\nRatcliff, R., & Rouder, J. N. (1998). Modeling response times for\ntwo-choice decisions. Psychological Science, 9(5),\n347–356.\n\n\nRogers, T. T., & McClelland, J. L. (2004). Semantic cognition: A\nparallel distributed processing approach. MIT Press.\n\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals\nof Statistics, 6(2), 461–464.\n\n\nShadlen, M. N., & Newsome, W. T. (2001). Neural basis of a\nperceptual decision in the parietal cortex (area LIP) of the rhesus\nmonkey. Journal of Neurophysiology, 86(4), 1916–1936.\nhttps://doi.org/10.1152/jn.2001.86.4.1916\n\n\nShepard, R. N. (1962a). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nI. Psychometrika, 27(2), 125–140.\nhttps://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nII. Psychometrika, 27(3), 219–246.\nhttps://doi.org/https://doi.org/10.1007/BF02289621\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober,\nC. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D.,\nNavarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service\nof science: Don’t let the tail wag the dog. Computational Brain\n& Behavior.\n\n\nStone, M. (1977). An asymptotic equivalence of choice of model by\ncross-validation and Akaike’s criterion.\nJournal of the Royal Statistical Society. Series B\n(Methodological), 39(1), 44–47.\n\n\nTeodorescu, A. R., & Usher, M. (2013). Disentangling decision\nmodels: From independence to competition. Psychological Review,\n120(1), 1–38.\n\n\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential\nsampling models without random between-trial variability: The racing\ndiffusion model of speeded decision making. Psychonomic Bulletin\n& Review, 27(5), 911–936. https://doi.org/10.3758/s13423-020-01719-6\n\n\nTownsend, J. T., & Nozawa, G. (1995). Spatio-temporal properties of\nelementary perception: An investigation of parallel, serial, and\ncoactive theories. Journal of Mathematical Psychology,\n39, 321–359.\n\n\nTrueblood, J. S., Holmes, W. R., Seegmiller, A. C., Douds, J., Compton,\nM., Szentirmai, E., Woodruff, M., Huang, W., Stratton, C., &\nEichbaum, Q. (2018). The impact of speed and bias on the cognitive\nprocesses of experts and novices in medical image decision-making.\nCognitive Research: Principles and Implications, 3,\n1–14.\n\n\nTuerlincx, F. (2004). The efficient computation of the cumulative\ndistribution and probability density functions in the diffusion model.\nBehavior Research Methods, Instruments, & Computers,\n36(4), 702–716.\n\n\nTurner, B. M., Forstmann, B. U., Wagenmakers, E.-J., Brown, S. D.,\nSederberg, P. B., & Steyvers, M. (2013). A bayesian framework for\nsimultaneously modeling neural and behavioral data. NeuroImage,\n72, 193–206. https://doi.org/10.1016/j.neuroimage.2013.01.048\n\n\nUsher, M., & McClelland, J. L. (2001). The time course of perceptual\nchoice: The leaky, competing accumulator model. Psychological\nReview, 108(3), 550–592.\n\n\nVehtari, A., & Lampinen, J. (2002). Bayesian model assessment and\ncomparison using cross-validation predictive densities. Neural\nComputation, 14(10), 2439–2468. https://doi.org/10.1162/08997660260293292\n\n\nZucchini, W. (2000). An introduction to model selection. Journal of\nMathematical Psychology, 44(1), 41–61. https://doi.org/10.1006/jmps.1999.1276",
    "crumbs": [
      "References"
    ]
  }
]
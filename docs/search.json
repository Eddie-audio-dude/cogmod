[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Cognitive Models",
    "section": "",
    "text": "Preface\nThis is a collection of notes and materials for an introductory course in computational cognitive modeling. It will be updated and, arguably, improved over the course of the semester.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Some functions of models\nAs Cox & Shiffrin (2024) describe, a computational cognitive model falls on the “causal” end of the spectrum in the graph shown at the top. They enumerate a couple of goals that such a model might serve:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#some-functions-of-models",
    "href": "intro.html#some-functions-of-models",
    "title": "1  Introduction",
    "section": "",
    "text": "All models are wrong, but causal models are useful when they capture and approximate the causal processes at work and when they generalize to other settings. When modeling complex human behavior, all the models are at best crude approximations to reality, but nonetheless they can prove useful by describing the processes that are most important for explaining behavior.\nModeling allows precise communication among scientists. When theories and hypotheses are proposed verbally and heuristically, their precise meaning is not generally known even to the proposers, and they are often misinterpreted and misunderstood by others. When theoretical constructs are clearly linked to elements of a model and the internal workings of the model are described with mathematical or computational precision (e.g., by including the code running the model simulation), other scientists can use, generalize, and test the model because its application in at least its original domain is well specified.\nModels make clear the links between assumptions and predictions. Different investigators cannot dispute the predictions of the model that are produced by a given set of parameters (the parameters generally index different quantitative variants of a given class of models).\nThe formal specification of the model clarifies the nature of proposed internal cognitive processes. A poor modeler may fail to demonstrate that linkage. A good modeler will explore the parameter space and show how the parameter values change the predictions and how narrow or broad a range of outcomes can be predicted by changes in the parameter values. A good modeler will also explore alterations in the model, perhaps by deleting some processes or by adding others, or by fixing some parameter values at certain values, thus providing diagnostic information about the qualitative features of the outcome space that are primarily due to a process controlled by particular parameters. A bad modeler might claim a fit to data provides support for an underlying causal theory when in fact the fit is primarily due to some parameter or theory not conceptually related to the claim.\nConstructing a model can act as an “intuition pump” (cf. Dennett, 1980). Many modelers try to infer underlying cognitive processes from complex data sets that involve multiple measures (e.g., accuracy and response time) and many conditions which may be difficult or impossible to summarize adequately. Modelers form hypotheses about the processes involved based on the data and their prior knowledge. It is often the case that intuiting predictions for different combinations of processes is not possible due to the limitations of human cognition. Thus, different combinations of processes are instantiated as formal models, enabling a modeler to observe and test the predictions of their hypotheses. In an iterative model building process, the failures in each iteration indicate the way forward to an appropriate account.\nModeling allows different hypothesis classes to be compared, both because the predictions of each are well specified and because model comparison techniques take into account model complexity. The issue of complexity is itself quite complex.\n\nOne issue is due to statistical noise produced by limited data. A flexible model with many parameters can produce what seems to be a good fit with parameter values that explain the noise in the data rather than the underlying processes. The best model comparison techniques penalize models appropriately for extra complexity. However, models are in most cases developed after observing the data, and they are used to explain the patterns observed. To do so, they often incorporate assumptions that are critical but not explicitly parameterized. It thus becomes a difficult and subtle matter to assess complexity adequately. A secondary problem with using fit to compare models is the fact that the most principled ways to control for complexity, such as Bayesian model selection and minimum description length, are difficult to implement computationally and are often replaced by approximations such as the Akaike or Bayes/Schwartz information criteria that often fail to account for key aspects of model complexity.\nSimpler models are also favored for other reasons. A chief one is limited human reasoning: As a model becomes more complex, it becomes more difficult for a human to understand how it works. Simpler models are also favored when analytic predictions can be derived (thereby greatly reducing computational costs) and for qualitative reasons such as “elegance”.\nSimpler models are particularly favored when their core processes generalize well across many tasks.\nThere exists a danger that the modeler will mistake small quantitative differences in “fit” for the important differences among models—differences that generally lie in qualitative patterns of predictions. Knowing one model provides a better fit to a limited set of observations from a narrow experimental setting is not often useful. For example, consider a model that correctly predicts the relative levels of recall accuracy observed across conditions in a given experiment but quantitatively overpredicts the accuracy in a single condition. Meanwhile, another model perfectly predicts the accuracy in that condition but fails to predict the right qualitative pattern of accuracy across conditions. We argue that the qualitatively correct prediction is a reason to favor the first model, even though it might yield a worse quantitative fit. Correct qualitative predictions across conditions are often a sign that a model captures an important and generalizable causal process.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-simulation",
    "href": "intro.html#the-importance-of-simulation",
    "title": "1  Introduction",
    "section": "1.2 The importance of simulation",
    "text": "1.2 The importance of simulation\nThe models that we will be covering are models that simulate behavioral (and maybe even neural) outcomes. Because we are building models of a complex system—namely, the mind—our models can also become complex. Therefore, understanding what kind of behavior a model produces may require us to simulate behavior from that model. This will also help us to understand the relationship between the model’s parameters and its behavior. By simulating how behavior changes as one or more parameters change, we can understand the role played by the theoretical construct represented by that parameter.\nFor example, we might have a parameter that represents the quality or precision with which an event is stored in memory. In a model where this memory representation is used to yield behavior, we can systematically adjust the value of the quality/precision parameter and observe the effect this has on the model’s simulated behavior. Again, because we are dealing with models that can grow quite complex, we may even be surprised by the behavior the model produces!\nTwo analogies may help give some intuition about the value of simulation: If we are cooking, often the only way to know how a particular combination of spices will taste is to actually combine them and taste. Model parameters are like the different amounts of each spice, with the final taste being analogous to the model’s simulated behavior. Alternatively, you can think of model parameters as being like characters in an improv sketch. The characters have different backgrounds and goals which dictate how they will interact and how the story will develop. The background and goals of the characters are like the parameters of a model, with the resulting performance analogous to the model’s predicted behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-importance-of-fitting-data",
    "href": "intro.html#the-importance-of-fitting-data",
    "title": "1  Introduction",
    "section": "1.3 The importance of fitting data",
    "text": "1.3 The importance of fitting data\n“Fitting” a model to data means finding the combination of parameter values for which the model produces behavior that most closely resembles that produced by a participant in some task. The value of doing this is that it helps us understand why that participant acted the way they did.\nFor example, we might want to know whether someone was fast because they were able to quickly accumulate the evidence they needed, because they were uncautious, because they were biased, or because they could execute motor actions quickly. We can address that question by finding the values of the parameters associated with each construct that best fit their observed performance.\n\n\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and immediate memory. Psychological Review, 64(3), 205–215.\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event memory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of human memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and Brain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nNeisser, U. (1967). Cognitive psychology. Appleton-Century-Crofts.\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober, C. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D., Navarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service of science: Don’t let the tail wag the dog. Computational Brain & Behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "ebrw.html",
    "href": "ebrw.html",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "2.1 Summed similarity\nFor concreteness, we imagine an experiment in which several color patches were studied. Colors can be described in terms of three features: hue, chroma (or “saturation”), and luminance (or “brightness”). Imagine that you saw many reddish-hued colors that varied in chroma and luminance. According to the EBRW, each of the colors you saw would leave a trace in memory. Each trace would consist of the values of the color you saw along those three dimensions. In this example, all the colors have the same value for “hue”, which is 0. The value of “0” for “hue” corresponds to a reddish color. The colors differ in their values for chroma and luminance, as illustrated in the graph below:\nCode\ncolDF &lt;- expand_grid(h = hue, c = seq(30, 70, length.out = 5), l = seq(30, 70, length.out = 5)) %&gt;%\n    mutate(col = hcl(h, c, l))\n\ncolDF %&gt;%\n    ggplot(aes(x = c, y = l, fill = col)) +\n    geom_tile(width = 2.5, height = 2.5) +\n    scale_fill_identity() +\n    coord_equal() +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", caption = bquote(plain(hue) == .(round(hue))))\nYour memory traces can also be written as a matrix, where each row corresponds to an item (color) and each column corresponds to a feature (h for “hue”, c for “chroma”, and l for “luminance”):\nCode\nknitr::kable(head(colDF %&gt;% select(h, c, l), 10), row.names = TRUE)\n\n\n\n\n\n\nh\nc\nl\n\n\n\n\n1\n0\n30\n30\n\n\n2\n0\n30\n40\n\n\n3\n0\n30\n50\n\n\n4\n0\n30\n60\n\n\n5\n0\n30\n70\n\n\n6\n0\n40\n30\n\n\n7\n0\n40\n40\n\n\n8\n0\n40\n50\n\n\n9\n0\n40\n60\n\n\n10\n0\n40\n70\nThese coordinates will often be derived using Multidimensional Scaling (MDS) (Nosofsky, 1992; Shepard, 1962a, 1962b). This type of analysis derives a spatial representation of a set of stimuli on the basis of similarity judgments provided by raters.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#summed-similarity",
    "href": "ebrw.html#summed-similarity",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "",
    "text": "2.1.1 Perceived distance and similarity\nThe perceived distance between any two of these colors is the Euclidean distance between their feature values, weighted by the degree of attention given to each feature: \\[\nd_{ij} = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{ik} - x_{jk} \\right)^2}\n\\] where \\(w_k\\) is the weight given to feature \\(k\\), \\(x_{ik}\\) is the value of item \\(i\\) on feature \\(k\\), \\(x_{jk}\\) is the value of item \\(j\\) on feature \\(k\\), \\(d_{ij}\\) is the perceived distance between items \\(i\\) and \\(j\\), and \\(N_F\\) is the number of features which in this example is 3 (hue, chroma, and luminance). Note also that while Euclidean distance is appropriate for colors, other types of distance metrics may be more appropriate for other kinds of stimuli.\nPerceived similarity between two items, \\(s_{ij}\\), is an exponential function of the psychological distance between those items: \\[\ns_{ij} = \\exp(-c d_{ij})\n\\] where \\(c\\) is a sensitivity parameter that controls how quickly perceived similarity decreases with distance, as illustrated in the graph below:\n\n\nCode\nexpand_grid(d = seq(0, 10, length.out = 151), c = seq(0.25, 3, by = 0.25)) %&gt;%\n    mutate(s = exp(-c * d)) %&gt;%\n    ggplot(aes(x = d, y = s, color = c, group = c)) +\n    geom_line() +\n    scale_color_continuous_sequential() +\n    labs(x = expression(d[ij]), y = expression(s[ij])) +\n    theme(legend.position = c(1, 1), legend.justification = c(1, 1))\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Summed similarity\nImagine that you have just been shown two colors from among the set shown earlier. We then present you with a third color—a probe item—and ask whether it was one of the two you just saw. You answer this question on the basis of the summed similarity between the probe item and the two items in memory. The probe item has its own vector of feature values, \\(\\mathbf{x_q}\\). The perceived distance between the probe item and each of the memory items is, as above, the Euclidean distance between the probe’s feature values and those of the memory item: \\[\n\\begin{align}\nd_{qj} & = \\sqrt{\\sum_{k = 1}^{N_F} w_k \\left(x_{qk} - x_{jk} \\right)^2} \\\\\ns_{qj} & = \\exp \\left( -c d_{qj} \\right) \\\\\nS & = \\sum_{j = 1}^{N_M} s_{qj}\n\\end{align}\n\\] and, again, the perceived similarity \\(s_{qj}\\) between the probe \\(q\\) and memory item \\(j\\) is an exponential function of perceived distance \\(d_{qj}\\). Finally, summed similarity \\(S\\) is the sum of the perceived similarities across all \\(N_M\\) items in memory.\nThe graphs below illustrate how this works. The left graph shows contours of equal similarity from each of two study items. The right graph shows summed similarity as a function of the chroma and luminance of a probe item (assuming the same hue).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d))\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 1, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n2.1.2.1 Trace strength\nIt is reasonable to believe that some memory traces are stronger than others, likely due to things like primacy and recency. In GCM/EBRW, “strength” is operationalized as a scaling factor \\(m_j\\) applied to perceived similarity: \\[\ns_{qj} = m_j \\exp \\left( -c d_{qj} \\right)\n\\]\nStronger traces have their similarity multiplied by a large value (\\(m_j\\) is large if trace \\(j\\) is strong) while weaker traces have their similarity multiplied by a small value (\\(m_j\\) is small if trace \\(j\\) is weak). This is illustrated in the pair of graphs below. A probe item does not need to be as similar to a strong item in order to evoke the same level of perceived similarity.\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nsens &lt;- 0.05\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-sens * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), c == .(signif(sens, 3)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Trace specificity\nThe specificity parameter \\(c\\) represents the fact that items are assumed to be encoded with some degree of error/uncertainty. Just as items may be encoded with more or less strength, it is reasonable to assume that items can be encoded in memory with more or less specificity. Thus, we add a subscript to the \\(c\\) parameter corresponding to each study item: \\[\ns_{qj} = m_j \\exp \\left( -c_j d_{qj} \\right)\n\\]\nIf an item is encoded with high specificity, then it will only be perceived as similar to the probe if the probe is very close in psychological space. This is illustrated in the pair of graphs below, where item 2 is not only stronger (\\(m_2 = 2\\) vs. \\(m_1 = 1\\)) but also more precise (\\(c_2 = 0.1\\) vs. \\(c_1 = 0.05\\)).\n\n\nCode\nX &lt;- matrix(\n    c(40, 60,\n      60, 50),\n    nrow = 2,\n    ncol = 2,\n    byrow = TRUE\n)\n\nspecificity &lt;- c(0.05, 0.1)\nstrength &lt;- c(1, 2)\n\ncolDF &lt;- tibble(h = hue, c = X[,1], l = X[,2]) %&gt;%\n    mutate(col = hcl(h, c, l)) %&gt;%\n    mutate(label = c(\"1\", \"2\"))\n\nitem_cols &lt;- as.vector(colDF$col)\nnames(item_cols) &lt;- as.character(1:length(item_cols))\n\nsimDF &lt;- expand_grid(c = seq(30, 70, length.out=101), l = seq(30, 70, length.out=101), item = c(1, 2)) %&gt;%\n    mutate(d = sqrt((c - X[item, 1])^2 + (l - X[item, 2])^2)) %&gt;%\n    mutate(s = exp(-specificity[item] * d) * strength[item])\n\nconPlot &lt;- colDF %&gt;%\n    ggplot(aes(x = c, y = l)) +\n    geom_contour(aes(z = s, color = factor(item)), data = simDF, alpha = 2/3, breaks = seq(0, 2, by = 0.2)) +\n    geom_tile(aes(fill = col), width = 2.5, height = 2.5) +\n    geom_text(aes(label = label), color = \"black\") +\n    scale_fill_identity(aesthetics = \"fill\") +\n    scale_color_manual(values = item_cols, aesthetics = \"color\", guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Contours of equal similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nsumSimPlot &lt;- simDF %&gt;%\n    group_by(c, l) %&gt;%\n    summarize(summed_sim = sum(s), .groups = \"keep\") %&gt;%\n    ggplot(aes(x = c, y = l, fill = summed_sim)) +\n    geom_raster() +\n    scale_fill_viridis_c(option = \"magma\", limits = c(0, 3), guide = \"none\") +\n    coord_equal(xlim = c(30, 70), ylim = c(30, 70)) +\n    labs(x = \"Chroma (saturation)\", y = \"Luminance (brightness)\", subtitle = \"Summed similarity\", caption = bquote(list(plain(hue) == .(round(hue)), m[1] == .(signif(strength[1], 3)), m[2] == .(signif(strength[2], 3)), c[1] == .(signif(specificity[1], 3)), c[2] == .(signif(specificity[2], 3)))))\n\nconPlot + sumSimPlot + plot_layout(nrow = 1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "href": "ebrw.html#making-a-recognition-decision-from-random-walk-to-diffusion",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.2 Making a recognition decision: From random walk to diffusion",
    "text": "2.2 Making a recognition decision: From random walk to diffusion\nAccording to the EBRW, each trace \\(j\\) in memory races to be retrieved at a rate proportional to its perceived similarity to the probe item, \\(s_{qj}\\). Traces race not just against one another, but against a criterion. If a memory trace wins the race, this is taken as evidence that the probe item matches something in memory, thus favoring a “yes” recognition response. If the criterion wins the race instead, this is taken as evidence that the probe item does not match anything in memory, thus favoring a “no” recognition response.\nThe idea is that, if the probe item matches something in memory, then the corresponding memory trace (or one sufficiently similar to probably match) should be able to win against the criterion. If nothing wins against the criterion, then this suggests there are no traces in memory that are a good match to the probe.\n\n2.2.1 Accumulating memory evidence\nThe outcome of each race is added to a running tally which starts at zero. The value of the tally at any given time \\(t\\), which we can denote \\(x(t)\\), constitutes the current state of evidence from memory for making a recognition decision. Assume that each race takes \\(\\Delta t\\) seconds to complete. Each time a memory trace wins the race, the tally gets incremented by one; each time the criterion wins the race, the tally gets decremented by one. Put formally, we can write this process as \\[\nx\\left( t + \\Delta t \\right) =\n\\begin{cases}\nx\\left( t \\right) + 1 & \\text{if trace wins} \\\\\nx\\left( t \\right) - 1 & \\text{if criterion wins}\n\\end{cases}\n\\] where \\(x(0) = 0\\).\n\n\n2.2.2 Step probabilities\nAlthough we have specified that whether memory evidence goes up or down depends on whether a trace or the criterion wins the race, we have not yet specified how the outcome of that race is determined. The winner of each race is random but depends on the similarity \\(s_{qj}\\) between each trace \\(j\\) and the probe \\(q\\). Specifically, trace \\(j\\) wins the race with probability: \\[\n\\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa}\n\\] where \\(\\kappa\\) is a nonnegative number that represents how stringent the criterion is. In other words, the equation above says that the probability that trace \\(j\\) wins the race is the similarity between trace \\(j\\) and the probe \\(q\\) divided by the summed similarity across all traces plus the criterion \\(\\kappa\\). In a sense, we can think of the criterion is like a “virtual memory trace” that races alongside the \\(N\\) actual memory traces.\nRemember that we increment memory strength whenever any trace wins the race, regardless of which one it is. Because only one trace can win each race, the probability that any trace wins is just the sum of the probabilities of winning across all \\(N\\) traces, i.e.: \\[\np = \\sum_{j = 1}^N \\frac{s_{qj}}{\\sum_{k = 1}^N s_{qk} + \\kappa} = \\frac{1}{\\sum_{k = 1}^N s_{qk} + \\kappa} \\left( \\sum_{j = 1}^Ns_{qj} \\right) = \\frac{S}{S + \\kappa}\n\\] where \\(S = \\sum_{j = 1}^N s_{qj}\\) is the summed similarity across all \\(N\\) traces. The quantity \\(p\\) is the probability that the random walk takes a step up.\nThe EBRW models the speed of decision making in terms of how many races must be run until the accumulated win advantage in favor of either a “yes” or “no” response reaches a decision boundary. To convert this to “real time”, we must say how long each race takes and allow for a residual time. Above, we used \\(\\Delta t\\) to stand for the amount of time (in seconds) each race takes to run. It will be convenient later to think instead of \\(\\nu = \\frac{1}{\\Delta t}\\), where \\(\\nu\\) is the number of races per second.\nThe figure below shows an example of how memory evidence evolves during a single trial in which \\(p = 0.55\\), \\(\\nu = 40\\), \\(B_{Upper} = 7\\), \\(B_{Lower} = -8\\), and \\(t_0 = 0.2\\). In addition, the graphs above and below the evidence trajectory illustrate the relative frequency with which, across many identical trials, each type of response would be made at each unit of time. Note that these distributions are discrete because the random walk operates in discrete time intervals, each of duration \\(\\Delta t\\) (which in this example is \\(\\Delta t = \\frac{1}{\\nu} = 0.025\\) seconds).\n\n\nCode\nset.seed(1)\n\nnu &lt;- 40\np &lt;- 0.55\n\nB &lt;- c(-8, 7)\nresid &lt;- 0.2\n\n### RT distributions\n\nY_rw &lt;- seq(B[1], B[2])\nP_rw &lt;- matrix(0, nrow = length(Y_rw), ncol = length(Y_rw))\nP_rw[cbind(2:(nrow(P_rw) - 1), 1:(ncol(P_rw) - 2))] &lt;- 1 - p\nP_rw[cbind(2:(nrow(P_rw) - 1), 3:ncol(P_rw))] &lt;- p\nP_rw[1, 1] &lt;- P_rw[nrow(P_rw), ncol(P_rw)] &lt;- 1\n\n### Simulation\n\nwhile (TRUE) {\n    winner &lt;- 0\n    x_rw &lt;- 0\n\n    while (TRUE) {\n        s &lt;- 2 * (runif(n = 1) &lt; p) - 1\n        x_rw &lt;- c(x_rw, x_rw[length(x_rw)] + s)\n        if (x_rw[length(x_rw)] &lt;= B[1]) {\n            winner &lt;- 1\n            break\n        } else if (x_rw[length(x_rw)] &gt;= B[2]) {\n            winner &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == 2 & (length(x_rw) / nu) &gt; 1.5) {\n        break\n    }\n}\n\nRT_rw &lt;- matrix(0, nrow = 2, ncol = length(x_rw))\nZ_rw &lt;- 1 * c(Y_rw == 0)\n\nfor (i in 1:length(x_rw)) {\n    Z_rw &lt;- Z_rw %*% P_rw\n    RT_rw[1, i] &lt;- Z_rw[1]\n    RT_rw[2, i] &lt;- Z_rw[length(Z_rw)]\n}\n\ndRT_rw &lt;- apply(RT_rw, MARGIN = 1, FUN = diff) * nu / 2\n\nrtPlot1 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#eeb211\", color = NA, width = 1 / nu) +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_rw)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(fill = \"#46166b\", color = NA, width = 1 / nu) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_rw)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + 1:length(x_rw) / nu, x = x_rw) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step(linewidth = 1.5) +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 From discrete random walk to continuous diffusion\nA random walk takes discrete-valued steps either up or down in discrete units of time. A Wiener diffusion process takes continuous-valued steps sampled from a normal distribution in infinitely small units of time, thus effectively operating in continuous time. We are going to approximate the discrete EBRW with a continuous diffusion process (so technically we should call this model the EBD for Exemplar-Based Diffusion, but we will keep calling it the EBRW for posterity).\nIn going from a random walk to a diffusion model, we are making an important psychological claim: We are saying that, instead of memory evidence arriving in discrete units at regular intervals, memory evidence is a continuous value that continually evolves as new information arrives. We can think of this as saying that, instead of only knowing the outcome of each race, you can see who is ahead and who is behind at any given time; this is the move from discrete time to continuous time. Moreover, instead of only scoring each race as a win or loss for the memory traces, the races are assigned a continuous value depending on how clear the winner is; this is the move from discrete evidence to continuous evidence.\n\n2.2.3.1 Mean and standard deviation of diffusion\nWe can write the update equation for the random walk like we did above: \\[\n\\begin{align}\nx \\left( t + \\Delta t \\right) & = \\begin{cases} x(t) + 1 & \\text{with probability } p \\\\ x(t) - 1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & = \\begin{cases} 1 & \\text{with probability } p \\\\ -1 & \\text{with probability } 1 - p \\end{cases} \\\\\nx \\left( t + \\Delta t \\right) - x(t) & \\sim 2 \\times \\text{Bernoulli} \\left( p \\right) - 1\n\\end{align}\n\\] where we have rearranged terms and used the shorthand in the final line to emphasize the idea that each step of the random walk can be thought of as a sample from a Bernoulli distribution with parameter \\(p\\) that is then transformed from \\(\\lbrace 0, 1 \\rbrace\\) to \\(\\lbrace -1, 1 \\rbrace\\).\nTo turn this into a continuous diffusion process, we need to swap out the transformed Bernoulli distribution with a normal distribution that has the same mean and variance. The mean is \\(2 p - 1\\) and the variance is \\(4 p \\left(1 - p \\right)\\). One more thing: remember that we run \\(\\nu\\) races per second, so we need to multiply the mean and variance by \\(\\nu\\). Therefore, the mean drift rate is \\(v = \\nu \\left(2 p - 1 \\right)\\) and the variance is \\(\\sigma^2 = 4 \\nu p (1 - p)\\).\nNote that this is different from the typical diffusion model where the variance of the evidence samples is arbitrarily fixed to 1. Notice an important property of this variance: It is largest when \\(p = 0.5\\) and approaches zero as \\(p\\) approaches either 0 or 1. In other words, the more uncertain the outcome of each race, the more noise there is in the diffusion. This is illustrated below:\n\n\nCode\nexpand_grid(p = seq(0, 1, length.out = 101), nu = seq(10, 40, by = 10)) %&gt;%\n    mutate(sigma2 = 4 * nu * p * (1 - p)) %&gt;%\n    ggplot(aes(x = p, y = sigma2, color = nu, group = nu)) +\n    geom_line() +\n    labs(x = p, y = expression(sigma^2), color = expression(nu)) +\n    theme(legend.position = c(1, 1), legend.justification = c(1, 1))\n\n\n\n\n\n\n\n\n\nTo summarize, the difference between the random walk and the diffusion is that we have swapped out a discrete binomial distribution of evidence increments per unit time with a continuous normal distribution of evidence increments per unit time. Everything else is the same: You still respond “yes” if and when the accumulated evidence \\(x(t)\\) reaches either the upper boundary or the lower boundary.\n\n\n2.2.3.2 Closeness of predictions\nTo illustrate how well the diffusion process approximates the random walk, the graphs below show the diffusion approximation to the same random walk example used above. The smooth lines in the upper and lower graphs are the probability of responding per unit time (i.e., the probability density function) according to the Wiener diffusion model. The open bars are the same probabilities from the random walk. The diffusion model’s predictions hew very closely to those of the random walk!\n\n\nCode\nmu &lt;- nu * (2 * p - 1)\nsigma2 &lt;- 4 * nu * p * (1 - p)\nboundsep &lt;- B[2] - B[1]\nbias &lt;- (0 - B[1]) / (B[2] - B[1])\ndelta_t &lt;- 0.001\n\nwhile (TRUE) {\n    winner_diff &lt;- NA\n    x_diff &lt;- 0\n    \n    while (TRUE) {\n        x_diff &lt;- c(x_diff, x_diff[length(x_diff)] + rnorm(n = 1, mean = mu * delta_t, sd = sqrt(sigma2 * delta_t)))\n        if (x_diff[length(x_diff)] &lt;= B[1]) {\n            winner_diff &lt;- 1\n            break\n        } else if (x_diff[length(x_diff)] &gt;= B[2]) {\n            winner_diff &lt;- 2\n            break\n        }\n    }\n    \n    if (winner == winner_diff & abs((length(x_diff) * delta_t) - (length(x_rw) / nu)) &lt; (1 / nu)) {\n        break\n    }\n}\n\nx_diff &lt;- pmax(pmin(x_diff, B[2]), B[1])\n\nt &lt;- seq(1, length(x_diff)) * delta_t\n\ndRT_diff &lt;- cbind(\n    WienerPDF(t = t, response = \"lower\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value,\n    WienerPDF(t = t, response = \"upper\", a = boundsep / sqrt(sigma2), v = mu / sqrt(sigma2), w = bias)$value\n)\n\nrtPlot1 &lt;- tibble(t = resid + t, p = dRT_diff[,2]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,2])), color = \"#eeb211aa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#eeb21177\", color = \"#eeb211\") +\n    coord_cartesian(xlim = c(0, NA), ylim = c(0, max(c(dRT_diff)))) +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrtPlot0 &lt;- tibble(t = resid + t, p = dRT_diff[,1]) %&gt;%\n    ggplot(aes(x = t, y = p)) +\n    geom_col(data = tibble(t = resid + 1:length(x_rw) / nu, p = c(0, dRT_rw[,1])), color = \"#46166baa\", fill = NA, width = 1 / nu) +\n    geom_area(fill = \"#46166b77\", color = \"#46166b\") +\n    labs(x = NULL, y = \"Pr(Respond at time t)\") +\n    scale_x_continuous(limits = c(0, NA)) +\n    scale_y_reverse(limits = c(max(c(dRT_diff)), 0)) +\n    theme(axis.text = element_blank(), axis.ticks.y = element_blank())\n\nrwPlot &lt;- tibble(t = resid + t, x = x_diff) %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_line() +\n    geom_hline(yintercept = B[2], linetype = \"solid\", color = \"#eeb211\", linewidth = 2) +\n    geom_hline(yintercept = B[1], linetype = \"solid\", color = \"#46166b\", linewidth = 2) +\n    geom_vline(xintercept = resid, linetype = \"dashed\", color = \"#666666\", linewidth = 2) +\n    geom_text(data = tibble(x = 0, y = B[2], label = paste0(\"B[Upper] == \", B[2])), mapping = aes(x = x, y = y, label = label), color = \"#eeb211\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = 2) +\n    geom_text(data = tibble(x = 0, y = B[1], label = paste0(\"B[Lower] == \", B[1])), mapping = aes(x = x, y = y, label = label), color = \"#46166b\", inherit.aes = FALSE, parse = TRUE, hjust = 0, vjust = -1) +\n    geom_text(data = tibble(x = resid, y = 0, label = paste0(\"t[0] == \", resid)), mapping = aes(x = x, y = y, label = label), color = \"#666666\", inherit.aes = FALSE, parse = TRUE, hjust = 1.1, vjust = 1.5) +\n    coord_cartesian(xlim = c(0, NA)) +\n    labs(x = \"Retrieval time (s)\", y = \"Memory evidence\", caption = bquote(list(p == .(p), nu == .(nu), v == .(signif(mu, 3)), sigma == .(signif(sqrt(sigma2), 3)))))\n\nrtPlot1 + rwPlot + rtPlot0 + plot_layout(ncol = 1, heights = c(1, 1.75, 1))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#implementation-in-r",
    "href": "ebrw.html#implementation-in-r",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.3 Implementation in R",
    "text": "2.3 Implementation in R\nTo find the EBRW parameters that best fit the recognition data from a participant, let’s implement the diffusion version of the EBRW in R using the WienR package. We must define a function to compute the negative log-likelihood (NLL) for a set of observed responses/RT’s, given a set of parameters. The function itself, in outline form, looks like the one below. I have written comments for the things that the function needs to accomplish to get from what is given to the function (in the parentheses following function) to what the function needs to return at the end.\nFor example purposes, this implementation doesn’t include all of the bells and whistles that the full model includes. It will not allow for varying trace strength nor will it include attention weights on each dimension. This is meant to illustrate the basic idea that we can define a diffusion model in which the drift rates are derived from a theory, rather than just estimated.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\nLet’s now fill in each of those sections in turn.\n\n2.3.1 Parameters\nThe vector par that is the first argument to the ebrw_nll function should be a named vector that has the following entries:\n\n\nCode\npar &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\n\n\n2.3.2 Computing the mean and SD of the drift for each trial\nRecall that the drift rates depend on the distances between each of the stimulus items. Since the function is provided with stim_coords, we can make our job a little easier by using the dist function to compute the matrix of distances between all pairs of items. This saves us from “recomputing” the distances between pairs of items that occur on multiple trials:\n\n\nCode\nstim_dists &lt;- as.matrix(dist(stim_coords))\n\n\nThen, to compute the summed similarity for each trial i, we can use a for loop:\n\n\nCode\nevidence_mean &lt;- rep(0, length(probe_item))\nevidence_sd &lt;- rep(0, length(probe_item))\n\nfor (i in 1:length(probe_item)) {\n    summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n    p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n    \n    evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n    evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n}\n\n\nWe have now completed the second step of writing the ebrw_nll function, as summarized below.\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    \n    # 3. Return final result\n    return(nll)\n}\n\n\n\n\n2.3.3 Calculating the log-likelihood\nThis step is almost too easy. We are using the WienR package, which means we can use the WienerPDF function like we’ve seen already. There is only one thing we need to do: The WienerPDF function assumes that the standard deviation of the diffusion is always equal to one. As such, we need to standardize the drift rate and boundary separation before we send them to the WienerPDF function by dividing each by evidence_sd:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    )\n    \n    # 3. Return final result\n    return(-sum(result$logvalue))\n}\n\n\n\n\n2.3.4 Error-checking\nIt is important for us to do some error checking. Sometimes, a particular combination of parameters will make it impossible for the WienerPDF function to calculate the log-likelihood. When that happens, it gives an error. In essence, such a result tells us that the model cannot work with that combination of parameters. Thus, rather than an “error”, that is really telling us that we should assign zero likelihood to that set of parameters, which is equivalent to a log-likelihood of \\(-\\infty\\).\nWe can do that kind of check in R by putting the WienerPDF function call within try(). If the WienerPDF function gives an error, then the result that gets stored in trial_wiener is also an error. Otherwise, it just gives us the log-likelihoods that we want.\nLet’s set up an “if…else” structure to do this check:\n\n\nCode\n# Function arguments:\n# par: this is a named vector of parameter values\n# stim_coords: this is a matrix of the coordinates of the stimuli, where each row is a stimulus and each column is a dimension\n# study_items: this is a matrix where each row is a trial and each column indicates the items that were studied on that trial\n# probe_item: this is a vector giving the index of the probe item on each trial\n# response: this is a vector where each value is 2 or 1, depending on whether the participant responsed \"yes\" (2) or \"no\" (1) on that trial\n# rt: this is a vector of the response times from each trial\nebrw_nll &lt;- function(par, stim_coords, study_items, probe_item, response, rt) {\n    # 1. Compute the mean and SD of the drift for each trial\n    \n    stim_dists &lt;- as.matrix(dist(stim_coords))\n    \n    evidence_mean &lt;- rep(0, length(probe_item))\n    evidence_sd &lt;- rep(0, length(probe_item))\n    \n    for (i in 1:length(probe_item)) {\n        summed_sim &lt;- sum(exp(-par[\"specificity\"] * stim_dists[probe_item[i], study_items[i,]]))\n        p &lt;- summed_sim / (summed_sim + par[\"criterion\"])\n        \n        evidence_mean[i] &lt;- par[\"retrieval_rate\"] * (2 * p - 1)\n        evidence_sd[i] &lt;- 2 * sqrt(par[\"retrieval_rate\"] * p * (1 - p))\n    }\n    \n    # 2. Calculate the log-likelihood of each observed response/RT on each trial\n    result &lt;- try(WienerPDF(\n        t = rt,\n        response = response,\n        a = par[\"a\"] / evidence_sd,\n        w = par[\"w\"],\n        v = evidence_mean / evidence_sd,\n        t0 = par[\"t0\"]\n    ))\n    \n    # 3. Return final result\n    if (class(result) == \"try-error\") {\n        return(Inf)\n    } else {\n        return(-sum(result$logvalue))\n    }\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "ebrw.html#a-worked-example",
    "href": "ebrw.html#a-worked-example",
    "title": "2  Exemplar of the Exemplar Based Random Walk",
    "section": "2.4 A worked example",
    "text": "2.4 A worked example\nThis example uses a single participant’s data from Experiment 2 of Gillespie & Cox (2024). In this experiment, each participant made similarity ratings between all pairs of eight items. Each item was an “auditory texture” constructed via Fourier synthesis. We applied Multidimensional Scaling to the similarity ratings from each participant to assign, for each participant, a set of coordinates to each item. The coordinates are such that items that are farther from one another were associated with lower similarity ratings and those that were closer to one another were assigned higher similarity ratings. Be sure to check out the paper itself for additional detail on how this was done, and how we decided that the multidimensional space in which the stimuli are represented had 3 dimensions. These coordinates will be used for the stim_coords argument of the ebrw_nll function.\nIn addition to providing similarity ratings, each participant engaged in a recognition memory task. On each trial of this task, the participant heard two auditory textures, presented sequentially. They then heard a “probe” sound and had to decide whether or not it was one of the two sounds that had just been presented. It is these recognition data that we will model with the EBRW.\nYou can grab the data yourself by running the following chunk of code to download it and load it into your R workspace:\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/ebrw_example_data.rdata\", \"blast_data.rdata\")\nload(\"ebrw_example_data.rdata\")\n\n\n\n2.4.1 Check out the data\nThe stimulus coordinates are saved in a matrix called stim_coords:\n\n\nCode\nprint(stim_coords)\n\n\n           [,1]         [,2]        [,3]\n[1,] -0.4679162 -0.463219039 -0.08056499\n[2,] -0.5549266  0.499390636  0.07099460\n[3,] -0.4742833 -0.132020672  0.43312165\n[4,] -0.5062581  0.005578674 -0.40175331\n[5,]  0.5110397 -0.222844222 -0.30381582\n[6,]  0.4578305  0.336495895 -0.27302187\n[7,]  0.5669455 -0.288366241  0.24624698\n[8,]  0.4675684  0.264984969  0.30879277\n\n\nWe can visualize them using plot_ly:\n\n\nCode\nto_plot &lt;- as.data.frame(stim_coords)\ncolnames(to_plot) &lt;- paste(\"Dimension\", 1:ncol(stim_coords))\nrownames(to_plot) &lt;- paste(\"Item\", 1:nrow(stim_coords))\n\nplot_ly(data = to_plot, x = ~ `Dimension 1`, y = ~ `Dimension 2`, z = ~ `Dimension 3`, type = \"scatter3d\", text = rownames(to_plot))\n\n\nNo scatter3d mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nIn addition for each trial of the recognition task, the study_items matrix tells us which of the two items had been presented as part of the set to be remembered and the probe_item vector tells us what the probe item was. These numbers refer to row in the stim_coords matrix.\n\n\nCode\nprint(study_items)\n\n\n      [,1] [,2]\n [1,]    3    5\n [2,]    3    6\n [3,]    8    1\n [4,]    1    7\n [5,]    2    4\n [6,]    7    2\n [7,]    6    7\n [8,]    8    3\n [9,]    3    4\n[10,]    5    6\n[11,]    6    8\n[12,]    1    4\n[13,]    4    8\n[14,]    7    4\n[15,]    6    1\n[16,]    1    3\n[17,]    1    2\n[18,]    3    2\n[19,]    6    4\n[20,]    8    2\n[21,]    3    7\n[22,]    4    5\n[23,]    5    2\n[24,]    1    5\n[25,]    7    8\n[26,]    2    6\n[27,]    7    5\n[28,]    5    8\n\n\nCode\nprint(probe_item)\n\n\n [1] 4 2 1 7 2 7 7 2 6 6 6 1 3 4 4 3 8 3 8 4 7 8 4 2 6 2 3 5\n\n\nFinally, the rt and response vectors record the response time (in seconds) and the response (where 2 is “yes” and 1 is “no”) produced by this participant on each trial.\n\n\n2.4.2 Finding optimal parameters\nThe version of the EBRW that we applied in our paper is a bit more complex than the one we will use here, which only has six free parameters. We will use R’s built-in nlminb function to find the best-fitting values of these parameters. To do this, we need to specify initial values for each parameter in a named vector, as shown below. These initial values don’t necessarily need to be anything in particular as long as they don’t cause the ebrw_nll function to return an error or a value of Inf.\n\n\nCode\ninit_par &lt;- c(\n    \"retrieval_rate\" = 3,     # This is the \"nu\" parameter\n    \"a\" = 2,                  # Response caution\n    \"w\" = 0.5,                # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 1,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 1           # Criterion (the \"kappa\" parameter)\n)\n\n\nWe also need to specify the upper and lower values that each of these parameters could possibly take, as shown below:\n\n\nCode\nlower &lt;- c(\n    \"retrieval_rate\" = 0,     # This is the \"nu\" parameter\n    \"a\" = 0,                  # Response caution\n    \"w\" = 0,                  # Response bias\n    \"t0\" = 0,                 # Residual time\n    \"specificity\" = 0,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = 0           # Criterion (the \"kappa\" parameter)\n)\n\nupper &lt;- c(\n    \"retrieval_rate\" = Inf,     # This is the \"nu\" parameter\n    \"a\" = Inf,                  # Response caution\n    \"w\" = 1,                    # Response bias\n    \"t0\" = min(rt),             # Residual time\n    \"specificity\" = Inf,        # Specificity of memory representations (the \"c\" parameter)\n    \"criterion\" = Inf           # Criterion (the \"kappa\" parameter)\n)\n\n\nNote that these upper and lower values can be Infinite if necessary!\nFinally, let’s use the nlminb function, which we need to provide with each of the ingredients we prepared above. We will save the result as fit:\n\n\nCode\nfit &lt;- nlminb(\n    start = init_par,          # Need to provide initial guess of parameter values\n    objective = ebrw_nll,      # Tell R the name of the function to optimize\n    lower = lower,             # The lower bounds on each parameter\n    upper = upper,             # The upper bounds on each parameter\n    stim_coords = stim_coords, # The coordinates of each stimulus\n    rt = rt,                   # The vector of RT's on each trial\n    response = response,       # The vector of responses on each trial\n    study_items = study_items, # The study items on each trial\n    probe_item = probe_item    # The probe item on each trial\n)\n\n\nWarning in nlminb(start = init_par, objective = ebrw_nll, lower = lower, :\nNA/NaN function evaluation\n\n\nAnd the final result!\n\n\nCode\nfit\n\n\n$par\nretrieval_rate              a              w             t0    specificity \n     1.2474191      2.1459586      0.4488126      0.6884095      5.6470633 \n     criterion \n     0.1035233 \n\n$objective\n[1] 21.59716\n\n$convergence\n[1] 0\n\n$iterations\n[1] 35\n\n$evaluations\nfunction gradient \n      56      243 \n\n$message\n[1] \"relative convergence (4)\"\n\n\nThe beauty of this result is that we have explained why this participant did what they did in terms of\n\nTheir internal representations of the stimuli, modeled as coordinates in a latent psychological space.\nA decision process that involves continuously sampling exemplars from memory until a criterion is reached.\n\n\n\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for novel auditory stimuli: Similarity, serial position, and list homogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models. Annual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An exemplar-familiarity model predicts short-term and long-term probe recognition across diverse forms of memory search. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011). Short-term memory scanning viewed as exemplar-based categorization. Psychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random walk model of speeded classification. Psychological Review, 104(2), 266–300.\n\n\nShepard, R. N. (1962a). The analysis of proximities: Multidimensional scaling with an unknown distance function. I. Psychometrika, 27(2), 125–140. https://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities: Multidimensional scaling with an unknown distance function. II. Psychometrika, 27(3), 219–246. https://doi.org/https://doi.org/10.1007/BF02289621",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exemplar of the Exemplar Based Random Walk</span>"
    ]
  },
  {
    "objectID": "r_coding.html",
    "href": "r_coding.html",
    "title": "3  Programming with R",
    "section": "",
    "text": "3.1 Tips and strategies",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#tips-and-strategies",
    "href": "r_coding.html#tips-and-strategies",
    "title": "3  Programming with R",
    "section": "",
    "text": "When trying to write code to accomplish a particular task—or when trying to understand code written by someone else—try to break the task into individual steps that are accomplished in sequence in order to yield the final result.\nIf you are unsure what a particular bit of code will do—for example, if you want to figure out how to code one of the steps you’ve identified above—try to construct a minimal working example. This example should be simple enough that you can figure out what the result should be without doing any code. Then you can try out the code and verify whether the result matches what you expected.\nThe same principles that underlie producing good code also underlie debugging code. This is covered well in the corresponding chapter of Wickham’s Advanced R book, but essentially debugging involves (a) isolating where the problem arises; (b) understanding the conditions that resulted in the problem; (c) revising the code in an attempt to correct the problem or to prevent problematic circumstances from arising; and (d) testing to ensure the solution in fact addresses the problem. Working on small bits of code at a time makes all of the essential steps of debugging easier.\nR supports vectorization of many operations. While vectorization allows for code to run more efficiently, the resulting code can sometimes be harder to understand and debug. As a result, you may want to write a less efficient but easier to read version of your code first, so that you can verify that it works the way you expect. You can then see where you might want to try to make your code more efficient, using your original easy-to-read code to verify that any changes you make don’t alter the expected result.\nUsing named vectors/matrices/arrays can often be quite handy when you want to index values by using a string that describes their meaning or interpretation, rather than a numerical index. Not only can this make your code more interpretable, it avoids issues when you may not know ahead of time which numerical index contains a particular desired value.\nR has a tendency to recycle things in ways you may not expect! For example, when doing any operation involving multiple vectors, if one vector is shorter than the other, R will sometimes “recycle” the elements of the shorter vector to create a new vector that is the same length as the longer one. The rules that govern how R “recycles” are not consistently applied and can be hard to predict, therefore it is important to ensure that your code will not produce this kind of ambiguous situation. You may want to include error checks to ensure that vectors are the same length. Alternatively, if you want to recycle, you can do so explicitly so there is no ambiguity (e.g., x_recycled &lt;- rep(x, length(y))[1:length(y)]).\nAlways remember the drop option when subsetting an array, matrix, or data frame! If the subsetting procedure selects only a single element, unless you use drop = FALSE, the result will be a length-one vector that “throws out” the other dimensions of your data structure. This can result in bugs if your code assumes that the result of the subset will have a consistent number of dimensions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "r_coding.html#exercise-fibonnacci",
    "href": "r_coding.html#exercise-fibonnacci",
    "title": "3  Programming with R",
    "section": "3.2 Exercise: Fibonnacci",
    "text": "3.2 Exercise: Fibonnacci\nThe following set of R coding exercises are meant to prepare you for the kind of coding that will be involved in writing our first cognitive model simulations. It is not exhaustive of all the things that you can do with R, but it addresses many of the essentials. It also exemplifies the workflow involved in building a model:\n\nImplement the basic processes involved in a simple case where you know what the correct result should be, so you can ensure you have implemented these basics appropriately.\nBuild a function that generalizes the code you wrote in step 1 so that you can apply it to different parameter settings.\nUse your function to simulate different results using different parameter settings.\nExplore the range of results your function produces across parameter settings.\nOptionally, consider ways that you can generalize your model even further by incorporating additional parameters.\n\nThese exercises are based on everyone’s favorite sequence, the Fibonnacci sequence. The sequence is defined by a simple rule: the next value in the sequence is the sum of the previous two values. Written in Math, that’s: \\[\nf[i] = f[i - 2] + f[i - 1]\n\\] where \\(f[\\cdot]\\) is a value in the Fibonnacci sequence and \\(i\\) is the index of the next value. To get this sequence going, we need to know the first two values, \\(f[1]\\) and \\(f[2]\\). Typically, these are both set to 1. As a result, the beginning of the Fibonnacci sequence goes like this: \\[\n1, 1, 2, 3, 5, 8, 13, \\ldots\n\\]\nAnyway, let’s begin!\n\n3.2.1 Exercise 1\nWrite two versions of a chunk of code that will create a vector called fib that contains the first 20 values in the Fibonnacci sequence. Assume that the first two values in the sequence are 1 and 1. Write one version of the code that creates the vector by appending each new value to the end of fib. Write another version that assigns values to the corresponding entries in fib directly using the appropriate index (for this second version, you may want to use the rep function to create the fib vector).\n\n\n3.2.2 Exericse 2\nBased on the code you wrote for the previous exercise, write a function that returns a vector containing the first N terms of the Fibonnacci sequence. Your function should take two arguments, the value N and a vector called init that contains the first two values in the sequence. Give those arguments sensible default values. The chunk below gives a sense of the overall structure your function should have:\n\n\nCode\nfib_func &lt;- function(N = ___, init = ___) {\n    ...\n    return(fib)\n}\n\n\n\n\n3.2.3 Exercise 3\nWrite code that calls the function you wrote in the previous exercise several times, each time using a different value for the second value in the init argument (but the same value for N and for init[1]). Collect the results from each function call in a single data frame or tibble. The data frame or tibble should have a column that stores the second initial value, a column for the vector returned from the function, and a third column that is the value’s index within the sequence. An example of the kind of result you’re looking for is given below:\n\n\n# A tibble: 8 × 3\n  init2   fib     i\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     1     1     1\n2     1     1     2\n3     1     2     3\n4     1     3     4\n5     4     1     1\n6     4     4     2\n7     4     5     3\n8     4     9     4\n\n\n\n\n3.2.4 Exercise 4\nWrite code that uses the ggplot2 library to plot the values of the Fibonnacci sequence on the y-axis against their position in the sequence on the x-axis. Distinguish between different init2 values by using different colored lines. The result should look something like the plot below.\n\n\n\n\n\n\n\n\n\n\n\n3.2.5 Extension exercise\nWrite a new function that takes a third argument, n_back, which specifies how many of the previous values to add up to create the next value in the sequence. For the Fibonnacci sequence, n_back = 2, but in principle we could define other kinds of sequences too. Adapt the code you wrote for your previous exercises to explore what happens with different values of n_back. You may also want to include some code at the beginning of your function that checks to ensure that the number of initial values provided in the init argument is sufficient!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programming with R</span>"
    ]
  },
  {
    "objectID": "random_walk.html",
    "href": "random_walk.html",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "4.1 Out for a random walk\nThe random walk model is designed to account for two aspects of behavior: choice and response time (RT). These and similar models are applied in situations where a person (or other organism!) has to decide between a small number of possible alternatives, often just two. Such situations abound in experimental psychology, including lexical decision, recognition memory, detection tasks, search tasks, categorization tasks, etc. The models are designed to help us understand two things:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#out-for-a-random-walk",
    "href": "random_walk.html#out-for-a-random-walk",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "Why did a participant make the choices they made?\nWhy did it take the participant a certain amount of time to make the choices they made?\n\n\n4.1.1 Key theoretical constructs\nThe vast majority of models of choice and RT, including random walk and diffusion models, address the two questions above by invoking four basic theoretical constructs:\nEvidence accumulation: Choosing from among a set of options is assumed to require accumulating “evidence” that weighs either in favor of or against each option. This evidence may come from perception (e.g., deciding which of two stimuli is brighter), from memory (e.g., deciding whether an item was or was not on a previously-studied list), or from deliberation (e.g., deciding which of two products to buy). As such, the idea that decisions are made by accumulating evidence helps explain not only which choice was made (it was the option that was most favored by the accumulated evidence) and how long it took to made the choice (the time needed to accumulate sufficient evidence to commit to a decision).\nResponse caution: If decisions are made by accumulating evidence, there must be a policy that terminates the accumulation process, otherwise someone would keep accumulating evidence forever—and this is exactly what Buridan’s ass needs to avoid! The construct of “response caution” refers to the idea that, depending on the situation, a decision maker may adopt a policy of deciding quickly on the basis of very little evidence (low response caution) or deciding slowly by waiting for more evidence to accumulate (high response caution). Thus, this construct is directly related to the idea of speed-accuracy trade-off.\nResponse bias: It may be that a decision maker is willing to commit to some options more readily than others; in that case, we say they are “biased” in favor of those responses. Typically, this bias is modeled by assuming lower response caution for some options than others. In other words, a participant may be willing to commit to some decisions on the basis of less accumulated evidence than others.\nResidual time: The time needed to accumulate sufficient evidence to make a decision is not the only thing that contributes to observed response times. After all, it takes time to realize that a trial of a task has actually begun. It may also take time to retrieve relevant information from memory, to focus attention on relevant features in the environment, or to evaluate a potential outcome. Finally, it takes some time to execute the motor actions associated with the chosen option (e.g., to press a button, move a lever, etc.). The time for all of these additional processes is often called non-decision time (NDT) or encoding and response execution time (\\(T_{ER}\\)). However, I prefer to call it simply “residual time” because that is what it is—it is the time “left over” besides the time needed for evidence accumulation.\n\n\n4.1.2 Representing the current state of evidence\nThe random walk model assumes that, at any given time, a decision maker represents the current balance of evidence between two options as a number. We will creatively refer to this representation as \\(x(t)\\), where \\(x\\) stands for evidence and \\((t)\\) stands for the fact that it is the evidence at a specific time \\(t\\). The sign and magnitude of \\(x(t)\\) represents the extent to which the current value of evidence favors one option over the other.\nIf \\(x(t)\\) equals zero, then the evidence at time \\(t\\) does not favor either option. This is akin to the situation when Buridan’s ass first encounters the two piles of hay. If \\(x(t) &gt; 0\\), then the evidence favors one of the two options. For Buridan’s ass, perhaps positive values of evidence represent evidence in favor of going toward the pile of hay on the right. If \\(x(t) &lt; 0\\), then the evidence favors the other option. For Buridan’s ass, maybe negative values of evidence represent evidence in favor of going toward the pile of hay on the left. Notice that we could just as easily do it the other way around: positive evidence favors going left while negative evidence favors going right. The important thing is just that the two options are associated with opposite signs of evidence.\nIn a cognitive task, the two choices might be “word” and “non-word” in a lexical decision task, “old” and “new” in a recognition memory task, “present” and “absent” in a visual search task, “same” and “different” in a change detection task, “category A” and “category B” in a categorization task, etc. Again, the point is that, at any given time, the degree to which the decision maker’s accumulated evidence at time \\(t\\) favors one option or the other is represented by the value of a number \\(x(t)\\), with each option associated with opposite signs.\n\n\n4.1.3 Accumulating evidence\nThe value of \\(x(t)\\) represents the evidence that has been accumulated by time \\(t\\). But what does it mean to “accumulate” evidence? And what is the “evidence” that is accumulated?\nIn a random walk model, we assume that at regular time intervals (each interval has duration \\(\\Delta t\\)), the decision maker receives a “sample” of evidence, which we will label \\(\\Delta x(t)\\). This sample can take one of two values, \\(+1\\) or \\(-1\\). If it is \\(+1\\), the sample favors the option associated with positive evidence values (e.g., the pile of hay on the right) and if it is \\(-1\\), the sample favors the option associated with negative evidence values (e.g., the pile of hay on the left). To accumulate evidence means to add the new sample \\(\\Delta x(t)\\) to the current value of the accumulated evidence, i.e.: \\[\n\\overbrace{x(t + \\Delta t)}^{\\text{Updated evidence}} = \\overbrace{x(t)}^{\\text{Current accumulated evidence}} + \\overbrace{\\Delta x(t)}^{\\text{Current sample of evidence}}\n\\] Thus, the accumulated evidence \\(x(t)\\) is the sum of all the samples of evidence that were obtained by time \\(t\\).\n\n\n4.1.4 What is evidence?\nAt this point, it would be reasonable to ask where these samples of evidence come from. There is no single answer to this question because the random walk model, like most of the models of choice and RT we will consider, treats evidence in a very abstract sense. Later in the course, we will encounter models that instantiate specific theories of the “evidence” a decision maker may use in a specific context.\nTo return to Buridan’s ass, the evidence might be perceptual in nature: For an interval of time, the donkey looks at both piles of hay. Even though both piles are, by assumption, equally big, that may not always be visually apparent. During any finite interval of time, one pile might happen to look ever so slightly larger than the other, perhaps due to a quirk of the light, a sheaf fluttering in the breeze, the donkey’s visual acuity, etc. If the pile on the right happened to look a bit bigger than the one on the left during one of those intervals, then the sample of evidence for that interval would be \\(+1\\). Otherwise, it would be \\(-1\\). Because these minute differences are due to essentially chance factors, and they are equally likely to favor either pile, we can say that the probability of getting a sample that is either \\(+1\\) or \\(-1\\) is \\(0.5\\). While the evidence might not favor one pile over the other in the long run, it will favor one option over a finite interval of time, which is all any real decision maker has at their disposal. As we shall see shortly, this is the key to saving Buridan’s ass.\nTreating evidence as due, at least in part, to chance factors is why this model is called a “random” walk. It also highlights the fact that the evidence samples need not occur with equal frequency. Perhaps samples come up \\(+1\\) with probability \\(p\\) and otherwise come up \\(-1\\), like the proverbial biased coin flip. If the evidence consistently favors one option, that means that \\(p\\) is close to either 1 or 0. To the extent that chance factors influence the evidence, \\(p\\) will be closer to \\(0.5\\). We have now been introduced to the first parameter of the random walk model: \\(p\\), the probability of getting a sample of evidence that favors the option associated with positive evidence.\nThe figure below illustrates different ways that evidence might accumulate over time. Each step up or down is driven by the sample of evidence that was obtained at that time, which is assumed to be random with probability \\(p\\). The figure also illustrates why this model is called a random “walk”, because each trajectory kind of looks like a path that someone might have walked.\n\n\nCode\nexpand_grid(p = c(0.2, 0.5, 0.8), sim_index = 1:5, t = 1:20) %&gt;%\n    mutate(x_sample = 2 * rbinom(n = n(), size = 1, prob = p) - 1) %&gt;%\n    group_by(p, sim_index) %&gt;%\n    mutate(x_accum = cumsum(x_sample)) %&gt;%\n    ggplot(aes(x = t, y = x_accum, color = factor(p), group = interaction(p, sim_index))) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_step(alpha = 0.5) +\n    labs(x = \"Time interval\", y = \"Accumulated evidence\", color = \"p\")\n\n\n\n\n\n\n\n\n\nWhat about evidence in cognitive tasks? Buridan’s ass relies on the same kind of sensory evidence as one needs to do, for example, psychophysical tasks like picking which stimulus is brighter, more leftward-oriented, etc. Evidence derived from memory can also be noisy—perhaps when retrieving an event, you sometimes recall the color of an object as blue and sometimes as green. When deciding between different gambles or products, we may also shift attention to different features of those options, leading us to judge them as better or worse depending on which features we attend to (Busemeyer & Townsend, 1993; Diederich, 1997).\n\n\n4.1.5 Doing some code\nHaving now familiarized ourselves with how the random walk model represents a decision maker’s evidence and how it processes that evidence via accumulation, let’s see how we would write that model in code. Specifically, we will be writing code that simulates different possible random walks. The way we will do this is more of an intellectual exercise, since we will not be striving for efficiency (later on, we will use special-purposes R packages for that). Rather, the point here is to see how the conceptual aspects of a model can be implemented in code. We will add on to this code as we go.\nFor now, we know that we will have a line that looks something like the accumulation equation above:\n\n\nCode\nx &lt;- x + x_sample\n\n\nHere, x stands for the value of the accumulated evidence and x_sample stands for the current sample of evidence (which is either 1 or -1). The &lt;- evaluates the expression on the right and assigns it to the thing on the left, so the code above says “take the current value of x, add the new sample x_sample, and put it back as the new value of x”.\nWith the code above as the core of the model, we now need to do three things: first, specify how to get x_sample; second, obtain many such samples; third, keep a record of how the accumulated evidence changes over time.\n\n4.1.5.1 Sampling evidence\nTo get a value for x_sample, we will use R’s rbinom function, which generates a random sample from a binomial distribution. Specifically, the line rbinom(n = 1, size = 1, prob = 0.5) will generate a sample that equals 1 with probability 0.5, otherwise it equals zero. It is perhaps easiest to think of it in terms of a coin flip: The n parameter of the rbinom function says how many sets of coins to flip, size says how many coins we flip in each set, and prob is the probability that any single flip comes up heads. The number that rbinom gives is the number of heads in a particular set of flips.\nFor Buridan’s ass, the sample of evidence favors each pile equally often, so prob = 0.5 makes sense. Note that because rbinom returns either a 0 or a 1, we need to do some math to turn the result into \\(+1\\) or \\(-1\\). This is shown below.\n\n\nCode\nx_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\nx &lt;- x + x_sample\n\n\n\n\n4.1.5.2 Obtaining many samples\nThere are a few ways we can write code that will obtain many samples. To anticipate what we will be doing later, we will use the while control structure. We can use it to specify a condition such that, so long as the condition is met, a block of code will continue to be executed in a loop.\nOur condition will depend on the current time. Remember that, in the random walk, each sample of evidence arrives at fixed intervals of time. We will therefore need to keep track of the current time as well as the accumulated evidence. Similar to how we updated the evidence, we will need to keep track of t, the current time. We will also need to specify dt, the duration of each interval (otherwise known as \\(\\Delta t\\)), and t_max, the amount of time to keep accumulating evidence.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\nNotice that we specified values for t_max and dt outside the while loop. We can specify initial values for x and t the same way:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\n\n\n4.1.5.3 Keeping a record\nThe chunk of code above will work just fine! But unfortunately it does not leave a record of accumulated evidence over time that we can then examine, like we did with the graph above. In the chunk below, we use a fun trick to keep a record of each value of x and t: We create two vectors x_record and t_record and use the c function to concatenate the current values of x and t to these vectors:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\n\n\n\n4.1.5.4 Visualizing the record\nNow that we are keeping a record of evidence over time, let’s visualize it! The code below uses base R for that purpose, although the graph above uses ggplot2 which we will use again later. The type = \"s\" setting in the plot function at the end give the “step-like” plot.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\nplot(t_record, x_record, type = \"s\", xlab = \"Time\", ylab = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nTry copy-pasting the code above and running it yourself a few times to see what it looks like!\n\n\n4.1.5.5 Making a function\nIf we have a chunk of code that we want to re-run many times, we would do better to write a function that we can call instead of having to re-run the whole chunk. Writing a function also makes it easier to deal with parameters that can have different settings, like dt and t_max. We will also make the probability \\(p\\) a parameter too. Finally, the values for these three parameters in the function line are defaults.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, dt = 0.05, t_max = 5) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nNow we can call the function rw_sim with different settings to simulate different random walks. Note that, because the function returns t_record and x_record as different columns of a tibble, we can easily use ggplot2 to plot the results, as in the examples below.\n\n\nCode\nsim_result1 &lt;- rw_sim(p = 0.5, dt = 0.05, t_max = 5)\n\nsim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result2 &lt;- rw_sim(p = 0.2, dt = 0.05, t_max = 5)\n\nsim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.2\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result3 &lt;- rw_sim(p = 0.8, dt = 0.05, t_max = 5)\n\nsim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.8\")\n\n\n\n\n\n\n\n\n\nGo ahead, try it out yourself with different values of p, dt, and/or t_max. It’s fun! And if you don’t think the step graphs are too interesting, just imagine that each of those steps is Simon the donkey trying to decide between his two piles of hay.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#making-a-decision",
    "href": "random_walk.html#making-a-decision",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "4.2 Making a decision",
    "text": "4.2 Making a decision\nSo far, we have built a simple model of evidence accumulation. In this model, samples of “evidence” arrive at regular intervals, with the sample supporting either one option (\\(+1\\)) or the other (\\(-1\\)) with probability \\(p\\), and the decision maker accumulates these samples by summation. The resulting accumulated evidence thus starts at zero and takes a “random walk” that can drift upward (if \\(p &gt; 0.5\\)), downward (if \\(p &lt; 0.5\\)), or in no particular direction (if \\(p = 0.5\\)).\n\n4.2.1 Response boundaries\nWhat we have not done is say how the decision maker uses this accumulated evidence to decide between their two options. According to the random walk model, the decision maker sets two values prior to accumulating evidence. These values are called thresholds, criteria, or boundaries (these terms are often used interchangeably). There is one positive boundary and one negative boundary. If and when the accumulated evidence crosses one of these boundaries, the decision maker selects the corresponding option.\nFor example, say that Buridan’s ass will pick the pile on the right if his accumulated evidence ever gets greater than \\(+5\\) and he will pick the pile on the left if his accumulated evidence ever gets less than \\(-5\\). We can visualize this situation by overlaying lines at those two boundaries on the “random walk” of accumulating evidence:\n\n\nCode\nburidan_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nHere’s another one:\n\n\nCode\nburidan_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nGo ahead and try it out yourself!\nThe point is that we can read from these graphs which option the donkey ends up picking by seeing which boundary gets crossed first. We can also see when the donkey makes his decision based on how long it took for that first boundary-crossing to occur. This is how the random walk model ultimately produces both a choice (which boundary was crossed first) and an RT (how long it took). It is also why the random walk saves Buridan’s ass: Even if the evidence in the long run does not favor either option, by chance the accumulated evidence will at some point cross one of the boundaries, enabling the donkey to make a decision.\n\n\n4.2.2 Response bias\nIn the examples above, Buridan’s ass set his response boundaries to be of equal distance from the initial evidence value of zero. Burdian’s ass might be more willing to go to the leftward pile than the rightward one—maybe it is more aesthetically appealing or the donkey has a limp that makes it easier for him to walk left than right. This would amount to a bias in favor of one option (going left) over the other (going right).\nWe can instantiate this bias in the random walk model via the donkey’s response boundaries. For example, the donkey may go to the left if the accumulated evidence ever gets less than \\(-4\\) but would only be willing to go to the right if the accumulated evidence ever gets greater than \\(+6\\). The following two graphs illustrate these biased response boundaries.\n\n\nCode\nburidan_bias_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 1\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nburidan_bias_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 2\")\n\n\n\n\n\n\n\n\n\nIntuitively, it seems reasonable to expect that, if one boundary is closer to the start than the other, that two things will happen: First, the option associated with the closer boundary will be picked more often (at least if the evidence against that option is not too strong). Second, the decision maker will tend to be faster to pick the option associated with the closer boundary. We will verify these intuitions later, but for now you can rest assured that these intuitions are correct.\n\n\n4.2.3 Revising our function\nNow that we have gotten acquainted with the notion of response boundaries and how they can be biased, let’s incorporate them into our random walk simulation function from earlier. This will involve two things: First, we will need to add two parameters to the function, one for each boundary. Second, we will need to change the condition in the while loop so that the random walk stops when it reaches a boundary. As a corrollary to this second step, we will keep the t_max condition but adjust the default value of t_max.\nThe revised function is shown below, with some additional explanation following:\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nThe key changes we made to the rw_sim function are:\n\nAdding parameters b_upper and b_lower for the upper and lower response boundaries, respectively.\nChanging the default value of t_max to Inf for “infinity”. This means that, by default, reaching a boundary is the only way the random walk will stop. However, by leaving t_max as a parameter, it means that we can set it to some real number like 5 or 10 to force the random walk to stop eventually.\nChanging the condition in the while loop. Now the walk will continue so long as the evidence x is below the upper boundary (x &lt; b_upper) and above the lower boundary (x &gt; b_lower) and so long as the maximum time hasn’t been reached (t &lt; t_max). Note that the & is a “logical and” operator.\n\nHere are a few simulation runs—try it out yourself!\n\n\nCode\nboundary_sim_result1 &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5)\n\nboundary_sim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 5, b_lower = -5\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result2 &lt;- rw_sim(p = 0.5, b_upper = 6, b_lower = -4)\n\nboundary_sim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 6, b_lower = -4\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result3 &lt;- rw_sim(p = 0.7, b_upper = 6, b_lower = -4)\n\nboundary_sim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.7, b_upper = 6, b_lower = -4\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#residual-time",
    "href": "random_walk.html#residual-time",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "4.3 Residual time",
    "text": "4.3 Residual time\nWe are nearly done with our simulation model! We can model accumulating evidence and making a decision. The final ingredient arises from the fact that, while a decision maker might select one option at a particular time, we can only observe the behavioral consequences of that decision. Those behavioral consequences might be hitting a key, clicking a button, pressing a lever, or walking toward a pile of hay. Executing that behavior takes time in addition to the time needed to accumulate evidence and reach a response boundary. That additional time goes by many names, often “non-decision time” (NDT) or “encoding and responding” time (\\(T_{ER}\\)), but I prefer to simply call it residual time.\nFor now, we will adopt a simple assumption that this residual time is constant. Therefore, the observed response time will be the sum of the time needed for the random walk to reach a boundary plus the residual time associated with all the other processes that are involved in taking an action but which our model doesn’t explicitly enumerate.\nTo make this concrete, let’s introduce a parameter called t0 that will stand for residual time. While I cannot speak to what a plausible value of t0 would be for Buridan’s ass, in many cognitive tasks, it tends to be around 0.2 or 0.3 seconds, to account for the time needed to execute a simple motor action like hitting a button.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(tibble(t = t_record, x = x_record))\n}\n\n\nNote that the main change to our rw_sim function is that the initial value for the time t is no longer 0 but t0, i.e., the value of the residual time parameter.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#simulating-many-trials",
    "href": "random_walk.html#simulating-many-trials",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "4.4 Simulating many trials",
    "text": "4.4 Simulating many trials\nOur rw_sim function can now simulate single realizations of a random walk decision process. As we have seen, though, each realization of this process is different because the samples of evidence are random. If we want to get a sense of the kind of behavior the model tends to produce, we need to simulate many realizations of the decision and examine the distribution of choices and RT’s produced by the model. This is the same reason why, in a typical cognitive task, we collect multiple trials from each participant in each condition. With a real participant, we are limited by the time and energy that a participant is willing to commit. With a model, we are still limited by time and energy, but they are our time and the computer’s energy. Nonetheless, it is worth keeping in mind that all the techniques below for visualizing choices and RT’s apply to observed data as well as they apply to simulated data.\n\n4.4.1 Running and saving many simulation results\nWe will need to write some code that repeatedly calls our rw_sim function a large number of times and saves the results so we can examine them later. What follows is not necessarily the most efficient way of accomplishing those goals, but it is conceptually transparent and introduces the for loop. The comments (following the # marks) explain what is going on with the line below.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Get a quick sense of what the results look like\nglimpse(sim_results)\n\n\nRows: 25,884\nColumns: 3\n$ t         &lt;dbl&gt; 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, …\n$ x         &lt;dbl&gt; 0, -1, -2, -3, -2, -3, -4, -3, -2, -3, -4, -3, -4, -3, -2, -…\n$ sim_index &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, …\n\n\n\n\n4.4.2 Visualizing the random walks\nWhat we are about to do may be a bit silly but helps build some intuitions about what is going on in the model. We are going to make a plot that overlays all 1000 simulated random walks on top of each other. The point is to get a sense of how much variability there is from one realization to the next.\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x, group = sim_index)) +\n    geom_step(alpha = 0.1) +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nOkay, maybe it is a bit silly after all. But it is possible to see that things “thin out” at longer times as more and more random walks end by hitting a boundary. If you check out the code that generates the plot, note how group = sim_index was used to make sure each individual simulation, indexed by sim_index, got its own step-line on the graph. Also note the use of alpha = 0.1 to make each line semi-transparent so they could be overlayed on one another.\nLet’s try a different approach to visualize the same thing, using a heatmap that indicates the relative frequency with which the accumulated evidence takes different values at different times:\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\")\n\n\n\n\n\n\n\n\n\nAgain, what is important to see above is that all the random walks start at the same time and evidence value (the yellow region) and then “fan out” over time.\n\n\n4.4.3 Joint distributions of choice and RT\nWhat we visualized in the previous section are the internal states of the model, that is, how the model represents the decision maker’s current balance of evidence between their two options. Remember, though, that the model is ultimately judged on its externally-observable behavior, since that is all we have to compare it against. We are finally going to visualize the choices and response times produced by the model. As we shall see, however, there are a few ways to do this!\n\n4.4.3.1 Extracting choices and RT’s\nFor each simulation, the RT is the final value of t, since that is the time (plus residual time) at which the first boundary was crossed. Meanwhile, the choice is whether the evidence x is positive or negative. The chunk of code below takes our simulation results and extracts the final choices and RT from each simulation.\n\n\nCode\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\nglimpse(choice_rt)\n\n\nRows: 1,000\nColumns: 3\n$ sim_index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ choice    &lt;fct&gt; lower, lower, lower, upper, upper, lower, upper, lower, uppe…\n$ rt        &lt;dbl&gt; 1.05, 2.35, 0.95, 0.75, 0.55, 2.45, 1.15, 0.45, 1.35, 3.25, …\n\n\n\n\n4.4.3.2 Joint frequency plot\nThe code below plots the frequency with which each choice (upper or lower) is made at different times. This kind of plot is not terribly common, but is a quick way to get a sense of both how often each choice is made as well as the shape of the distributions of RT’s.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_freqpoly(binwidth = 0.2) +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n4.4.3.3 Conditional RT density\nThe code below plots the conditional density of the RT’s for each choice. This kind of plot is much more common, but doesn’t convey any information about the relative frequency with which different choices are made. Nonetheless, it illustrates how the random walk produces distributions of RT’s with a pronounced right skew, similar to RT distributions that are actually observed in choice tasks. Note that the conditional RT distributions for each choice are pretty similar to one another too.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n4.4.3.4 Quantile-probability plots\nIn the choice-RT modeling world, it is common to make “quantile-probability plots”, sometimes abbreviated to QP plots. These plots can be a bit confusing at first, but are useful because they convey information about choice proportions and RT distributions in a single graph.\nThe horizontal axis of a QP plot corresponds to the probability of having made a particular choice. In this case, that is the proportion of simulations that resulted in each choice. We can get that information in numerical form from our choice_rt tibble:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\n\n# A tibble: 2 × 3\n  choice     n p_resp\n  &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 upper    507  0.507\n2 lower    493  0.493\n\n\nThe vertical axis of a QP plot corresponds to different quantiles of the conditional RT distributions for each choice. Typically, those quantiles are the RT’s at the 10th, 30th, 50th, 70th, and 90th percentiles of the distribution. The reason for all of these quantiles is that they convey information about different aspects of the distribution: The 50th percentile, otherwise known as the median, conveys the central tendency. The 30th and 70th percentiles indicate where the “bulk” of the RT’s tend to fall. Finally, the 10th and 90th percentiles convey information about the lower and upper tails of the distribution, respectively. We can obtain those quantiles numerically like so:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\n\n# A tibble: 10 × 2\n   choice  rt_q\n   &lt;fct&gt;  &lt;dbl&gt;\n 1 upper   0.55\n 2 upper   0.75\n 3 upper   1.05\n 4 upper   1.55\n 5 upper   2.65\n 6 lower   0.55\n 7 lower   0.85\n 8 lower   1.25\n 9 lower   1.75\n10 lower   2.75\n\n\nTo make a QP plot, we need to “join” together the response proportions and RT quantiles into the same tibble:\n\n\nCode\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q)\n\n\nJoining with `by = join_by(choice)`\n\n\n# A tibble: 10 × 4\n   choice     n p_resp  rt_q\n   &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 upper    507  0.507  0.55\n 2 upper    507  0.507  0.75\n 3 upper    507  0.507  1.05\n 4 upper    507  0.507  1.55\n 5 upper    507  0.507  2.65\n 6 lower    493  0.493  0.55\n 7 lower    493  0.493  0.85\n 8 lower    493  0.493  1.25\n 9 lower    493  0.493  1.75\n10 lower    493  0.493  2.75\n\n\nThat joined tibble can then be used as the basis for our QP plot:\n\n\nCode\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#putting-it-all-together",
    "href": "random_walk.html#putting-it-all-together",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "4.5 Putting it all together",
    "text": "4.5 Putting it all together\nWe have used R to build a random walk model of decision making, implemented via a function called rw_sim, that accumulates samples of evidence until the accumulated evidence reaches either an upper or lower boundary. This model depends on several parameters, of which the most theoretically important are:\n\np: The probability that any given sample of evidence favors the option associated with the upper response boundary.\nb_upper: The upper response boundary.\nb_lower: The lower response boundary.\nt0: Residual time.\n\nWe also saw different ways that we can visualize both the internal states and external behavior of the model. It may be useful at this point to put together everything we have done so far into a single chunk of code. This will make your own explorations of this model easier.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#exercises",
    "href": "random_walk.html#exercises",
    "title": "4  Building a random walk model to simulate choice and RT",
    "section": "4.6 Exercises",
    "text": "4.6 Exercises\n\nSet the p parameter to something other than 0.5, so that the evidence tends to favor one option over the other. Do one set of simulations in which the response boundaries are equidistant from the starting value of 0 (you may need to play around to find values that you like). Do another set of simulations in which you keep the boundaries equidistant but make them closer to the starting point. What is the effect on the model’s choices and RT’s of having boundaries that are closer to the starting point?\nRun one set of simulations with the p parameter to 0.6 and the response boundaries equidistant from the starting point. Run another set of simulations keeping the response boundaries the same but increasing the p parameter to 0.8. What is the effect of increasing the p parameter on the RT distributions for making the “upper” choice? What is the effect of increasing the p parameter on the RT distributions for making the “lower” choice?\nImagine that, instead of each sample of evidence equalling either \\(+1\\) or \\(-1\\), the evidence could also equal \\(0\\). Write code to simulate this model and use your simulations to see how this model might differ from the random walk model we developed in this chapter.\n\nYou will need to introduce a new parameter to the model that represents the probability of getting a sample that equals zero. What ways can you think of to implement this aspect of the model? Which method did you pick and why?\nHow does the shape of the predicted RT distributions differ, if at all, from that predicted by the original random walk model? (Hint: you may want to explore settings in which there is zero probability of taking a step either up or down. It may also help to visualize the random walks themselves too.)\nWhat cognitive tasks might be better modeled by allowing for evidence to have a value of zero?\n\nTry implementing a model in which the residual time can vary randomly according to some distribution. Since residual time must be non-negative, you might consider distributions like the Gamma distribution or a uniform distribution between two positive values.\n\nHow did you implement random residual times?\nHow does random residual time affect the shape of the predicted RT distributions?\nWhat psychological factors might contribute to variability in residual time?\n\n\n\n\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A dynamic–cognitive approach to decision making in an uncertain environment. Psychological Review, 100(3), 432–459.\n\n\nDiederich, A. (1997). Dynamic stochastic models for decision making under time constraints. Journal of Mathematical Psychology, 41(3), 260–274. https://doi.org/10.1006/jmps.1997.1167",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Broadbent, D. E. (1957). A mechanical model for human attention and\nimmediate memory. Psychological Review, 64(3),\n205–215.\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A\ndynamic–cognitive approach to decision making in an uncertain\nenvironment. Psychological Review, 100(3), 432–459.\n\n\nCox, G. E., & Shiffrin, R. M. (2024). Computational models of event\nmemory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of\nhuman memory. Oxford University Press.\n\n\nDennett, D. (1980). The milk of human intentionality. Behavioral and\nBrain Sciences, 3(3), 428–430. https://doi.org/10.1017/s0140525x0000580x\n\n\nDiederich, A. (1997). Dynamic stochastic models for decision making\nunder time constraints. Journal of Mathematical Psychology,\n41(3), 260–274. https://doi.org/10.1006/jmps.1997.1167\n\n\nGillespie, N. F., & Cox, G. E. (2024). Perception and memory for\nnovel auditory stimuli: Similarity, serial position, and list\nhomogeneity. PsyArXiv. https://doi.org/10.31234/osf.io/n294a\n\n\nNeisser, U. (1967). Cognitive psychology.\nAppleton-Century-Crofts.\n\n\nNosofsky, R. M. (1986). Attention, similarity, and the\nidentification-categorization relationship. Journal of Experimental\nPsychology: General, 115(1), 39–57.\n\n\nNosofsky, R. M. (1992). Similarity scaling and cognitive process models.\nAnnual Review of Psychology, 43, 25–53.\n\n\nNosofsky, R. M., Cox, G. E., Cao, R., & Shiffrin, R. M. (2014). An\nexemplar-familiarity model predicts short-term and long-term probe\nrecognition across diverse forms of memory search. Journal of\nExperimental Psychology: Learning, Memory, and Cognition,\n40(6), 1524–1539.\n\n\nNosofsky, R. M., Little, D. R., Donkin, C., & Fific, M. (2011).\nShort-term memory scanning viewed as exemplar-based categorization.\nPsychological Review, 118(2), 280–315.\n\n\nNosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random\nwalk model of speeded classification. Psychological Review,\n104(2), 266–300.\n\n\nShepard, R. N. (1962a). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nI. Psychometrika, 27(2), 125–140.\nhttps://doi.org/https://doi.org/10.1007/BF02289630\n\n\nShepard, R. N. (1962b). The analysis of proximities:\nMultidimensional scaling with an unknown distance function.\nII. Psychometrika, 27(3), 219–246.\nhttps://doi.org/https://doi.org/10.1007/BF02289621\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober,\nC. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D.,\nNavarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service\nof science: Don’t let the tail wag the dog. Computational Brain\n& Behavior.",
    "crumbs": [
      "References"
    ]
  }
]
# Associative Learning

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(colorspace)
library(khroma)
library(mvtnorm)

set.seed(12222)
```

In the previous chapter, we saw several different examples of how computational cognitive models can *represent* the sorts of things we do cognition about: words, concepts, objects, events, etc.  The representations were treated as given, either from a statistical procedure like Multidimensional Scaling or machine learning or from our own knowledge/expertise regarding the physical and conceptual features of items (like color, size, shape, etc.).  Although one can view storage of new exemplars in memory as a kind of learning (see the Exercises), this chapter focuses on the kind of *associative learning* that is thought to underlie a variety of phenomena in cognition.  Associative learning refers to the formation of functional links/connections/associations between elements that frequently co-occur.  This form of learning is important for learning how words and referents go together, what properties objects have, and how to make predictions about what may happen next.

An important distinction in this form of learning is between *supervised* and *unsupervised* learning.  In *unsupervised* learning, the learner does not have an explicit goal; as such, unsupervised learning often amounts to forming a representation of the patterns of correlation between elements in the learner's environment.  In *supervised* learning, the learner has a particular goal they are trying to achieve; in supervised learning, the learner gets feedback either from a "teacher" or from the environment itself about how well they achieved their goal.  In supervised learning, the learner tries to form a representation that minimizes their "error", that is, the discrepancy between the learner's goal and the feedback they received.

The *representations* we explored in the last chapter all took the form of *vectors* which characterized the properties of items that someone might encounter.  Since associative learning involves learning how properties go with one another, we will introduce another type of representation in this chapter:  A *matrix* of *associative weights*.  All the forms of learning we will examine in this chapter amount to making adjustments to the entries in one or more of these matrices.  We'll first see how this principle plays out in the context of a simple but powerful form of unsupervised learning: Hebbian learning.

## Hebbian learning

Although this form of learning takes its name from @Hebb1949, the basic idea has been around since at least the ancient Greeks.  The idea is that things that are experienced at the same time become associated with one another.  Eventually, experiencing one thing "activates" or "evokes" or "retrieves" other things that were frequently encountered alongside it.  In more recent times, the principle has been applied to neurons, giving rise to the dictum that "neurons that fire together wire together".

To model Hebbian learning, we assume that the learner experiences discrete learning "events".  These "events" are analogous to the kinds of memory traces we used in the EBRW: each event is represented as a vector with $D$ dimensions.  These representations can be localist or either separable or integral distributed.  Learning is modeled by making adjustments in a $D \times D$ matrix, where the entry in the $i$th row and $j$th column is the *associative weight* between element $i$ and element $j$ of the event representations.  These weights get updated each time an event occurs.  As a result, the weights eventually come to represent the ways that different event element co-vary with one another.

### Representing learning events

Let's make this concrete by thinking back to the Blast cell example.  Recall that those data involved participants with varying degrees of expertise in identifying whether a cell was a potentially cancerous "blast" cell or not, just by looking at a picture of the cell.  Let's imagine a related but somewhat simpler scenario, based on those used by @MedinEtAl1982, that puts us in the position of being a novice gradually learning to become an expert.

Imagine that we are new doctors reading case reports that describe the presence or absence of four symptoms in each patient.  For the moment, we are only interested in how these different symptoms may or may not co-vary with one another.  The four symptoms are swollen eyelids, splotchy ears, discolored gums, and nosebleed.  We have eight patient reports, and we can represent each report using a *separable distributed vector* with $D = 4$ dimensions.  As shown below, we can represent the presence of a symptom with a `1` and its absence with a `0`.

```{r}
#| code-fold: show

event <- matrix(c(
    0, 0, 1, 1,
    1, 1, 1, 1,
    0, 1, 0, 0,
    1, 1, 1, 1,
    1, 0, 1, 1,
    1, 1, 0, 0,
    0, 1, 1, 1,
    1, 0, 0, 0
), nrow = 8, ncol = 4, byrow = TRUE,
dimnames = list(
    c("EM", "RM", "JJ", "LF", "AM", "JS", "ST", "SE"),
    c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed")
))

knitr::kable(event)
```

### Updating associative weights

Before reading any of the patient reports, we are a tabula rasa, a "blank slate".  That means we don't know anything about how any of the symptoms go together.  This state of initial ignorance is represented by an associative weight matrix that is filled with zeros.  This is illustrated below.

```{r}
#| code-fold: show

assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(event), dimnames = list(colnames(event), colnames(event)))

knitr::kable(assc_weights)
```

Now we read the first patient report:

```{r}
print(event[1,])
```

How should we update our matrix of associative weights on the basis of this report?  Since discolored gums and nosebleed were both present, we should increment the cells of the matrix corresponding to the combination of those symptoms.  Moreover, since discolored gums and nosebleed are both present with themselves, we might as well update those cells of the matrix too.  The result is that our new matrix might look something like this:

```{r}
knitr::kable(assc_weights + outer(event[1,], event[1,]))
```

To formalize what we just did, we will draw on one concept we have already seen and another concept we've sort of seen, if through a glass darkly.  For the concept we have seen, recall that our models of choice and response time involved *accumulating* samples of evidence, where we added the new sample to a "running total".  That's exactly how we will be updating our matrix of associative weights, and we can write it formally like this:
$$
W(t + 1) = W(t) + \Delta W(t)
$$
where $W(t)$ is our matrix of associative weights at the current time ($t$), $W(t + 1)$ is our updated matrix after experiencing the learning event that occurs at time $t$, and $\Delta W(t)$ is how we *change* our weights on the basis of the learning event experienced at time $t$.  This is just like accumulating samples of evidence, but instead we are accumulating changes in associative weights over time.

Now for the thing we haven't exactly seen, at least not in this form:  Where do we get $\Delta W(t)$?  Since we are talking about adding something to a $D \times D$ matrix, we already know that $\Delta W(t)$ must also be a $D \times D$ matrix.  We also know conceptually what $\Delta W(t)$ needs to do:  It needs to represent the *combinations* of features that were present in the learning event at time $t$.  Recall from last chapter that, when dealing with binary 0/1 vectors, the *dot product* between two such vectors gave us a count of the number of features that were present (i.e., coded as `1`) in each representation.  This is because when $x_{ik} = 1$ and $x_{jk} = 1$, $x_{ik} x_{jk} = 1$, otherwise $x_{ik} x_{jk} = 0$.  This is the idea behind what we are about to do.

We can get $\Delta W(t)$ by taking the *outer product* of the learning event representation $\mathbf{x}(t)$ with itself.  The outer product between two vectors $\mathbf{a}$ and $\mathbf{b}$ is sometimes written $\mathbf{a} \otimes \mathbf{b}$.  If $\mathbf{a}$ has length $N$ and $\mathbf{b}$ has length $M$, then $\mathbf{a} \otimes \mathbf{b}$ is an $N \times M$ *matrix* where the entry in the $i$th row and $j$th column is the *product* between the $i$th element of $\mathbf{a}$ and the $j$th element of $\mathbf{b}$.  This is illustrated in the example below, showing that the `outer` function in R gives us the outer product.

```{r}
#| code-fold: show

a <- c(1, 0, 0, 1)
b <- c(1, 0, 1)

# Outer product of a and b
outer(a, b)

# Outer product of a with itself
outer(a, a)

# Outer product of b with itself
outer(b, b)
```

So if the vector $\mathbf{x}(t)$ represents the learning event experienced at time $t$, then
$$
\Delta W(t) = \lambda \left[ \mathbf{x}(t) \otimes \mathbf{x}(t) \right]
$$
where $\lambda$ is a parameter that represents the $learning rate$.  In the present example, we will keep things simple and assume $\lambda = 1$, but we will make use of this parameter later.

Getting back to our symptom example, we can write the update procedure in R like this:

```{r}
#| code-fold: show

learning_rate <- 1
i <- 1

assc_weights <- assc_weights + learning_rate * outer(event[i,], event[i,])
```

You might already anticipate where we are going:  We can use a `for` loop to update the matrix of associative weights for *each* learning "event", i.e., for each patient record we read.

```{r}
#| code-fold: show

# Initialize weights to zero
assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(event))

# Specify learning rate
learning_rate <- 1

# Update weights for each event
for (i in 1:nrow(event)) {
    assc_weights <- assc_weights + learning_rate * outer(event[i,], event[i,])
}

knitr::kable(assc_weights)
```

### Using what you've learned

Via Hebbian learning, we have accumulated information about the co-occurrence patterns of different features (symptoms) across a series of learning events (patient records).  We can use the resulting matrix of associative weights to do something that has been labeled in a few ways, such as *cued recall*, *pattern completion*, *inference*, and *fill-in-the-blanks*.  The idea is that if we know that a patient has *some* symptoms, we can use the matrix of associative weights to make a reasonable guess about whether they have *other* symptoms, based on the degree to which those other symptoms co-occurred with the ones we know about.  As the various names listed above imply, this is the same kind of process that goes on when we, say, correctly infer that penguins have wings by knowing that they have beaks and webbed feet (we might also *incorrectly* infer that penguins can fly for the same reason!).

Say, for example, that we know a patient has discolored gums.  By looking at the corresponding row in our matrix of associative weights, we can see that this symptom co-occurs with nosebleed more often than it does with either swollen eyelids or splotchy ears, as shown below.

```{r}
assc_weights["discolored_gums",]
```

Of course, the entries in our associative weight matrix are just numbers, they are not behavior.  We need an additional *process* that enables us to predict behavior on the basis of the knowledge represented by the associative weight matrix.  The relevant behavior here is whether or not you would be willing to say that a patient had symptom $k$---this is a *choice*.  We could also model the response time associated with that choice (see the Exercises), but for now we only focus on choice behavior.

Specifically, we will transform the numbers extracted from the associative weight matrix into *probabilities* using the *logistic function*.  This function will be familiar if you've done logistic regression, since it transforms unrestricted real numbers into the range between zero and one.  The formula for the logistic function is
$$
f(x) = \frac{1}{1 + \exp \left(-x \right)}
$$
and it looks like this:

```{r}
tibble(x = seq(-6, 6, length.out = 501)) %>%
    mutate(y = 1 / (1 + exp(-x))) %>%
    ggplot(aes(x = x, y = y)) +
    geom_line() +
    labs(x = "x", y = expression(f(x)), title = "Logistic function")
```

As shown above, the logistic function returns values greater than 0.5 whenever its argument $x$ is a positive number.  When $x$ is negative, the logistic function returns values less than 0.5.  And if $x = 0$, the logistic function is exactly 0.5.

We can apply the logistic function to the row of the associative weight matrix above:

```{r}
#| code-fold: show

1 / (1 + exp(-assc_weights["discolored_gums",]))
```

Of course, we can probably ignore the entry for `discolored_gums` because we already know the patient has those!  Looking at the other probabilities, they are pretty big, reflecting the fact that the associative weights are also pretty large.  The magnitude of the weights depends on the learning rate parameter.  The chunk of code below shows what happens if we reduce the learning rate.

```{r}
#| code-fold: show

# Initialize weights to zero
assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(event))

# Specify learning rate
learning_rate <- 0.2

# Update weights for each event
for (i in 1:nrow(event)) {
    assc_weights <- assc_weights + learning_rate * outer(event[i,], event[i,])
}

knitr::kable(assc_weights)

1 / (1 + exp(-assc_weights["discolored_gums",]))
```

With a smaller learning rate, the probabilities are not so extreme, and there is a bigger difference between the larger probabilities and smaller probabilities.  Even so, we can anticipate that more learning will cause these weights to keep increasing and the probabilities to increase along with them.  How can we address this counterintuitive behavior?

### Discriminative learning

The fault, as it turns out, is not in our stars but in our representations.  Recall that we coded the presence/absence of symptoms as `1` or `0`.  As a result, associative weights can only ever increase with learning.  To avoid this, we can instead code the absence of a symptom as `-1`.  By using negative values, we can represent the *absence* of a feature more explicitly, thereby allowing us to learn to *discriminate* between the presence or absence of different features.

First, let's see what our learning event representations look like now:

```{r}
#| code-fold: show

event <- matrix(c(
    -1, -1,  1,  1,
     1,  1,  1,  1,
    -1,  1, -1, -1,
     1,  1,  1,  1,
     1, -1,  1,  1,
     1,  1, -1, -1,
    -1,  1,  1,  1,
     1, -1, -1, -1
), nrow = 8, ncol = 4, byrow = TRUE,
dimnames = list(
    c("EM", "RM", "JJ", "LF", "AM", "JS", "ST", "SE"),
    c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed")
))

knitr::kable(event)
```

Now let's see what happens when we take the outer product of the first learning event with itself:

```{r}
#| code-fold: show

outer(event[1,], event[1,])
```

We can see that the fact that discolored gums and nosebleed were both present while swollen eyelids and splotchy ears were not will result in a *lowering* of the associative weight between those two sets of symptoms.

Now let's see what the final set of associative weights looks like:

```{r}
#| code-fold: show

# Initialize weights to zero
assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(event))

# Specify learning rate
learning_rate <- 1

# Update weights for each event
for (i in 1:nrow(event)) {
    assc_weights <- assc_weights + learning_rate * outer(event[i,], event[i,])
}

knitr::kable(assc_weights)
```

Now if we know a patient has discolored gums, we are very sure that they also have nosebleed and are equivocal about whether or not they have swollen eyelids or splotchy ears, as shown below:

```{r}
#| code-fold: show

1 / (1 + exp(-assc_weights["discolored_gums",]))
```

On the other hand, if we know a patient has swollen eyelids, we don't have any strong opinions about whether or not they have any other symptoms (though we think it is more likely than not).  Note that this is a consequence of the fact that discolored gums and nosebleed did tend to co-occur in our training events, whereas swollen eyelids did not systematically covary with any other symptoms.

```{r}
#| code-fold: show

1 / (1 + exp(-assc_weights["swollen_eyelids",]))
```

### Using multiple cues

So far, we have only thought about situations in which a single symptom was given for a new patient.  What if we know that a patient has 2 symptoms or 3?  Or what if we know they do *not* have a particular symptom?  To address these situations, we need to go beyond just looking at a single row at a time.

To appreciate what we are about to do, imagine that we knew a patient had discolored gums and that they did *not* have swollen eyelids.  In that case, the strength of support for each feature would be the row corresponding to `discolored_gums` *minus* the row corresponding to `swollen_eyelids`, as shown below:

```{r}
#| code-fold: show

assc_weights["discolored_gums",] - assc_weights["swollen_eyelids",]
```

When we apply the logistic function to the vector above, we are still equivocal about splotchy ears but we are actually *more* sure that they have nosebleed:

```{r}
#| code-fold: show

1 / (1 + exp(-(assc_weights["discolored_gums",] - assc_weights["swollen_eyelids",])))
```

We can make the logic of what we just did to obtain that prediction more general.  We will again make use of some linear algebra.  Specifically, we will obtain the "strength of support" for each symptom by multiplying the matrix of associative weights with a vector that encodes the presence/absence/missingness of each known symptom.  This vector is called a "probe" or a "cue", and the result will be another vector that gives the total degree of support for each symptom.  In math, we can write the operation like this:
$$
\mathbf{o} = \mathbf{c} W
$$
where $\mathbf{c}$ is the cue (or probe) vector and $\mathbf{o}$ is the "output" vector.

The example above corresponds to the following cue vector:

```{r}
#| code-fold: show

cue <- c(-1, 0, 1, 0)
names(cue) <- rownames(assc_weights)

print(cue)
```

Notice that we use `-1` to code for the *known absence* of a feature, `1` to code for the *known presence* of a feature, and `0` to code for "missing knowledge" about a feature.

We can use the `cue` vector to "probe" the associative weight matrix.  In R, matrix multiplication uses the `%*%` operator (think of it as a "fancy multiplication").  So the code below directly implements the equation listed above:

```{r}
cue %*% assc_weights
```

And as we hoped, we get the same result from our fancy linear algebra as we did when we did it by hand earlier.  The point of introducing this linear algebra now is that it will generalize more readily to situations in which we have more complex event representations (e.g., integral representations).

### Associating events with actions

In the preceding examples, the learner associated features of events with one another, but now we consider how to model learning the relations between features of events and *outcomes* or *actions*.  In the context of our ongoing medical example, imagine that a new doctor is learning to diagnose whether or not someone has a particular disease based on the pattern of symptoms they display.  Now, instead of associating symptoms with symptoms, the doctor needs to associate symptoms with the presence/absence of the disease.  Modeling this form of learning will require making two changes to the Hebbian learning model we have been building so far.

First, we need to redefine the associative weight matrix $W$.  Before, it was $D \times D$, where $D$ is the number of dimensions in our learning event representations.  Now, it will be $D \times O$, where $O$ is the number of dimensions used to represent the available actions.  Sometimes, as in some of the examples below, $O$ will equal 1 if the learner just needs to decide whether to take an action or not (e.g., whether or not someone has a disease).  But in general, $O$ could have many dimensions if the learner can take many actions or if the actions are sufficiently complex that they require a distributed representation.  The entry in the $i$th row and $j$th column of our new associative weight matrix will represent the strength of association between event dimension $i$ and action/outcome dimension $j$.

The other thing we need to do is define, for each learning event, the "label" or "correct answer" that is associated with it.  In the model implementation below, we do this by having two matrices:  an `event` matrix that stores the features of each learning event, with one row per event and one column per feature; and a `target` matrix that stores the "correct answer" for each event, with one row per event and one column per outcome dimension.

The example below uses the same set of symptoms as our running example.  The first four patients were diagnosed with a disease while the second four were not.

```{r}
#| code-fold: show

event <- matrix(c(
     1,  1,  1,  1,
    -1,  1, -1, -1,
     1, -1, -1,  1,
     1, -1, -1, -1,
     1, -1,  1,  1,
    -1, -1,  1, -1,
    -1,  1, -1,  1,
    -1, -1, -1, -1
), nrow = 8, ncol = 4, byrow = TRUE, dimnames = list(
    c(paste0("T", 1:4), paste0("F", 1:4)),
    c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed")
))

target <- matrix(c(
     1,
     1,
     1,
     1,
    -1,
    -1,
    -1,
    -1
), nrow = 8, ncol = 1, byrow = TRUE, dimnames = list(
    c(paste0("T", 1:4), paste0("F", 1:4)),
    c("Diagnosis")
))

assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(target))

learning_rate <- 1

for (i in 1:nrow(event)) {
    assc_weights <- assc_weights + learning_rate * outer(event[i,], target[i,])
}

knitr::kable(assc_weights)
```

In the end, the new doctor has learned that swollen eyelids are strongly diagnostic of the disease, splotchy ears are weakly diagnostic, discolored gums are weakly counter-indicative of the disease, and nosebleed is uninformative.

Notice that all we needed to do to model this form of associative learning was to swap out `event` for `target`.  Formally, we can specify the learning procedure like this:
$$
\Delta W(t) = \lambda \left[ \mathbf{x}(t) \otimes \mathbf{t}(t) \right]
$$
where $\lambda$ and $\mathbf{x}(t)$ are as defined above and $\mathbf{t}(t)$ is the vector representation of the *target* ("correct answer") for the learning event experienced at time $t$.

<!-- In the following example, the first two features are largely diagnostic of which disease it is.  However, a learner could also pick up on the higher-order regularity that terrigitis is associated with the last two features either both being present or both absent, whereas midosis is associated with those features being anti-correlated. -->

<!-- ```{r} -->
<!-- #| code-fold: show -->

<!-- event <- matrix(c( -->
<!--      1,  1,  1,  1, -->
<!--     -1,  1,  1,  1, -->
<!--      1,  1, -1, -1, -->
<!--      1, -1, -1, -1, -->
<!--      1, -1,  1, -1, -->
<!--     -1, -1,  1, -1, -->
<!--     -1,  1, -1,  1, -->
<!--     -1, -1, -1,  1 -->
<!-- ), nrow = 8, ncol = 4, byrow = TRUE, dimnames = list( -->
<!--     c(paste0("T", 1:4), paste0("M", 1:4)), -->
<!--     c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed") -->
<!-- )) -->

<!-- response <- matrix(c( -->
<!--      1, -1, -->
<!--      1, -1, -->
<!--      1, -1, -->
<!--      1, -1, -->
<!--     -1,  1, -->
<!--     -1,  1, -->
<!--     -1,  1, -->
<!--     -1,  1 -->
<!-- ), nrow = 8, ncol = 2, byrow = TRUE, dimnames = list( -->
<!--     c(paste0("T", 1:4), paste0("M", 1:4)), -->
<!--     c("Terrigitis", "Midosis") -->
<!-- )) -->

<!-- assc_weights <- matrix(0, nrow = ncol(event), ncol = ncol(response)) -->

<!-- learning_rate <- 1 -->

<!-- for (i in 1:nrow(event)) { -->
<!--     assc_weights <- assc_weights + learning_rate * outer(event[i,], response[i,]) -->
<!-- } -->

<!-- knitr::kable(assc_weights) -->

<!-- transfer_event <- matrix(c( -->
<!--     -1, -1, -1, -1, -->
<!--     -1, -1,  1,  1, -->
<!--     -1,  1, -1, -1, -->
<!--      1, -1,  1,  1, -->
<!--      1,  1,  1, -1, -->
<!--      1,  1, -1,  1, -->
<!--     -1,  1,  1, -1, -->
<!--      1, -1, -1,  1 -->
<!-- ), nrow = 8, ncol = 4, byrow = TRUE, -->
<!-- dimnames = list( -->
<!--     paste0("N", 1:8), -->
<!--     c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed") -->
<!-- )) -->

<!-- p_resp <- matrix(0, nrow = nrow(transfer_event), ncol = ncol(response), dimnames = list(rownames(transfer_event), colnames(response))) -->

<!-- for (i in 1:nrow(transfer_event)) { -->
<!--     p_resp[i,] <- 1 / (1 + exp(-transfer_event[i,] %*% assc_weights)) -->
<!-- } -->

<!-- knitr::kable(p_resp) -->
<!-- ``` -->

## Error-driven learning

This was a form of *unsupervised* learning, since the learner had no explicit *goal* other than to learn.  In *supervised* learning, a learner associates features of events with different *actions* or *outcomes*.  Each time a learning event occurs, the learner uses the features of that event to form a representation of the action/outcome they select.  The learner then receives feedback telling them the correct action/outcome they *should* have chosen.  The goal of the learner is to adjust their associative weights in such a way that they reduce the discrepancy between the action/outcome they pick and the one they are told is correct.

The new doctor examines the symptoms of a patient report (this is the "learning event"), makes a diagnosis (this is the chosen action/outcome), and then gets told what the *correct* diagnosis would have been for that patient (this is the feedback).  The new doctor then has to adjust the pattern of associations between symptoms (learning event features) and diagnoses (actions/outcomes).

We can imagine the same kind of learning occurring in many situations:  When you are learning language, you might choose which word to use to describe an object based on its visible features (e.g., calling a black and white creature with four legs a "zebra") and then someone nearby would either confirm your choice or provide the correct name (e.g., "no, that's a dalmatian").  When you are learning a skill like using a tool or playing an instrument, you take an action (e.g., pressing a key on a keyboard) and then get feedback about whether it was correct or not (e.g., you hear the correct note you should have played).

<!-- ## Learning representations by backpropagation of error -->

<!-- ```{r} -->
<!-- #| code-fold: show -->

<!-- logistic_act <- function(x) { -->
<!--     return(1 / (1 + exp(-x))) -->
<!-- } -->

<!-- event <- matrix(c( -->
<!--      1,  1, -->
<!--      1, -1, -->
<!--     -1,  1, -->
<!--     -1, -1 -->
<!-- ), nrow = 4, ncol = 2, byrow = TRUE) -->

<!-- response <- matrix(c( -->
<!--     0, -->
<!--     1, -->
<!--     1, -->
<!--     0 -->
<!-- ), nrow = 4, ncol = 1, byrow = TRUE) -->

<!-- learning_rate <- 0.1 -->
<!-- n_hidden <- 4 -->
<!-- n_epochs <- 10000 -->
<!-- learn_by_epoch <- TRUE -->

<!-- i_to_h_assc_weights <- matrix(rnorm(n = ncol(event) * n_hidden, sd = 0.01), nrow = ncol(event), ncol = n_hidden) -->
<!-- h_to_o_assc_weights <- matrix(rnorm(n = n_hidden * ncol(response), sd = 0.01), nrow = n_hidden, ncol = ncol(response)) -->

<!-- for (epoch in 1:n_epochs) { -->
<!--     training_order <- sample(nrow(event)) -->

<!--     d_h_to_o <- 0 * h_to_o_assc_weights -->
<!--     d_i_to_h <- 0 * i_to_h_assc_weights -->

<!--     for (i in training_order) { -->
<!--         # Forward propagation (prediction) -->

<!--         # Note the use of `as.vector` to ensure result is a vector (not a matrix with a single row) -->
<!--         # We also allow hidden units to have activations between -1 and 1 by scaling/shifting the logistic function. -->
<!--         # This means we have to multiply the derivative on the error by the scaling factor (2) during back-propagation -->
<!--         hidden_activation <- 2 * logistic_act(as.vector(event[i,] %*% i_to_h_assc_weights)) - 1 -->
<!--         output_activation <- logistic_act(as.vector(hidden_activation %*% h_to_o_assc_weights)) -->

<!--         # Compute error at output layer -->
<!--         output_error <- output_activation - response[i,] -->

<!--         # Back propagation (learning) -->

<!--         # Derivative of error with respect to output unit activation -->
<!--         d_output_error <- output_error * output_activation * (1 - output_activation) -->

<!--         # Derivative of error with respect to hidden unit activation -->
<!--         # Note that multiplying by 2 is a consequence of the hidden units having shifted/scaled activation that ranges between -1 and 1 rather than between 0 and 1. -->
<!--         d_hidden_error <- as.vector(h_to_o_assc_weights %*% d_output_error) * 2 * hidden_activation * (1 - hidden_activation) -->

<!--         if (learn_by_epoch) { -->
<!--             # How much to adjust the associative weights between the hidden and output layers -->
<!--             d_h_to_o <- d_h_to_o + learning_rate * outer(hidden_activation, d_output_error) -->

<!--             # How much to adjust the associative weights between the input and hidden layers -->
<!--             d_i_to_h <- d_i_to_h + learning_rate * outer(event[i,], d_hidden_error) -->
<!--         } else { -->
<!--             d_h_to_o <- learning_rate * outer(hidden_activation, d_output_error) -->
<!--             d_i_to_h <- learning_rate * outer(event[i,], d_hidden_error) -->

<!--             # Adjust weights -->
<!--             i_to_h_assc_weights <- i_to_h_assc_weights + d_i_to_h -->
<!--             h_to_o_assc_weights <- h_to_o_assc_weights + d_h_to_o -->
<!--         } -->
<!--     } -->

<!--     if (learn_by_epoch) { -->
<!--         # Adjust weights -->
<!--         i_to_h_assc_weights <- i_to_h_assc_weights + d_i_to_h -->
<!--         h_to_o_assc_weights <- h_to_o_assc_weights + d_h_to_o -->
<!--     } -->
<!-- } -->

<!-- transfer_event <- matrix(c( -->
<!--      1,  1, -->
<!--      1, -1, -->
<!--     -1,  1, -->
<!--     -1, -1 -->
<!-- ), nrow = 4, ncol = 2, byrow = TRUE) -->

<!-- p_resp <- matrix(0, nrow = nrow(transfer_event), ncol = ncol(response), dimnames = list(rownames(transfer_event), colnames(response))) -->

<!-- for (i in 1:nrow(transfer_event)) { -->
<!--     hidden_activation <- 2 * logistic_act(as.vector(transfer_event[i,] %*% i_to_h_assc_weights)) - 1 -->
<!--     p_resp[i,] <- logistic_act(as.vector(hidden_activation %*% h_to_o_assc_weights)) -->
<!-- } -->

<!-- knitr::kable(p_resp) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| code-fold: show -->

<!-- logistic_act <- function(x) { -->
<!--     return(1 / (1 + exp(-x))) -->
<!-- } -->

<!-- event <- matrix(c( -->
<!--      1,  1,  1,  1, -->
<!--     -1,  1,  1,  1, -->
<!--      1,  1, -1, -1, -->
<!--      1, -1, -1, -1, -->
<!--      1, -1,  1, -1, -->
<!--     -1, -1,  1, -1, -->
<!--     -1,  1, -1,  1, -->
<!--     -1, -1, -1,  1 -->
<!-- ), nrow = 8, ncol = 4, byrow = TRUE, dimnames = list( -->
<!--     c(paste0("T", 1:4), paste0("M", 1:4)), -->
<!--     c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed") -->
<!-- )) -->

<!-- response <- matrix(c( -->
<!--     1, 0, -->
<!--     1, 0, -->
<!--     1, 0, -->
<!--     1, 0, -->
<!--     0, 1, -->
<!--     0, 1, -->
<!--     0, 1, -->
<!--     0, 1 -->
<!-- ), nrow = 8, ncol = 2, byrow = TRUE, dimnames = list( -->
<!--     c(paste0("T", 1:4), paste0("M", 1:4)), -->
<!--     c("Terrigitis", "Midosis") -->
<!-- )) -->

<!-- response <- response[,1, drop = FALSE] -->

<!-- learning_rate <- 0.1 -->
<!-- n_hidden <- 3 -->
<!-- n_epochs <- 10000 -->
<!-- learn_by_epoch <- TRUE -->

<!-- i_to_h_assc_weights <- matrix(rnorm(n = ncol(event) * n_hidden, sd = 0.01), nrow = ncol(event), ncol = n_hidden) -->
<!-- h_to_o_assc_weights <- matrix(rnorm(n = n_hidden * ncol(response), sd = 0.01), nrow = n_hidden, ncol = ncol(response)) -->

<!-- for (epoch in 1:n_epochs) { -->
<!--     training_order <- sample(nrow(event)) -->

<!--     d_h_to_o <- 0 * h_to_o_assc_weights -->
<!--     d_i_to_h <- 0 * i_to_h_assc_weights -->

<!--     for (i in training_order) { -->
<!--         # Forward propagation (prediction) -->

<!--         # Note the use of `as.vector` to ensure result is a vector (not a matrix with a single row) -->
<!--         # We also allow hidden units to have activations between -1 and 1 by scaling/shifting the logistic function. -->
<!--         # This means we have to multiply the derivative on the error by the scaling factor (2) during back-propagation -->
<!--         hidden_activation <- logistic_act(as.vector(event[i,] %*% i_to_h_assc_weights)) -->
<!--         output_activation <- logistic_act(as.vector(hidden_activation %*% h_to_o_assc_weights)) -->

<!--         # Compute error at output layer -->
<!--         output_error <- output_activation - response[i,] -->

<!--         # Back propagation (learning) -->

<!--         # Derivative of error with respect to output unit activation -->
<!--         d_output_error <- output_error * output_activation * (1 - output_activation) -->

<!--         # Derivative of error with respect to hidden unit activation -->
<!--         # Note that multiplying by 2 is a consequence of the hidden units having shifted/scaled activation that ranges between -1 and 1 rather than between 0 and 1. -->
<!--         d_hidden_error <- as.vector(h_to_o_assc_weights %*% d_output_error) * hidden_activation * (1 - hidden_activation) -->

<!--         if (learn_by_epoch) { -->
<!--             # How much to adjust the associative weights between the hidden and output layers -->
<!--             d_h_to_o <- d_h_to_o + learning_rate * outer(hidden_activation, d_output_error) -->

<!--             # How much to adjust the associative weights between the input and hidden layers -->
<!--             d_i_to_h <- d_i_to_h + learning_rate * outer(event[i,], d_hidden_error) -->
<!--         } else { -->
<!--             d_h_to_o <- learning_rate * outer(hidden_activation, d_output_error) -->
<!--             d_i_to_h <- learning_rate * outer(event[i,], d_hidden_error) -->

<!--             # Adjust weights -->
<!--             i_to_h_assc_weights <- i_to_h_assc_weights + d_i_to_h -->
<!--             h_to_o_assc_weights <- h_to_o_assc_weights + d_h_to_o -->
<!--         } -->
<!--     } -->

<!--     if (learn_by_epoch) { -->
<!--         # Adjust weights -->
<!--         i_to_h_assc_weights <- i_to_h_assc_weights + d_i_to_h -->
<!--         h_to_o_assc_weights <- h_to_o_assc_weights + d_h_to_o -->
<!--     } -->
<!-- } -->

<!-- transfer_event <- matrix(c( -->
<!--     -1, -1, -1, -1, -->
<!--     -1, -1,  1,  1, -->
<!--     -1,  1, -1, -1, -->
<!--      1, -1,  1,  1, -->
<!--      1,  1,  1, -1, -->
<!--      1,  1, -1,  1, -->
<!--     -1,  1,  1, -1, -->
<!--      1, -1, -1,  1 -->
<!-- ), nrow = 8, ncol = 4, byrow = TRUE, -->
<!-- dimnames = list( -->
<!--     paste0("N", 1:8), -->
<!--     c("swollen_eyelids", "splotchy_ears", "discolored_gums", "nosebleed") -->
<!-- )) -->

<!-- p_resp <- matrix(0, nrow = nrow(transfer_event), ncol = ncol(response), dimnames = list(rownames(transfer_event), colnames(response))) -->

<!-- for (i in 1:nrow(transfer_event)) { -->
<!--     hidden_activation <- logistic_act(as.vector(transfer_event[i,] %*% i_to_h_assc_weights)) -->
<!--     p_resp[i,] <- logistic_act(as.vector(hidden_activation %*% h_to_o_assc_weights)) -->
<!-- } -->

<!-- knitr::kable(p_resp) -->
<!-- ``` -->

<!-- ## Exercises -->

<!-- 1. Within the context of a model like the EBRW, storing a new exemplar as a trace in memory could be considered a form of *learning*, in the sense that the performance of the model *changes* as a function of having experienced that new exemplar.  Compare and contrast this form of learning with the forms of learning we encountered in this chapter. -->
<!-- 2. Describe how you would use the output of any of the learning models we've seen in this chapter to predict not only choice behavior, but also choice and response time. -->